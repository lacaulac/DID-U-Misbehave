cpio;copy files to and from archives;-o, --create;Copy-out. Read a list of file names from the standard input and create on the standard output (unless overridden by the --file option) an archive containing these files.;NONE;4
cpio;copy files to and from archives;-i, --extract;Copy-in. Read the archive from standard input (or from the file supplied with the --file option) and extract files from it, or (if the -t option is given) list its contents to the standard output. If one or more patterns are supplied, read or list only files matching these patterns. The -t option alone implies -i.;NONE;3
cpio;copy files to and from archives;-i, --extract;Copy-in. Read the archive from standard input (or from the file supplied with the --file option) and extract files from it, or (if the -t option is given) list its contents to the standard output. If one or more patterns are supplied, read or list only files matching these patterns. The -t option alone implies -i.;NONE;4
cpio;copy files to and from archives;-p, --pass-through;Pass-through. Read a list of file names from the standard input and copy them to the specified directory.;NONE;3
cpio;copy files to and from archives;-?, --help;Give a short help summary and exit.;NONE;0
cpio;copy files to and from archives;--usage;Print a short usage message and exit.;NONE;0
cpio;copy files to and from archives;--version;Print program version and exit.;NONE;0
cpio;copy files to and from archives;--block-size=BLOCK-SIZE;Set the I/O block size to BLOCK-SIZE * 512 bytes.;NONE;0
cpio;copy files to and from archives;-B;Set the I/O block size to 5120 bytes.;NONE;0
cpio;copy files to and from archives;-c;Use the old portable (ASCII) archive format. This is the same as -H odc.;NONE;0
cpio;copy files to and from archives;-C, --io-size=NUMBER;Set the I/O block size to the given NUMBER of bytes.;NONE;0
cpio;copy files to and from archives;-D, --directory=DIR;Change to directory DIR.;NONE;0
cpio;copy files to and from archives;--force-local;Archive file is local, even if its name contains colons.;NONE;0
cpio;copy files to and from archives;-H, --format=FORMAT;Use given archive FORMAT. Valid formats are (the number in parentheses gives maximum size for individual archive member): bin The obsolete binary format. (2147483647 bytes) odc The old (POSIX.1) portable format. (8589934591 bytes) newc The new (SVR4) portable format, which supports file systems having more than 65536 i-nodes. (4294967295 bytes) crc The new (SVR4) portable format with a checksum added. tar The old tar format. (8589934591 bytes) ustar The POSIX.1 tar format. Also recognizes GNU tar archives, which are similar but not identical. (8589934591 bytes) hpbin The obsolete binary format used by HPUX's cpio (which stores device files differently). hpodc The portable format used by HPUX's cpio (which stores device files differently).;NONE;0
cpio;copy files to and from archives;-R, --owner=[USER][:.][GROUP];In copy-in and copy-pass mode, set the ownership of all files created to the specified USER and/or GROUP. In copy-out mode, store the supplied owner information in the archive. USER and GROUP are first looked up in the system user and group databases. If not found, cpio checks if they consist of decimal digits only and, if so, treats them as numeric UID and GID, correspondingly. To avoid the lookup and ensure that arguments are treated as numeric values, prefix them with a plus sign, e.g.: -R +0:+0.;NONE;9
cpio;copy files to and from archives;--quiet;Do not print the number of blocks copied at the end of the run.;NONE;0
cpio;copy files to and from archives;--rsh-command=COMMAND;Use remote COMMAND instead of rsh.;NONE;1
cpio;copy files to and from archives;-v, --verbose;Verbosely list the files processed.;NONE;0
cpio;copy files to and from archives;-V, --dot;Print a "." for each file processed.;NONE;0
cpio;copy files to and from archives;-W, --warning=FLAG;Controls warning display. The FLAG is one of none, to disable all warnings, all to enable them, truncate, to enable warnings about field truncation, and no-truncate, to disable them.;NONE;0
cpio;copy files to and from archives;-F, --file=[[USER@]HOST:]ARCHIVE-FILE;Use this ARCHIVE-FILE instead of standard input (in copy-in mode) or standard output (in copy-out mode). Optional USER and HOST specify the user and host names in case of a remote archive.;NONE;2
cpio;copy files to and from archives;-F, --file=[[USER@]HOST:]ARCHIVE-FILE;Use this ARCHIVE-FILE instead of standard input (in copy-in mode) or standard output (in copy-out mode). Optional USER and HOST specify the user and host names in case of a remote archive.;NONE;3
cpio;copy files to and from archives;-F, --file=[[USER@]HOST:]ARCHIVE-FILE;Use this ARCHIVE-FILE instead of standard input (in copy-in mode) or standard output (in copy-out mode). Optional USER and HOST specify the user and host names in case of a remote archive.;NONE;5
cpio;copy files to and from archives;-M, --message=STRING;Print STRING when the end of a volume of the backup media is reached.;NONE;4
cpio;copy files to and from archives;-b, --swap;Swap both halfwords of words and bytes of halfwords in the data. Equivalent to -sS.;NONE;0
cpio;copy files to and from archives;-f, --nonmatching;Only copy files that do not match any of the given patterns.;NONE;0
cpio;copy files to and from archives;-n, --numeric-uid-gid;In the verbose table of contents listing, show numeric UID and GID.;NONE;0
cpio;copy files to and from archives;-r, --rename;Interactively rename files.;NONE;3
cpio;copy files to and from archives;-s, --swap-bytes;Swap the bytes of each halfword in the files.;NONE;0
cpio;copy files to and from archives;-S, --swap-halfwords;Swap the halfwords of each word (4 bytes) in the files.;NONE;0
cpio;copy files to and from archives;--to-stdout;Extract files to standard output.;NONE;4
cpio;copy files to and from archives;-E, --pattern-file=FILE;Read additional patterns specifying filenames to extract or list from FILE.;NONE;2
cpio;copy files to and from archives;--only-verify-crc;When reading a CRC format archive, only verify the CRC's of each file in the archive, without actually extracting the files.;NONE;0
cpio;copy files to and from archives;-A, --append;Append to an existing archive.;NONE;3
cpio;copy files to and from archives;--device-independent, --reproducible;Create reproducible archives. This is equivalent to --ignore-devno --renumber-inodes.;NONE;0
cpio;copy files to and from archives;--ignore-devno;Store 0 in the device number field of each archive member, instead of the actual device number.;NONE;0
cpio;copy files to and from archives;-O [[USER@]HOST:]ARCHIVE-NAME;Use ARCHIVE-NAME instead of standard output. Optional USER and HOST specify the user and host names in case of a remote archive. The output archive name can be specified wither using this option, or using -F (--file), but not both.;NONE;3
cpio;copy files to and from archives;-O [[USER@]HOST:]ARCHIVE-NAME;Use ARCHIVE-NAME instead of standard output. Optional USER and HOST specify the user and host names in case of a remote archive. The output archive name can be specified wither using this option, or using -F (--file), but not both.;NONE;5
cpio;copy files to and from archives;--renumber-inodes;Renumber inodes when storing them in the archive.;NONE;0
cpio;copy files to and from archives;-l, --link;Link files instead of copying them, when possible.;NONE;3
cpio;copy files to and from archives;--absolute-filenames;Do not strip file system prefix components from the file names. This is the default.;NONE;0
cpio;copy files to and from archives;--no-absolute-filenames;Create all files relative to the current directory.;NONE;0
cpio;copy files to and from archives;-0, --null;Filenames in the list are delimited by null characters instead of newlines.;NONE;0
cpio;copy files to and from archives;-a, --reset-access-time;Reset the access times of files after reading them.;NONE;9
cpio;copy files to and from archives;-I [[USER@]HOST:]ARCHIVE-NAME;Use ARCHIVE-NAME instead of standard input. Optional USER and HOST specify the user and host names in case of a remote archive.;NONE;2
cpio;copy files to and from archives;-I [[USER@]HOST:]ARCHIVE-NAME;Use ARCHIVE-NAME instead of standard input. Optional USER and HOST specify the user and host names in case of a remote archive.;NONE;5
cpio;copy files to and from archives;-L, --dereference;Dereference symbolic links (copy the files that they point to instead of copying the links).;NONE;2
cpio;copy files to and from archives;-d, --make-directories;Create leading directories where needed.;NONE;3
cpio;copy files to and from archives;-m, --preserve-modification-time;Retain previous file modification times when creating files.;NONE;9
cpio;copy files to and from archives;--no-preserve-owner;Do not change the ownership of the files.;NONE;9
cpio;copy files to and from archives;--sparse;Write files with large blocks of zeros as sparse files.;NONE;0
cpio;copy files to and from archives;-u, --unconditional;Replace all files unconditionally.;NONE;3
cpio;copy files to and from archives;cpio;copy files to and from archives;NONE;2
nc;arbitrary TCP and UDP connections and listens;nc;arbitrary TCP and UDP connections and listens;NONE;5
nc;arbitrary TCP and UDP connections and listens;-6;Use IPv6 addresses only.;NONE;0
nc;arbitrary TCP and UDP connections and listens;-b;Allow broadcast.;NONE;0
nc;arbitrary TCP and UDP connections and listens;-C;Send CRLF as line-ending. Each line feed (LF) character from the input data is translated into CR+LF before being written to the socket. Line feed characters that are already preceded with a carriage return (CR) are not translated. Received data is not affected.;NONE;0
nc;arbitrary TCP and UDP connections and listens;-D;Enable debugging on the socket.;NONE;0
nc;arbitrary TCP and UDP connections and listens;-d;Do not attempt to read from stdin.;NONE;0
nc;arbitrary TCP and UDP connections and listens;-F;Pass the first connected socket using sendmsg(2) to stdout and exit. This is useful in conjunction with -X to have nc perform connection setup with a proxy but then leave the rest of the connection to another program (e.g. ssh(1) using the ssh_config(5) ProxyUseFdpass option). Cannot be used with -U.;NONE;4
nc;arbitrary TCP and UDP connections and listens;-h;Print out the nc help text and exit.;NONE;0
nc;arbitrary TCP and UDP connections and listens;-I length;Specify the size of the TCP receive buffer.;NONE;0
nc;arbitrary TCP and UDP connections and listens;-i interval;Sleep for interval seconds between lines of text sent and received. Also causes a delay time between connections to multiple ports.;NONE;0
nc;arbitrary TCP and UDP connections and listens;-k;When a connection is completed, listen for another one. Requires -l. When used together with the -u option, the server socket is not connected and it can receive UDP datagrams from multiple hosts.;NONE;0
nc;arbitrary TCP and UDP connections and listens;-l;Listen for an incoming connection rather than initiating a connection to a remote host. The destination and port to listen on can be specified either as non-optional arguments, or with options -s and -p respectively. Cannot be used together with -x or -z. Additionally, any timeouts specified with the -w option are ignored.;NONE;5
nc;arbitrary TCP and UDP connections and listens;-M ttl;Set the TTL / hop limit of outgoing packets.;NONE;5
nc;arbitrary TCP and UDP connections and listens;-m minttl;Ask the kernel to drop incoming packets whose TTL / hop limit is under minttl.;NONE;0
nc;arbitrary TCP and UDP connections and listens;-N;shutdown(2) the network socket after EOF on the input. Some servers require this to finish their work.;NONE;0
nc;arbitrary TCP and UDP connections and listens;-n;Do not do any DNS or service lookups on any specified addresses, hostnames or ports.;NONE;0
nc;arbitrary TCP and UDP connections and listens;-O length;Specify the size of the TCP send buffer.;NONE;0
nc;arbitrary TCP and UDP connections and listens;-P proxy_username;Specifies a username to present to a proxy server that requires authentication. If no username is specified then authentication will not be attempted. Proxy authentication is only supported for HTTP CONNECT proxies at present.;NONE;5
nc;arbitrary TCP and UDP connections and listens;-p source_port;Specify the source port nc should use, subject to privilege restrictions and availability.;NONE;5
nc;arbitrary TCP and UDP connections and listens;-q seconds;after EOF on stdin, wait the specified number of seconds and then quit. If seconds is negative, wait forever (default). Specifying a non- negative seconds implies -N.;NONE;0
nc;arbitrary TCP and UDP connections and listens;-r;Choose source and/or destination ports randomly instead of sequentially within a range or in the order that the system assigns them.;NONE;0
nc;arbitrary TCP and UDP connections and listens;-S;Enable the RFC 2385 TCP MD5 signature option.;NONE;0
nc;arbitrary TCP and UDP connections and listens;-s source;Send packets from the interface with the source IP address. For UNIX-domain datagram sockets, specifies the local temporary socket file to create and use so that datagrams can be received. Cannot be used together with -x.;NONE;0
nc;arbitrary TCP and UDP connections and listens;-T keyword;Change the IPv4 TOS/IPv6 traffic class value. keyword may be one of critical, inetcontrol, lowcost, lowdelay, netcontrol, throughput, reliability, or one of the DiffServ Code Points: ef, af11 ... af43, cs0 ... cs7. or a number in either hex or decimal.;NONE;5
nc;arbitrary TCP and UDP connections and listens;-t;Send RFC 854 DON'T and WON'T responses to RFC 854 DO and WILL requests. This makes it possible to use nc to script telnet sessions.;NONE;0
nc;arbitrary TCP and UDP connections and listens;-U;Use UNIX-domain sockets. Cannot be used together with -F or -x.;NONE;0
nc;arbitrary TCP and UDP connections and listens;-u;Use UDP instead of TCP. Cannot be used together with -x. For UNIX-domain sockets, use a datagram socket instead of a stream socket. If a UNIX-domain socket is used, a temporary receiving socket is created in /tmp unless the -s flag is given.;NONE;0
nc;arbitrary TCP and UDP connections and listens;-V rtable;Set the routing table to be used.;NONE;0
nc;arbitrary TCP and UDP connections and listens;-v;Produce more verbose output.;NONE;0
nc;arbitrary TCP and UDP connections and listens;-W recvlimit;Terminate after receiving recvlimit packets from the network.;NONE;0
nc;arbitrary TCP and UDP connections and listens;-w timeout;Connections which cannot be established or are idle timeout after timeout seconds. The -w flag has no effect on the -l option, i.e. nc will listen forever for a connection, with or without the -w flag. The default is no timeout.;NONE;0
nc;arbitrary TCP and UDP connections and listens;-X proxy_protocol;Use proxy_protocol when talking to the proxy server. Supported protocols are 4 (SOCKS v.4), 5 (SOCKS v.5) and connect (HTTPS proxy). If the protocol is not specified, SOCKS version 5 is used.;NONE;0
nc;arbitrary TCP and UDP connections and listens;-x proxy_address[:port];Connect to destination using a proxy at proxy_address and port. If port is not specified, the well-known port for the proxy protocol is used (1080 for SOCKS, 3128 for HTTPS). An IPv6 address can be specified unambiguously by enclosing proxy_address in square brackets. A proxy cannot be used with any of the options -lsuU.;NONE;5
nc;arbitrary TCP and UDP connections and listens;-Z;DCCP mode.;NONE;0
nc;arbitrary TCP and UDP connections and listens;-z;Only scan for listening daemons, without sending any data to them. Cannot be used together with -l.;NONE;0
zip;package and compress (archive) files;zip;package and compress (archive) files;NONE;3
zip;package and compress (archive) files;zip;package and compress (archive) files;NONE;2
zip;package and compress (archive) files;-A, --adjust-sfx;Adjust self-extracting executable archive. A self-extracting executable archive is created by prepending the SFX stub to an existing archive. The -A option tells zip to adjust the entry offsets stored in the archive to take into account this "preamble" data. Note: self-extracting archives for the Amiga are a special case. At present, only the Amiga port of zip is capable of adjusting or updating these without corrupting them. -J can be used to remove the SFX stub if other updates need to be made.;NONE;0
zip;package and compress (archive) files;-AC, --archive-clear;[WIN32] Once archive is created (and tested if -T is used, which is recommended), clear the archive bits of files processed. WARNING: Once the bits are cleared they are cleared. You may want to use the -sf show files option to store the list of files processed in case the archive operation must be repeated. Also consider using the -MM must match option. Be sure to check out -DF as a possibly better way to do incremental backups.;NONE;9
zip;package and compress (archive) files;-AS, --archive-set;[WIN32] Only include files that have the archive bit set. Directories are not stored when -AS is used, though by default the paths of entries, including directories, are stored as usual and can be used by most unzips to recreate directories. The archive bit is set by the operating system when a file is modified and, if used with -AC, -AS can provide an incremental backup capability. However, other applications can modify the archive bit and it may not be a reliable indicator of which files have changed since the last archive operation. Alternative ways to create incremental backups are using -t to use file dates, though this won't catch old files copied to directories being archived, and -DF to create a differential archive.;NONE;7
zip;package and compress (archive) files;-B, --binary;[VM/CMS and MVS] force file to be read binary (default is text).;NONE;0
zip;package and compress (archive) files;-Bn;[TANDEM] set Edit/Enscribe formatting options with n defined as bit 0: Don't add delimiter (Edit/Enscribe) bit 1: Use LF rather than CR/LF as delimiter (Edit/Enscribe) bit 2: Space fill record to maximum record length (Enscribe) bit 3: Trim trailing space (Enscribe) bit 8: Force 30K (Expand) large read for unstructured files;NONE;0
zip;package and compress (archive) files;-b path;--temp-path path Use the specified path for the temporary zip archive. For example: zip -b /tmp stuff * will put the temporary zip archive in the directory /tmp, copying over stuff.zip to the current directory when done. This option is useful when updating an existing archive and the file system containing this old archive does not have enough space to hold both old and new archives at the same time. It may also be useful when streaming in some cases to avoid the need for data descriptors. Note that using this option may require zip take additional time to copy the archive file when done to the destination file system.;NONE;3
zip;package and compress (archive) files;-c, --entry-comments;Add one-line comments for each file. File operations (adding, updating) are done first, and the user is then prompted for a one-line comment for each file. Enter the comment followed by return, or just return for no comment.;NONE;3
zip;package and compress (archive) files;-C, --preserve-case;[VMS] Preserve case all on VMS. Negating this option (-C-) downcases.;NONE;0
zip;package and compress (archive) files;-C2, --preserve-case-2;[VMS] Preserve case ODS2 on VMS. Negating this option (-C2-) downcases.;NONE;0
zip;package and compress (archive) files;-C5, --preserve-case-5;[VMS] Preserve case ODS5 on VMS. Negating this option (-C5-) downcases.;NONE;0
zip;package and compress (archive) files;-d, --delete;Remove (delete) entries from a zip archive. -db --display-bytes Display running byte counts showing the bytes zipped and the bytes to go.;NONE;3
zip;package and compress (archive) files;-dc, --display-counts;Display running count of entries zipped and entries to go.;NONE;0
zip;package and compress (archive) files;-dd, --display-dots;Display dots while each entry is zipped (except on ports that have their own progress indicator). See -ds below for setting dot size. The default is a dot every 10 MB of input file processed. The -v option also displays dots (previously at a much higher rate than this but now -v also defaults to 10 MB) and this rate is also controlled by -ds.;NONE;0
zip;package and compress (archive) files;-df, --datafork;[MacOS] Include only data-fork of files zipped into the archive. Good for exporting files to foreign operating-systems. Resource-forks will be ignored at all.;NONE;0
zip;package and compress (archive) files;-dg, --display-globaldots;Display progress dots for the archive instead of for each file. The command zip -qdgds 10m will turn off most output except dots every 10 MB.;NONE;0
zip;package and compress (archive) files;-ds size;--dot-size size Set amount of input file processed for each dot displayed. See -dd to enable displaying dots. Setting this option implies -dd. Size is in the format nm where n is a number and m is a multiplier. Currently m can be k (KB), m (MB), g (GB), or t (TB), so if n is 100 and m is k, size would be 100k which is 100 KB. The default is 10 MB. The -v option also displays dots and now defaults to 10 MB also. This rate is also controlled by this option. A size of 0 turns dots off. This option does not control the dots from the "Scanning files" message as zip scans for input files. The dot size for that is fixed at 2 seconds or a fixed number of entries, whichever is longer.;NONE;0
zip;package and compress (archive) files;-du, --display-usize;Display the uncompressed size of each entry. -dv --display-volume Display the volume (disk) number each entry is being read from, if reading an existing archive, and being written to.;NONE;7
zip;package and compress (archive) files;-D, --no-dir-entries;Do not create entries in the zip archive for directories. Directory entries are created by default so that their attributes can be saved in the zip archive. The environment variable ZIPOPT can be used to change the default options. For example under Unix with sh: ZIPOPT="-D". export ZIPOPT (The variable ZIPOPT can be used for any option, including -i and -x using a new option format detailed below, and can include several options.) The option -D is a shorthand for -x "*/" but the latter previously could not be set as default in the ZIPOPT environment variable as the contents of ZIPOPT gets inserted near the beginning of the command line and the file list had to end at the end of the line. This version of zip does allow -x and -i options in ZIPOPT if the form;NONE;0
zip;package and compress (archive) files;-DF, --difference-archive;Create an archive that contains all new and changed files since the original archive was created. For this to work, the input file list and current directory must be the same as during the original zip operation. -e --encrypt Encrypt the contents of the zip archive using a password which is entered on the terminal in response to a prompt (this will not be echoed. if standard error is not a tty, zip will exit with an error). The password prompt is repeated to save the user from typing errors.;NONE;7
zip;package and compress (archive) files;-E, --longnames;[OS/2] Use the .LONGNAME Extended Attribute (if found) as filename.;NONE;7
zip;package and compress (archive) files;-f, --freshen;Replace (freshen) an existing entry in the zip archive only if it has been modified more recently than the version already in the zip archive. unlike the update option (-u) this will not add files that are not already in the zip archive. For example: zip -f foo This command should be run from the same directory from which the original zip command was run, since paths stored in zip archives are always relative. Note that the timezone environment variable TZ should be set according to the local timezone in order for the -f, -u and -o options to work correctly. The reasons behind this are somewhat subtle but have to do with the differences between the Unix-format file times (always in GMT) and most of the other operating systems (always local time) and the necessity to compare the two. A typical TZ value is ``MET-1MEST'' (Middle European time with automatic adjustment for ``summertime'' or Daylight Savings Time). The format is TTThhDDD, where TTT is the time zone such as MET, hh is the difference between GMT and local time such as -1 above, and DDD is the time zone when daylight savings time is in effect. Leave off the DDD if there is no daylight savings time. For the US Eastern time zone EST5EDT.;NONE;7
zip;package and compress (archive) files;-F, --fix;Fix the zip archive. The -F option can be used if some portions of the archive are missing, but requires a reasonably intact central directory. The input archive is scanned as usual, but zip will ignore some problems. The resulting archive should be valid, but any inconsistent entries will be left out.;NONE;0
zip;package and compress (archive) files;-FF, --fixfix;Fix the zip archive. The -F option can be used if some portions of the archive are missing, but requires a reasonably intact central directory. The input archive is scanned as usual, but zip will ignore some problems. The resulting archive should be valid, but any inconsistent entries will be left out.;NONE;0
zip;package and compress (archive) files;-FI, --fifo [Unix];Normally zip skips reading any FIFOs (named pipes) encountered, as zip can hang if the FIFO is not being fed. This option tells zip to read the contents of any FIFO it finds.;NONE;2
zip;package and compress (archive) files;-FS, --filesync;Synchronize the contents of an archive with the files on the OS. Normally when an archive is updated, new files are added and changed files are updated but files that no longer exist on the OS are not deleted from the archive. This option enables a new mode that checks entries in the archive against the file system. If the file time and file size of the entry matches that of the OS file, the entry is copied from the old archive instead of being read from the file system and compressed. If the OS file has changed, the entry is read and compressed as usual. If the entry in the archive does not match a file on the OS, the entry is deleted. Enabling this option should create archives that are the same as new archives, but since existing entries are copied instead of compressed, updating an existing archive with -FS can be much faster than creating a new archive. Also consider using -u for updating an archive. For this option to work, the archive should be updated from the same directory it was created in so the relative paths match. If few files are being copied from the old archive, it may be faster to create a new archive instead. Note that the timezone environment variable TZ should be set according to the local timezone in order for this option to work correctly. A change in timezone since the original archive was created could result in no times matching and recompression of all files. This option deletes files from the archive. If you need to preserve the original archive, make a copy of the archive first or use the --out option to output the updated archive to a new file. Even though it may be slower, creating a new archive with a new archive name is safer, avoids mismatches between archive and OS paths, and is preferred.;NONE;7
zip;package and compress (archive) files;-g, --grow;Grow (append to) the specified zip archive, instead of creating a new one. If this operation fails, zip attempts to restore the archive to its original state. If the restoration fails, the archive might become corrupted. This option is ignored when there's no existing archive or when at least one archive member must be updated or deleted.;NONE;0
zip;package and compress (archive) files;-h, -?, --help;Display the zip help information (this also appears if zip is run with no arguments).;NONE;0
zip;package and compress (archive) files;-h2, --more-help;Display extended help including more on command line format, pattern matching, and more obscure options.;NONE;0
zip;package and compress (archive) files;-i files, --include files;Include only the specified files;NONE;0
zip;package and compress (archive) files;-I, --no-image;[Acorn RISC OS] Don't scan through Image files. When used, zip will not consider Image files (eg. DOS partitions or Spark archives when SparkFS is loaded) as directories but will store them as single files. For example, if you have SparkFS loaded, zipping a Spark archive will result in a zipfile containing a directory (and its content) while using the 'I' option will result in a zipfile containing a Spark archive. Obviously this second case will also be obtained (without the 'I' option) if SparkFS isn't loaded.;NONE;0
zip;package and compress (archive) files;-ic, --ignore-case;[VMS, WIN32] Ignore case when matching archive entries. This option is only available on systems where the case of files is ignored. On systems with case-insensitive file systems, case is normally ignored when matching files on the file system but is not ignored for -f (freshen), -d (delete), -U (copy), and similar modes when matching against archive entries (currently -f ignores case on VMS) because archive entries can be from systems where case does matter and names that are the same except for case can exist in an archive. The -ic option makes all matching case insensitive. This can result in multiple archive entries matching a command line pattern.;NONE;0
zip;package and compress (archive) files;-j, --junk-paths;Store just the name of a saved file (junk the path), and do not store directory names. By default, zip will store the full path (relative to the current directory).;NONE;0
zip;package and compress (archive) files;-jj, --absolute-path;[MacOS] record Fullpath (+ Volname). The complete path including volume will be stored. By default the relative path will be stored.;NONE;7
zip;package and compress (archive) files;-J, --junk-sfx;Strip any prepended data (e.g. a SFX stub) from the archive.;NONE;0
zip;package and compress (archive) files;-k, --DOS-names;Attempt to convert the names and paths to conform to MSDOS, store only the MSDOS attribute (just the user write attribute from Unix), and mark the entry as made under MSDOS (even though it was not). for compatibility with PKUNZIP under MSDOS which cannot handle certain names such as those with two dots.;NONE;7
zip;package and compress (archive) files;-l, --to-crlf;Translate the Unix end-of-line character LF into the MSDOS convention CR LF. This option should not be used on binary files. This option can be used on Unix if the zip file is intended for PKUNZIP under MSDOS. If the input files already contain CR LF, this option adds an extra CR. This is to ensure that unzip -a on Unix will get back an exact copy of the original file, to undo the effect of zip -l. See -ll for how binary files are handled.;NONE;0
zip;package and compress (archive) files;-la, --log-append;Append to existing logfile. Default is to overwrite.;NONE;3
zip;package and compress (archive) files;-lf logfilepath;--logfile-path logfilepath Open a logfile at the given path. By default any existing file at that location is overwritten, but the -la option will result in an existing file being opened and the new log information appended to any existing information. Only warnings and errors are written to the log unless the -li option is also given, then all information messages are also written to the log.;NONE;3
zip;package and compress (archive) files;-li, --log-info;Include information messages, such as file names being zipped, in the log. The default is to only include the command line, any warnings and errors, and the final status.;NONE;0
zip;package and compress (archive) files;-ll, --from-crlf;Translate the MSDOS end-of-line CR LF into Unix LF. This option should not be used on binary files. This option can be used on MSDOS if the zip file is intended for unzip under Unix. If the file is converted and the file is later determined to be binary a warning is issued and the file is probably corrupted. In this release if -ll detects binary in the first buffer read from a file, zip now issues a warning and skips line end conversion on the file. This check seems to catch all binary files tested, but the original check remains and if a converted file is later determined to be binary that warning is still issued. A new algorithm is now being used for binary detection that should allow line end conversion of text files in UTF-8 and similar encodings.;NONE;0
zip;package and compress (archive) files;-L, --license;Display the zip license.;NONE;0
zip;package and compress (archive) files;-m, --move;Move the specified files into the zip archive. actually, this deletes the target directories/files after making the specified zip archive. If a directory becomes empty after removal of the files, the directory is also removed. No deletions are done until zip has created the archive without error. This is useful for conserving disk space, but is potentially dangerous so it is recommended to use it in combination with -T to test the archive before removing all input files.;NONE;9
zip;package and compress (archive) files;-MM, --must-match;All input patterns must match at least one file and all input files found must be readable. Normally when an input pattern does not match a file the "name not matched" warning is issued and when an input file has been found but later is missing or not readable a missing or not readable warning is issued. In either case zip continues creating the archive, with missing or unreadable new files being skipped and files already in the archive remaining unchanged. After the archive is created, if any files were not readable zip returns the OPEN error code (18 on most systems) instead of the normal success return (0 on most systems). With -MM set, zip exits as soon as an input pattern is not matched (whenever the "name not matched" warning would be issued) or when an input file is not readable. In either case zip exits with an OPEN error and no archive is created.;NONE;0
zip;package and compress (archive) files;-n suffixes;--suffixes suffixes Do not attempt to compress files named with the given suffixes. Such files are simply stored (0% compression) in the output zip file, so that zip doesn't waste its time trying to compress them. The suffixes are separated by either colons or semicolons. For example: zip -rn .Z:.zip:.tiff:.gif:.snd foo foo will copy everything from foo into foo.zip, but will store any files that end in .Z, .zip, .tiff, .gif, or .snd without trying to compress them (image and sound files often have their own specialized compression methods). By default, zip does not compress files with extensions in the list .Z:.zip:.zoo:.arc:.lzh:.arj. Such files are stored directly in the output archive. The environment variable ZIPOPT can be used to change the default options. For example under Unix with csh: setenv ZIPOPT "-n .gif:.zip" To attempt compression on all files, use: zip -n : foo The maximum compression option -9 also attempts compression on all files regardless of extension. On Acorn RISC OS systems the suffixes are actually filetypes (3 hex digit format). By default, zip does not compress files with filetypes in the list DDC:D96:68E (i.e. Archives, CFS files and PackDir files).;NONE;0
zip;package and compress (archive) files;-nw, --no-wild;Do not perform internal wildcard processing (shell processing of wildcards is still done by the shell unless the arguments are escaped). Useful if a list of paths is being read and no wildcard substitution is desired.;NONE;0
zip;package and compress (archive) files;-N, --notes;[Amiga, MacOS] Save Amiga or MacOS filenotes as zipfile comments. They can be restored by using the -N option of unzip. If -c is used also, you are prompted for comments only for those files that do not have filenotes.;NONE;7
zip;package and compress (archive) files;-o, --latest-time;Set the "last modified" time of the zip archive to the latest (oldest) "last modified" time found among the entries in the zip archive. This can be used without any other operations, if desired.;NONE;9
zip;package and compress (archive) files;-O output-file;--output-file output-file Process the archive changes as usual, but instead of updating the existing archive, output the new archive to output-file. Useful for updating an archive without changing the existing archive and the input archive must be a different file than the output archive. This option can be used to create updated split archives. It can also be used with -U to copy entries from an existing archive to a new archive. See the EXAMPLES section below. Another use is converting zip files from one split size to another. For instance, to convert an archive with 700 MB CD splits to one with 2 GB DVD splits, can use: zip -s 2g cd-split.zip --out dvd-split.zip which uses copy mode. See -U below. Also: zip -s 0 split.zip --out unsplit.zip will convert a split archive to a single-file archive. Copy mode will convert stream entries (using data descriptors and which should be compatible with most unzips) to normal entries (which should be compatible with all unzips), except if standard encryption was used. For archives with encrypted entries, zipcloak will decrypt the entries and convert them to normal entries.;NONE;3
zip;package and compress (archive) files;-p, --paths;Include relative file paths as part of the names of files stored in the archive. This is the default. The -j option junks the paths and just stores the names of the files.;NONE;0
zip;package and compress (archive) files;-P password;--password password Use password to encrypt zipfile entries (if any). THIS IS INSECURE! Many multi-user operating systems provide ways for any user to see the current command line of any other user. even on stand-alone systems there is always the threat of over-the-shoulder peeking. Storing the plaintext password as part of a command line in an automated script is even worse. Whenever possible, use the non-echoing, interactive prompt to enter passwords. (And where security is truly important, use strong encryption such as Pretty Good Privacy instead of the relatively weak standard encryption provided by zipfile utilities.);NONE;0
zip;package and compress (archive) files;-q, --quiet;Quiet mode. eliminate informational messages and comment prompts. (Useful, for example, in shell scripts and background tasks).;NONE;0
zip;package and compress (archive) files;-Qn, --Q-flag n;[QDOS] store information about the file in the file header with n defined as bit 0: Don't add headers for any file bit 1: Add headers for all files bit 2: Don't wait for interactive key press on exit;NONE;7
zip;package and compress (archive) files;-r, --recurse-paths;Travel the directory structure recursively. for example: zip -r foo.zip foo or more concisely zip -r foo foo In this case, all the files and directories in foo are saved in a zip archive named foo.zip, including files with names starting with ".", since the recursion does not use the shell's file-name substitution mechanism. If you wish to include only a specific subset of the files in directory foo and its subdirectories, use the -i option to specify the pattern of files to be included. You should not use -r with the name ".*", since that matches ".." which will attempt to zip up the parent directory (probably not what was intended). Multiple source directories are allowed as in zip -r foo foo1 foo2 which first zips up foo1 and then foo2, going down each directory. Note that while wildcards to -r are typically resolved while recursing down directories in the file system, any -R, -x, and -i wildcards are applied to internal archive pathnames once the directories are scanned. To have wildcards apply to files in subdirectories when recursing on Unix and similar systems where the shell does wildcard substitution, either escape all wildcards or put all arguments with wildcards in quotes. This lets zip see the wildcards and match files in subdirectories using them as it recurses.;NONE;7
zip;package and compress (archive) files;-R, --recurse-patterns;Travel the directory structure recursively starting at the current directory.;NONE;7
zip;package and compress (archive) files;-RE, --regex;[WIN32] Before zip 3.0, regular expression list matching was enabled by default on Windows platforms. Because of confusion resulting from the need to escape "[" and "]" in names, it is now off by default for Windows so "[" and "]" are just normal characters in names. This option enables [] matching again.;NONE;7
zip;package and compress (archive) files;-s splitsize;--split-size splitsize Enable creating a split archive and set the split size. A split archive is an archive that could be split over many files. As the archive is created, if the size of the archive reaches the specified split size, that split is closed and the next split opened. In general all splits but the last will be the split size and the last will be whatever is left. If the entire archive is smaller than the split size a single-file archive is created.;NONE;0
zip;package and compress (archive) files;-sb, --split-bell;If splitting and using split pause mode, ring the bell when zip pauses for each split destination.;NONE;0
zip;package and compress (archive) files;-sc, --show-command;Show the command line starting zip as processed and exit. The new command parser permutes the arguments, putting all options and any values associated with them before any non-option arguments. This allows an option to appear anywhere in the command line as long as any values that go with the option go with it. This option displays the command line as zip sees it, including any arguments from the environment such as from the ZIPOPT variable. Where allowed, options later in the command line can override options earlier in the command line.;NONE;0
zip;package and compress (archive) files;-sf, --show-files;Show the files that would be operated on, then exit. For instance, if creating a new archive, this will list the files that would be added. If the option is negated, -sf-, output only to an open log file. Screen display is not recommended for large lists.;NONE;0
zip;package and compress (archive) files;-so, --show-options;Show all available options supported by zip as compiled on the current system. As this command reads the option table, it should include all options. Each line includes the short option (if defined), the long option (if defined), the format of any value that goes with the option, if the option can be negated, and a small description. The value format can be no value, required value, optional value, single character value, number value, or a list of values. The output of this option is not intended to show how to use any option but only show what options are available.;NONE;0
zip;package and compress (archive) files;-sp, --split-pause;If splitting is enabled with -s, enable split pause mode. This creates split archives as -s does, but stream writing is used so each split can be closed as soon as it is written and zip will pause between each split to allow changing split destination or media. Though this split mode allows writing splits directly to removable media, it uses stream archive format that may not be readable by some unzips. Before relying on splits created with -sp, test a split archive with the unzip you will be using. To convert a stream split archive (created with -sp) to a standard archive see the --out option.;NONE;0
zip;package and compress (archive) files;-su, --show-unicode;As -sf, but also show Unicode version of the path if exists.;NONE;0
zip;package and compress (archive) files;-sU, --show-just-unicode;As -sf, but only show Unicode version of the path if exists, otherwise show the standard version of the path.;NONE;0
zip;package and compress (archive) files;-sv, --split-verbose;Enable various verbose messages while splitting, showing how the splitting is being done.;NONE;0
zip;package and compress (archive) files;-S, --system-hidden;[MSDOS, OS/2, WIN32 and ATARI] Include system and hidden files. [MacOS] Includes finder invisible files, which are ignored otherwise.;NONE;0
zip;package and compress (archive) files;-t mmddyyyy;--from-date mmddyyyy Do not operate on files modified prior to the specified date, where mm is the month (00-12), dd is the day of the month (01-31), and yyyy is the year. The ISO 8601 date format yyyy-mm-dd is also accepted. For example: zip -rt 12071991 infamy foo zip -rt 1991-12-07 infamy foo will add all the files in foo and its subdirectories that were last modified on or after 7 December 1991, to the zip archive infamy.zip.;NONE;7
zip;package and compress (archive) files;-tt mmddyyyy;--before-date mmddyyyy Do not operate on files modified after or at the specified date, where mm is the month (00-12), dd is the day of the month (01-31), and yyyy is the year. The ISO 8601 date format yyyy-mm-dd is also accepted. For example: zip -rtt 11301995 infamy foo zip -rtt 1995-11-30 infamy foo will add all the files in foo and its subdirectories that were last modified before 30 November 1995, to the zip archive infamy.zip.;NONE;7
zip;package and compress (archive) files;-T, --test;Test the integrity of the new zip file. If the check fails, the old zip file is unchanged and (with the -m option) no input files are removed.;NONE;0
zip;package and compress (archive) files;-TT cmd;--unzip-command cmd Use command cmd instead of 'unzip -tqq' to test an archive when the -T option is used.;NONE;1
zip;package and compress (archive) files;-u, --update;Replace (update) an existing entry in the zip archive only if it has been modified more recently than the version already in the zip archive. For example: zip -u stuff * will add any new files in the current directory, and update any files which have been modified since the zip archive stuff.zip was last created/modified (note that zip will not try to pack stuff.zip into itself when you do this). Note that the -u option with no input file arguments acts like the -f (freshen) option.;NONE;7
zip;package and compress (archive) files;-U, --copy-entries;Copy entries from one archive to another. Requires the --out option to specify a different output file than the input archive. Copy mode is the reverse of -d delete. When delete is being used with --out, the selected entries are deleted from the archive and all other entries are copied to the new archive, while copy mode selects the files to include in the new archive. Unlike -u update, input patterns on the command line are matched against archive entries only and not the file system files. For instance, zip inarchive "*.c" --copy --out outarchive copies entries with names ending in .c from inarchive to outarchive. The wildcard must be escaped on some systems to prevent the shell from substituting names of files from the file system which may have no relevance to the entries in the archive. If no input files appear on the command line and --out is used, copy mode is assumed: zip inarchive --out outarchive This is useful for changing split size for instance. Encrypting and decrypting entries is not yet supported using copy mode. Use zipcloak for that.;NONE;0
zip;package and compress (archive) files;-UN v;--unicode v Determine what zip should do with Unicode file names. zip 3.0, in addition to the standard file path, now includes the UTF-8 translation of the path if the entry path is not entirely 7-bit ASCII. When an entry is missing the Unicode path, zip reverts back to the standard file path. The problem with using the standard path is this path is in the local character set of the zip that created the entry, which may contain characters that are not valid in the character set being used by the unzip. When zip is reading an archive, if an entry also has a Unicode path, zip now defaults to using the Unicode path to recreate the standard path using the current local character set.;NONE;0
zip;package and compress (archive) files;-v, --verbose;Verbose mode or print diagnostic version info. Normally, when applied to real operations, this option enables the display of a progress indicator during compression (see -dd for more on dots) and requests verbose diagnostic info about zipfile structure oddities. However, when -v is the only command line argument a diagnostic screen is printed instead. This should now work even if stdout is redirected to a file, allowing easy saving of the information for sending with bug reports to Info-ZIP. The version screen provides the help screen header with program name, version, and release date, some pointers to the Info-ZIP home and distribution sites, and shows information about the target environment (compiler type and version, OS version, compilation date and the enabled optional features used to create the zip executable).;NONE;0
zip;package and compress (archive) files;-V, --VMS-portable;[VMS] Save VMS file attributes. (Files are truncated at EOF.) When a -V archive is unpacked on a non-VMS system, some file types (notably Stream_LF text files and pure binary files like fixed-512) should be extracted intact. Indexed files and file types with embedded record sizes (notably variable-length record types) will probably be seen as corrupt elsewhere.;NONE;7
zip;package and compress (archive) files;-VV, --VMS-specific;[VMS] Save VMS file attributes, and all allocated blocks in a file, including any data beyond EOF. Useful for moving ill-formed files among VMS systems. When a -VV archive is unpacked on a non-VMS system, almost all files will appear corrupt.;NONE;7
zip;package and compress (archive) files;-w, --VMS-versions;[VMS] Append the version number of the files to the name, including multiple versions of files. Default is to use only the most recent version of a specified file.;NONE;7
zip;package and compress (archive) files;-ww, --VMS-dot-versions;[VMS] Append the version number of the files to the name, including multiple versions of files, using the .nnn format. Default is to use only the most recent version of a specified file.;NONE;7
zip;package and compress (archive) files;-ws, --wild-stop-dirs;Wildcards match only at a directory level.;NONE;0
zip;package and compress (archive) files;-x files;--exclude files Explicitly exclude the specified files, as in: zip -r foo foo -x \*.o which will include the contents of foo in foo.zip while excluding all the files that end in .o. The backslash avoids the shell filename substitution, so that the name matching is performed by zip at all directory levels. Also possible: zip -r foo foo -x@exclude.lst which will include the contents of foo in foo.zip while excluding all the files that match the patterns in the file exclude.lst. The long option forms of the above are zip -r foo foo --exclude \*.o and zip -r foo foo --exclude @exclude.lst Multiple patterns can be specified, as in: zip -r foo foo -x \*.o \*.c If there is no space between -x and the pattern, just one value is assumed (no list): zip -r foo foo -x\*.o See -i for more on include and exclude.;NONE;0
zip;package and compress (archive) files;-X, --no-extra;Do not save extra file attributes (Extended Attributes on OS/2, uid/gid and file times on Unix). The zip format uses extra fields to include additional information for each entry. Some extra fields are specific to particular systems while others are applicable to all systems. Normally when zip reads entries from an existing archive, it reads the extra fields it knows, strips the rest, and adds the extra fields applicable to that system. With -X, zip strips all old fields and only includes the Unicode and Zip64 extra fields (currently these two extra fields cannot be disabled).;NONE;0
zip;package and compress (archive) files;-y, --symlinks;For UNIX and VMS (V8.3 and later), store symbolic links as such in the zip archive, instead of compressing and storing the file referred to by the link. This can avoid multiple copies of files being included in the archive as zip recurses the directory trees and accesses files directly and by links.;NONE;0
zip;package and compress (archive) files;-z, --archive-comment;Prompt for a multi-line comment for the entire zip archive. The comment is ended by a line containing just a period, or an end of file condition (^D on Unix, ^Z on MSDOS, OS/2, and VMS). The comment can be taken from a file: zip -z foo < foowhat;NONE;3
zip;package and compress (archive) files;-Z cm;--compression-method cm Set the default compression method.;NONE;0
zip;package and compress (archive) files;-#;Regulate the speed of compression using the specified digit #, where -0 indicates no compression (store all files), -1 indicates the fastest compression speed (less compression) and -9 indicates the slowest compression speed (optimal compression, ignores the suffix list). The default compression level is -6. Though still being worked, the intention is this setting will control compression speed for all compression methods. Currently only deflation is controlled.;NONE;0
zip;package and compress (archive) files;-!, --use-privileges;[WIN32] Use privileges (if granted) to obtain all aspects of WinNT security.;NONE;0
zip;package and compress (archive) files;-@, --names-stdin;Take the list of input files from standard input. Only one filename per line.;NONE;0
zip;package and compress (archive) files;-$, --volume-label;[MSDOS, OS/2, WIN32] Include the volume label for the drive holding the first file to be compressed.;NONE;7
whois;client for the whois directory service;whois;client for the whois directory service;NONE;5
whois;client for the whois directory service;-H;Do not display the legal disclaimers that some registries like to show you.;NONE;0
whois;client for the whois directory service;-p PORT, --port=PORT;Connect to PORT.;NONE;5
whois;client for the whois directory service;-I;First query whois.iana.org and then follow its referral to the whois server authoritative for that request. This works for IP addresses, AS numbers and domains. BEWARE: this implies that the IANA server will receive your complete query.;NONE;0
whois;client for the whois directory service;--verbose;Be verbose.;NONE;0
whois;client for the whois directory service;--help;Display online help.;NONE;0
whois;client for the whois directory service;--version;Display the program version. Other options are flags understood by whois.ripe.net and some other RIPE-like servers:;NONE;0
whois;client for the whois directory service;-a;Also search all the mirrored databases.;NONE;0
whois;client for the whois directory service;-b;Return brief IP address ranges with abuse contact.;NONE;0
whois;client for the whois directory service;-B;Disable objects filtering. (Show the e-mail addresses.);NONE;0
whois;client for the whois directory service;-c;Return the smallest IP address range with a reference to an irt object.;NONE;0
whois;client for the whois directory service;-d;Return the reverse DNS delegation object too.;NONE;0
whois;client for the whois directory service;-g SOURCE:FIRST-LAST;Search updates from SOURCE database between FIRST and LAST update serial number. It is useful to obtain Near Real Time Mirroring stream.;NONE;0
whois;client for the whois directory service;-G;Disable grouping of associated objects.;NONE;0
whois;client for the whois directory service;-i ATTR[,ATTR];Inverse-search objects having associated attributes. ATTR is the attribute name, while the positional OBJECT argument is the attribute value.;NONE;0
whois;client for the whois directory service;-K;Return primary key attributes only. An exception is the members attribute of set objects, which is always returned. Another exception are all attributes of the objects organisation, person and role, that are never returned.;NONE;0
whois;client for the whois directory service;-l;Return the one level less specific object.;NONE;0
whois;client for the whois directory service;-L;Return all levels of less specific objects.;NONE;0
whois;client for the whois directory service;-m;Return all one level more specific objects.;NONE;0
whois;client for the whois directory service;-M;Return all levels of more specific objects.;NONE;0
whois;client for the whois directory service;-q KEYWORD;Return information about the server. KEYWORD can be version for the server version, sources for the list of database sources or types for the list of supported object types.;NONE;5
whois;client for the whois directory service;-r;Disable recursive lookups for contact information.;NONE;0
whois;client for the whois directory service;-R;Disable following referrals and force showing the object from the local copy in the server.;NONE;0
whois;client for the whois directory service;-s SOURCE[,SOURCE]...;Request the server to search for objects mirrored from SOURCE. Sources are delimited by comma, and the order is significant. Use the -q sources parameter to obtain a list of valid sources.;NONE;0
whois;client for the whois directory service;-t TYPE;Return the template for a object of TYPE.;NONE;5
whois;client for the whois directory service;-T TYPE[,TYPE]...;Restrict the search to objects of TYPE. Multiple types are separated by a comma.;NONE;5
whois;client for the whois directory service;-v TYPE;Return the verbose template for a object of TYPE.;NONE;5
whois;client for the whois directory service;-x;Search for only exact match on network address prefix.;NONE;0
ls;list directory contents;ls;list directory contents;NONE;7
ls;list directory contents;-a, --all;do not ignore entries starting with .;NONE;7
ls;list directory contents;-A, --almost-all;do not list implied . and ..;NONE;0
ls;list directory contents;--author;with -l, print the author of each file;NONE;7
ls;list directory contents;-b, --escape;print C-style escapes for nongraphic characters ;NONE;0
ls;list directory contents;--block-size=SIZE;with -l, scale sizes by SIZE when printing them. e.g., '--block-size=M'. see SIZE format below;NONE;0
ls;list directory contents;-B, --ignore-backups;do not list implied entries ending with ~ ;NONE;0
ls;list directory contents;-c;with -lt: sort by, and show, ctime (time of last modification of file status information). with -l: show ctime and sort by name. otherwise: sort by ctime, newest first;NONE;7
ls;list directory contents;-C;list entries by columns;NONE;0
ls;list directory contents;--color[=WHEN];color the output WHEN. more info below;NONE;0
ls;list directory contents;-d, --directory;list directories themselves, not their contents;NONE;0
ls;list directory contents;-D, --dired;generate output designed for Emacs' dired mode;NONE;0
ls;list directory contents;-f;list all entries in directory order;NONE;0
ls;list directory contents;-F, --classify[=WHEN];append indicator (one of */=>@|) to entries WHEN;NONE;0
ls;list directory contents;--file-type;likewise, except do not append '*';NONE;0
ls;list directory contents;--format=WORD;across -x, commas -m, horizontal -x, long -l, single-column -1, verbose -l, vertical -C;NONE;0
ls;list directory contents;--full-time;like -l --time-style=full-iso;NONE;7
ls;list directory contents;-g;like -l, but do not list owner;NONE;7
ls;list directory contents;--group-directories-first;group directories before files. can be augmented with a --sort option, but any use of --sort=none (-U) disables grouping;NONE;0
ls;list directory contents;-G, --no-group;in a long listing, don't print group names;NONE;0
ls;list directory contents;-h, --human-readable;with -l and -s, print sizes like 1K 234M 2G etc.;NONE;0
ls;list directory contents;--si;likewise, but use powers of 1000 not 1024;NONE;0
ls;list directory contents;-H, --dereference-command-line;follow symbolic links listed on the command line ;NONE;7
ls;list directory contents;--dereference-command-line-symlink-to-dir;follow each command line symbolic link that points to a directory;NONE;7
ls;list directory contents;--hide=PATTERN;do not list implied entries matching shell PATTERN (overridden by -a or -A);NONE;0
ls;list directory contents;--hyperlink[=WHEN];hyperlink file names WHEN;NONE;0
ls;list directory contents;--indicator-style=WORD;append indicator with style WORD to entry names: none (default), slash (-p), file-type (--file-type), classify (-F);NONE;7
ls;list directory contents;-i, --inode;print the index number of each file;NONE;7
ls;list directory contents;-I, --ignore=PATTERN;do not list implied entries matching shell PATTERN;NONE;0
ls;list directory contents;-k, --kibibytes;default to 1024-byte blocks for file system usage. used only with -s and per directory totals;NONE;0
ls;list directory contents;-l;use a long listing format ;NONE;7
ls;list directory contents;-L, --dereference;when showing file information for a symbolic link, show information for the file the link references rather than for the link itself;NONE;7
ls;list directory contents;-m;fill width with a comma separated list of entries;NONE;0
ls;list directory contents;-n, --numeric-uid-gid;like -l, but list numeric user and group IDs;NONE;6
ls;list directory contents;-n, --numeric-uid-gid;like -l, but list numeric user and group IDs;NONE;7
ls;list directory contents;-N, --literal;print entry names without quoting;NONE;0
ls;list directory contents;-o;like -l, but do not list group information ;NONE;0
ls;list directory contents;-p, --indicator-style=slash;append / indicator to directories;NONE;7
ls;list directory contents;-q, --hide-control-chars;print ? instead of nongraphic characters;NONE;0
ls;list directory contents;--show-control-chars;show nongraphic characters as-is (the default, unless program is 'ls' and output is a terminal);NONE;0
ls;list directory contents;-Q, --quote-name;enclose entry names in double quotes;NONE;0
ls;list directory contents;--quoting-style=WORD;use quoting style WORD for entry names: literal, locale, shell, shell-always, shell-escape, shell-escape-always, c, escape (overrides QUOTING_STYLE environment variable) ;NONE;0
ls;list directory contents;-r, --reverse;reverse order while sorting;NONE;0
ls;list directory contents;-R, --recursive;list subdirectories recursively;NONE;7
ls;list directory contents;-s, --size;print the allocated size of each file, in blocks;NONE;7
ls;list directory contents;-S;sort by file size, largest first;NONE;0
ls;list directory contents;--sort=WORD;sort by WORD instead of name: none (-U), size (-S), time (-t), version (-v), extension (-X), width;NONE;0
ls;list directory contents;--time=WORD;change the default of using modification times. access time (-u): atime, access, use. change time (-c): ctime, status. birth time: birth, creation. with -l, WORD determines which time to show. with --sort=time, sort by WORD (newest first);NONE;7
ls;list directory contents;--time-style=TIME_STYLE;time/date format with -l. see TIME_STYLE below;NONE;0
ls;list directory contents;-t;sort by time, newest first. see --time;NONE;0
ls;list directory contents;-T, --tabsize=COLS;assume tab stops at each COLS instead of 8;NONE;0
ls;list directory contents;-u;with -lt: sort by, and show, access time. with -l: show access time and sort by name. otherwise: sort by access time, newest first;NONE;7
ls;list directory contents;-U;do not sort. list entries in directory order;NONE;0
ls;list directory contents;-v;natural sort of (version) numbers within text;NONE;0
ls;list directory contents;-w, --width=COLS;set output width to COLS. 0 means no limit;NONE;0
ls;list directory contents;-x;list entries by lines instead of by columns ;NONE;0
ls;list directory contents;-X;sort alphabetically by entry extension ;NONE;0
ls;list directory contents;-Z, --context;print any security context of each file;NONE;7
ls;list directory contents;--zero;end each output line with NUL, not newline;NONE;0
ls;list directory contents;-1;list one file per line;NONE;0
ls;list directory contents;--help;display this help and exit;NONE;0
ls;list directory contents;--version;output version information and exit;NONE;0
ab;ab is a tool for benchmarking your Apache Hypertext Transfer Protocol (HTTP) server. It is designed to give you an impression of how your current Apache installation performs. This especially shows you how many requests per second your Apache installation is capable of serving.;ab;ab is a tool for benchmarking your Apache Hypertext Transfer Protocol (HTTP) server. It is designed to give you an impression of how your current Apache installation performs. This especially shows you how many requests per second your Apache installation is capable of serving.;NONE;5
ab;ab is a tool for benchmarking your Apache Hypertext Transfer Protocol (HTTP) server. It is designed to give you an impression of how your current Apache installation performs. This especially shows you how many requests per second your Apache installation is capable of serving.;-A auth-username:password;Supply BASIC Authentication credentials to the server. The username and password are separated by a single : and sent on the wire base64 encoded. The string is sent regardless of whether the server needs it (i.e., has sent an 401 authentication needed).;NONE;5
ab;ab is a tool for benchmarking your Apache Hypertext Transfer Protocol (HTTP) server. It is designed to give you an impression of how your current Apache installation performs. This especially shows you how many requests per second your Apache installation is capable of serving.;-b windowsize;Size of TCP send/receive buffer, in bytes.;NONE;0
ab;ab is a tool for benchmarking your Apache Hypertext Transfer Protocol (HTTP) server. It is designed to give you an impression of how your current Apache installation performs. This especially shows you how many requests per second your Apache installation is capable of serving.;-B local-address;Address to bind to when making outgoing connections.;NONE;0
ab;ab is a tool for benchmarking your Apache Hypertext Transfer Protocol (HTTP) server. It is designed to give you an impression of how your current Apache installation performs. This especially shows you how many requests per second your Apache installation is capable of serving.;-c concurrency;Number of multiple requests to perform at a time. Default is one request at a time.;NONE;0
ab;ab is a tool for benchmarking your Apache Hypertext Transfer Protocol (HTTP) server. It is designed to give you an impression of how your current Apache installation performs. This especially shows you how many requests per second your Apache installation is capable of serving.;-C cookie-name=value;Add a Cookie: line to the request. The argument is typically in the form of a name=value pair. This field is repeatable.;NONE;5
ab;ab is a tool for benchmarking your Apache Hypertext Transfer Protocol (HTTP) server. It is designed to give you an impression of how your current Apache installation performs. This especially shows you how many requests per second your Apache installation is capable of serving.;-d;Do not display the "percentage served within XX [ms] table". (legacy support).;NONE;0
ab;ab is a tool for benchmarking your Apache Hypertext Transfer Protocol (HTTP) server. It is designed to give you an impression of how your current Apache installation performs. This especially shows you how many requests per second your Apache installation is capable of serving.;-e csv-file;Write a Comma separated value (CSV) file which contains for each percentage (from 1% to 100%) the time (in milliseconds) it took to serve that percentage of the requests. This is usually more useful than the 'gnu plot' file. as the results are already 'binned'.;NONE;0
ab;ab is a tool for benchmarking your Apache Hypertext Transfer Protocol (HTTP) server. It is designed to give you an impression of how your current Apache installation performs. This especially shows you how many requests per second your Apache installation is capable of serving.;-E client-certificate-file;When connecting to an SSL website, use the provided client certificate in PEM format to authenticate with the server. The file is expected to contain the client certificate, followed by intermediate certificates, followed by the private key. Available in 2.4.36 and later.;NONE;2
ab;ab is a tool for benchmarking your Apache Hypertext Transfer Protocol (HTTP) server. It is designed to give you an impression of how your current Apache installation performs. This especially shows you how many requests per second your Apache installation is capable of serving.;-E client-certificate-file;When connecting to an SSL website, use the provided client certificate in PEM format to authenticate with the server. The file is expected to contain the client certificate, followed by intermediate certificates, followed by the private key. Available in 2.4.36 and later.;NONE;5
ab;ab is a tool for benchmarking your Apache Hypertext Transfer Protocol (HTTP) server. It is designed to give you an impression of how your current Apache installation performs. This especially shows you how many requests per second your Apache installation is capable of serving.;-f protocol;Specify SSL/TLS protocol (SSL2, SSL3, TLS1, TLS1.1, TLS1.2, or ALL). TLS1.1 and TLS1.2 support available in 2.4.4 and later.;NONE;11
ab;ab is a tool for benchmarking your Apache Hypertext Transfer Protocol (HTTP) server. It is designed to give you an impression of how your current Apache installation performs. This especially shows you how many requests per second your Apache installation is capable of serving.;-g gnuplot-file;Write all measured values out as a 'gnuplot' or TSV (Tab separate values) file. This file can easily be im ported into packages like Gnuplot, IDL, Mathematica, Igor or even Excel. The labels are on the first line of the file.;NONE;3
ab;ab is a tool for benchmarking your Apache Hypertext Transfer Protocol (HTTP) server. It is designed to give you an impression of how your current Apache installation performs. This especially shows you how many requests per second your Apache installation is capable of serving.;-h;Display usage information.;NONE;0
ab;ab is a tool for benchmarking your Apache Hypertext Transfer Protocol (HTTP) server. It is designed to give you an impression of how your current Apache installation performs. This especially shows you how many requests per second your Apache installation is capable of serving.;-H custom-header;Append extra headers to the request. The argument is typically in the form of a valid header line, contain ing a colon-separated field-value pair (i.e., "Accept-Encoding: zip/zop.8bit").;NONE;5
ab;ab is a tool for benchmarking your Apache Hypertext Transfer Protocol (HTTP) server. It is designed to give you an impression of how your current Apache installation performs. This especially shows you how many requests per second your Apache installation is capable of serving.;-i;Do HEAD requests instead of GET.;NONE;11
ab;ab is a tool for benchmarking your Apache Hypertext Transfer Protocol (HTTP) server. It is designed to give you an impression of how your current Apache installation performs. This especially shows you how many requests per second your Apache installation is capable of serving.;-k;Enable the HTTP KeepAlive feature, i.e., perform multiple requests within one HTTP session. Default is no KeepAlive.;NONE;11
ab;ab is a tool for benchmarking your Apache Hypertext Transfer Protocol (HTTP) server. It is designed to give you an impression of how your current Apache installation performs. This especially shows you how many requests per second your Apache installation is capable of serving.;-l;Do not report errors if the length of the responses is not constant. This can be useful for dynamic pages. Available in 2.4.7 and later.;NONE;0
ab;ab is a tool for benchmarking your Apache Hypertext Transfer Protocol (HTTP) server. It is designed to give you an impression of how your current Apache installation performs. This especially shows you how many requests per second your Apache installation is capable of serving.;-m HTTP-method;Custom HTTP method for the requests. Available in 2.4.10 and later.;NONE;5
ab;ab is a tool for benchmarking your Apache Hypertext Transfer Protocol (HTTP) server. It is designed to give you an impression of how your current Apache installation performs. This especially shows you how many requests per second your Apache installation is capable of serving.;-n requests;Number of requests to perform for the benchmarking session. The default is to just perform a single request which usually leads to non-representative benchmarking results.;NONE;11
ab;ab is a tool for benchmarking your Apache Hypertext Transfer Protocol (HTTP) server. It is designed to give you an impression of how your current Apache installation performs. This especially shows you how many requests per second your Apache installation is capable of serving.;-p POST-file;File containing data to POST. Remember to also set -T.;NONE;2
ab;ab is a tool for benchmarking your Apache Hypertext Transfer Protocol (HTTP) server. It is designed to give you an impression of how your current Apache installation performs. This especially shows you how many requests per second your Apache installation is capable of serving.;-p POST-file;File containing data to POST. Remember to also set -T.;NONE;5
ab;ab is a tool for benchmarking your Apache Hypertext Transfer Protocol (HTTP) server. It is designed to give you an impression of how your current Apache installation performs. This especially shows you how many requests per second your Apache installation is capable of serving.;-P proxy-auth-username:password;Supply BASIC Authentication credentials to a proxy en-route. The username and password are separated by a single : and sent on the wire base64 encoded. The string is sent regardless of whether the proxy needs it (i.e., has sent an 407 proxy authentication needed).;NONE;5
ab;ab is a tool for benchmarking your Apache Hypertext Transfer Protocol (HTTP) server. It is designed to give you an impression of how your current Apache installation performs. This especially shows you how many requests per second your Apache installation is capable of serving.;-q;When processing more than 150 requests, ab outputs a progress count on stderr every 10% or 100 requests or so. The -q flag will suppress these messages.;NONE;0
ab;ab is a tool for benchmarking your Apache Hypertext Transfer Protocol (HTTP) server. It is designed to give you an impression of how your current Apache installation performs. This especially shows you how many requests per second your Apache installation is capable of serving.;-r;Don't exit on socket receive errors.;NONE;0
ab;ab is a tool for benchmarking your Apache Hypertext Transfer Protocol (HTTP) server. It is designed to give you an impression of how your current Apache installation performs. This especially shows you how many requests per second your Apache installation is capable of serving.;-s timeout;Maximum number of seconds to wait before the socket times out. Default is 30 seconds. Available in 2.4.4 and later.;NONE;0
ab;ab is a tool for benchmarking your Apache Hypertext Transfer Protocol (HTTP) server. It is designed to give you an impression of how your current Apache installation performs. This especially shows you how many requests per second your Apache installation is capable of serving.;-S;Do not display the median and standard deviation values, nor display the warning/error messages when the av erage and median are more than one or two times the standard deviation apart. And default to the min/avg/max values. (legacy support).;NONE;0
ab;ab is a tool for benchmarking your Apache Hypertext Transfer Protocol (HTTP) server. It is designed to give you an impression of how your current Apache installation performs. This especially shows you how many requests per second your Apache installation is capable of serving.;-t timelimit;Maximum number of seconds to spend for benchmarking. This implies a -n 50000 internally. Use this to bench mark the server within a fixed total amount of time. Per default there is no timelimit.;NONE;0
ab;ab is a tool for benchmarking your Apache Hypertext Transfer Protocol (HTTP) server. It is designed to give you an impression of how your current Apache installation performs. This especially shows you how many requests per second your Apache installation is capable of serving.;-T content-type;Content-type header to use for POST/PUT data, eg. application/x-www-form-urlencoded. Default is text/plain.;NONE;5
ab;ab is a tool for benchmarking your Apache Hypertext Transfer Protocol (HTTP) server. It is designed to give you an impression of how your current Apache installation performs. This especially shows you how many requests per second your Apache installation is capable of serving.;-u PUT-file;File containing data to PUT. Remember to also set -T.;NONE;2
ab;ab is a tool for benchmarking your Apache Hypertext Transfer Protocol (HTTP) server. It is designed to give you an impression of how your current Apache installation performs. This especially shows you how many requests per second your Apache installation is capable of serving.;-u PUT-file;File containing data to PUT. Remember to also set -T.;NONE;5
ab;ab is a tool for benchmarking your Apache Hypertext Transfer Protocol (HTTP) server. It is designed to give you an impression of how your current Apache installation performs. This especially shows you how many requests per second your Apache installation is capable of serving.;-v verbosity;Set verbosity level - 4 and above prints information on headers, 3 and above prints response codes (404, 200, etc.), 2 and above prints warnings and info.;NONE;4
ab;ab is a tool for benchmarking your Apache Hypertext Transfer Protocol (HTTP) server. It is designed to give you an impression of how your current Apache installation performs. This especially shows you how many requests per second your Apache installation is capable of serving.;-V;Display version number and exit.;NONE;0
ab;ab is a tool for benchmarking your Apache Hypertext Transfer Protocol (HTTP) server. It is designed to give you an impression of how your current Apache installation performs. This especially shows you how many requests per second your Apache installation is capable of serving.;-w;Print out results in HTML tables. Default table is two columns wide, with a white background.;NONE;0
ab;ab is a tool for benchmarking your Apache Hypertext Transfer Protocol (HTTP) server. It is designed to give you an impression of how your current Apache installation performs. This especially shows you how many requests per second your Apache installation is capable of serving.;-x <table>-attributes;String to use as attributes for <table>. Attributes are inserted <table here >.;NONE;0
ab;ab is a tool for benchmarking your Apache Hypertext Transfer Protocol (HTTP) server. It is designed to give you an impression of how your current Apache installation performs. This especially shows you how many requests per second your Apache installation is capable of serving.;-X proxy[:port];Use a proxy server for the requests.;NONE;5
ab;ab is a tool for benchmarking your Apache Hypertext Transfer Protocol (HTTP) server. It is designed to give you an impression of how your current Apache installation performs. This especially shows you how many requests per second your Apache installation is capable of serving.;-y <tr>-attributes;String to use as attributes for <tr>.;NONE;0
ab;ab is a tool for benchmarking your Apache Hypertext Transfer Protocol (HTTP) server. It is designed to give you an impression of how your current Apache installation performs. This especially shows you how many requests per second your Apache installation is capable of serving.;-z <td>-attributes;String to use as attributes for <td>.;NONE;0
ab;ab is a tool for benchmarking your Apache Hypertext Transfer Protocol (HTTP) server. It is designed to give you an impression of how your current Apache installation performs. This especially shows you how many requests per second your Apache installation is capable of serving.;-Z ciphersuite;Specify SSL/TLS cipher suite (See openssl ciphers);NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;NONE;5
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--abstract-unix-socket <path>;(HTTP) Connect through an abstract Unix domain socket, instead of using the network. Note: netstat shows the path of an abstract socket prefixed with '@', however the <path> argument should not have this leading character.;NONE;3
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--abstract-unix-socket <path>;(HTTP) Connect through an abstract Unix domain socket, instead of using the network. Note: netstat shows the path of an abstract socket prefixed with '@', however the <path> argument should not have this leading character.;NONE;2
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--alt-svc <file name>;(HTTPS) This option enables the alt-svc parser in curl. If the file name points to an existing alt-svc cache file, that will be used. After a completed transfer, the cache will be saved to the file name again if it has been modified. Specify a "" file name (zero length) to avoid loading/saving and make curl just handle the cache in memory. If this option is used several times, curl will load contents from all the files but the last one will be used for saving.;NONE;3
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--anyauth;(HTTP) Tells curl to figure out authentication method by itself, and use the most secure one the remote site claims to support. This is done by first doing a request and checking the response-headers, thus possibly inducing an extra network round-trip. This is used instead of setting a specific authentication method, which you can do with --basic, --digest, --ntlm, and --negotiate. Using --anyauth is not recommended if you do uploads from stdin, since it may require data to be sent twice and then the client must be able to rewind. If the need should arise when uploading from stdin, the upload operation will fail. Used together with -u, --user.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-a, --append;(FTP SFTP) When used in an upload, this makes curl append to the target file instead of overwriting it. If the remote file does not exist, it will be created. Note that this flag is ignored by some SFTP servers (in cluding OpenSSH).;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--aws-sigv4 <provider1[:provider2[:region[:service]]]>;Use AWS V4 signature authentication in the transfer. The provider argument is a string that is used by the algorithm when creating outgoing authentication head ers. The region argument is a string that points to a geographic area of a resources collection (region-code) when the region name is omitted from the endpoint. The service argument is a string that points to a function provided by a cloud (service-code) when the ser vice name is omitted from the endpoint.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--basic;(HTTP) Tells curl to use HTTP Basic authentication with the remote host. This is the default and this option is usually pointless, unless you use it to override a previously set option that sets a different authenti cation method (such as --ntlm, --digest, or --negotiate). Used together with -u, --user.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--cacert <file>;(TLS) Tells curl to use the specified certificate file to verify the peer. The file may contain multiple CA certificates. The certificate(s) must be in PEM format. Normally curl is built to use a default file for this, so this option is typically used to alter that default file. curl recognizes the environment variable named 'CURL_CA_BUNDLE' if it is set, and uses the given path as a path to a CA cert bundle. This option overrides that variable. The windows version of curl will automatically look for a CA certs file named 'curl-ca-bundle.crt', either in the same directory as curl.exe, or in the Current Working Directory, or in any folder along your PATH. If curl is built against the NSS SSL library, the NSS PEM PKCS#11 module (libnsspem.so) needs to be avail able for this option to work properly. (iOS and macOS only) If curl is built against Secure Transport, then this option is supported for backward compatibility with other SSL engines, but it should not be set. If the option is not set, then curl will use the certificates in the system and user Keychain to verify the peer, which is the preferred method of veri fying the peer's certificate chain. (Schannel only) This option is supported for Schannel in Windows 7 or later with libcurl 7.60 or later. This option is supported for backward compatibility with other SSL engines. instead it is recommended to use Win dows' store of root certificates (the default for Schannel). If this option is used several times, the last one will be used.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--capath <dir>;(TLS) Tells curl to use the specified certificate directory to verify the peer. Multiple paths can be pro vided by separating them with ":" (e.g. "path1:path2:path3"). The certificates must be in PEM format, and if curl is built against OpenSSL, the directory must have been processed using the c_rehash utility supplied with OpenSSL. Using --capath can allow OpenSSL-powered curl to make SSL-connections much more efficiently than using --cacert if the --cacert file contains many CA certificates. If this option is set, the default capath value will be ignored, and if it is used several times, the last one will be used.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--cert-status;(TLS) Tells curl to verify the status of the server certificate by using the Certificate Status Request (aka. OCSP stapling) TLS extension. If this option is enabled and the server sends an invalid (e.g. expired) response, if the response suggests that the server certificate has been revoked, or no response at all is received, the verification fails. This is currently only implemented in the OpenSSL, GnuTLS and NSS backends.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--cert-type <type>;(TLS) Tells curl what type the provided client certificate is using. PEM, DER, ENG and P12 are recognized types. If not specified, PEM is assumed. If this option is used several times, the last one will be used.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-E, --cert <certificate[:password]>;(TLS) Tells curl to use the specified client certificate file when getting a file with HTTPS, FTPS or an other SSL-based protocol. The certificate must be in PKCS#12 format if using Secure Transport, or PEM format if using any other engine. If the optional password is not specified, it will be queried for on the termi nal. Note that this option assumes a "certificate" file that is the private key and the client certificate concatenated! See -E, --cert and --key to specify them independently. If curl is built against the NSS SSL library then this option can tell curl the nickname of the certificate to use within the NSS database defined by the environment variable SSL_DIR (or by default /etc/pki/nssdb). If the NSS PEM PKCS#11 module (libnsspem.so) is available then PEM files may be loaded. If you want to use a file from the current directory, please precede it with "./" prefix, in order to avoid confusion with a nickname. If the nickname contains ":", it needs to be preceded by "\" so that it is not recognized as pass word delimiter. If the nickname contains "\", it needs to be escaped as "\\" so that it is not recognized as an escape character. If curl is built against OpenSSL library, and the engine pkcs11 is available, then a PKCS#11 URI (RFC 7512) can be used to specify a certificate located in a PKCS#11 device. A string beginning with "pkcs11:" will be interpreted as a PKCS#11 URI. If a PKCS#11 URI is provided, then the --engine option will be set as "pkcs11" if none was provided and the --cert-type option will be set as "ENG" if none was provided. (iOS and macOS only) If curl is built against Secure Transport, then the certificate string can either be the name of a certificate/private key in the system or user keychain, or the path to a PKCS#12-encoded cer tificate and private key. If you want to use a file from the current directory, please precede it with "./" prefix, in order to avoid confusion with a nickname. (Schannel only) Client certificates must be specified by a path expression to a certificate store. (Loading PFX is not supported. you can import it to a store first). You can use "<store location>\<store name>\<thumbprint>" to refer to a certificate in the system certificates store, for example, "Curren tUser\MY\934a7ac6f8a5d579285a74fa61e19f23ddfe8d7a". Thumbprint is usually a SHA-1 hex string which you can see in certificate details. Following store locations are supported: CurrentUser, LocalMachine, CurrentSer vice, Services, CurrentUserGroupPolicy, LocalMachineGroupPolicy, LocalMachineEnterprise. If this option is used several times, the last one will be used.;NONE;2
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--ciphers <list of ciphers>;(TLS) Specifies which ciphers to use in the connection. The list of ciphers must specify valid ciphers. Read up on SSL cipher list details on this URL: https://curl.se/docs/ssl-ciphers.html If this option is used several times, the last one will be used.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--compressed-ssh;(SCP SFTP) Enables built-in SSH compression. This is a request, not an order. the server may or may not do it.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--compressed;(HTTP) Request a compressed response using one of the algorithms curl supports, and automatically decompress the content. Headers are not modified. If this option is used and the server sends an unsupported encoding, curl will report an error. This is a request, not an order. the server may or may not deliver data compressed.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-K, --config <file>;Specify a text file to read curl arguments from. The command line arguments found in the text file will be used as if they were provided on the command line. Options and their parameters must be specified on the same line in the file, separated by whitespace, colon, or the equals sign. Long option names can optionally be given in the config file without the initial double dashes and if so, the colon or equals characters can be used as separators. If the option is specified with one or two dashes, there can be no colon or equals character between the option and its parameter. If the parameter contains whitespace (or starts with : or =), the parameter must be enclosed within quotes. Within double quotes, the following escape sequences are available: \\, \", \t, \n, \r and \v. A backslash preceding any other letter is ignored. If the first column of a config line is a '#' character, the rest of the line will be treated as a comment. Only write one option per physical line in the config file. Specify the filename to -K, --config as '-' to make curl read the file from stdin.;NONE;10
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--connect-timeout <fractional seconds>;Maximum time in seconds that you allow curl's connection to take. This only limits the connection phase, so if curl connects within the given period it will continue - if not it will exit. Since version 7.32.0, this option accepts decimal values. If this option is used several times, the last one will be used.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--connect-to <HOST1:PORT1:HOST2:PORT2>;For a request to the given HOST1:PORT1 pair, connect to HOST2:PORT2 instead. This option is suitable to di rect requests at a specific server, e.g. at a specific cluster node in a cluster of servers. This option is only used to establish the network connection. It does NOT affect the hostname/port that is used for TLS/SSL (e.g. SNI, certificate verification) or for the application protocols. "HOST1" and "PORT1" may be the empty string, meaning "any host/port". "HOST2" and "PORT2" may also be the empty string, meaning "use the re quest's original host/port". A "host" specified to this option is compared as a string, so it needs to match the name used in request URL. It can be either numerical such as "127.0.0.1" or the full host name such as "example.org". This option can be used many times to add many connect rules.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-C, --continue-at <offset>;Continue/Resume a previous file transfer at the given offset. The given offset is the exact number of bytes that will be skipped, counting from the beginning of the source file before it is transferred to the desti nation. If used with uploads, the FTP server command SIZE will not be used by curl. Use "-C -" to tell curl to automatically find out where/how to resume the transfer. It then uses the given output/input files to figure that out. If this option is used several times, the last one will be used.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-c, --cookie-jar <filename>;(HTTP) Specify to which file you want curl to write all cookies after a completed operation. Curl writes all cookies from its in-memory cookie storage to the given file at the end of operations. If no cookies are known, no data will be written. The file will be written using the Netscape cookie file format. If you set the file name to a single dash, "-", the cookies will be written to stdout. This command line option will activate the cookie engine that makes curl record and use cookies. Another way to activate it is to use the -b, --cookie option. If the cookie jar cannot be created or written to, the whole curl operation will not fail or even report an error clearly. Using -v, --verbose will get a warning displayed, but that is the only visible feedback you get about this possibly lethal situation. If this option is used several times, the last specified file name will be used.;NONE;3
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-b, --cookie <data|filename>;(HTTP) Pass the data to the HTTP server in the Cookie header. It is supposedly the data previously received from the server in a "Set-Cookie:" line. The data should be in the format "NAME1=VALUE1. NAME2=VALUE2". If no '=' symbol is used in the argument, it is instead treated as a filename to read previously stored cookie from. This option also activates the cookie engine which will make curl record incoming cookies, which may be handy if you are using this in combination with the -L, --location option or do multiple URL transfers on the same invoke. If the file name is exactly a minus ("-"), curl will instead read the contents from stdin. The file format of the file to read cookies from should be plain HTTP headers (Set-Cookie style) or the Net scape/Mozilla cookie file format. The file specified with -b, --cookie is only used as input. No cookies will be written to the file. To store cookies, use the -c, --cookie-jar option. If you use the Set-Cookie file format and do not specify a domain then the cookie is not sent since the do main will never match. To address this, set a domain in Set-Cookie line (doing that will include sub-do mains) or preferably: use the Netscape format. This option can be used multiple times. Users often want to both read cookies from a file and write updated cookies back to a file, so using both -b, --cookie and -c, --cookie-jar in the same command line is common.;NONE;5
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-b, --cookie <data|filename>;(HTTP) Pass the data to the HTTP server in the Cookie header. It is supposedly the data previously received from the server in a "Set-Cookie:" line. The data should be in the format "NAME1=VALUE1. NAME2=VALUE2". If no '=' symbol is used in the argument, it is instead treated as a filename to read previously stored cookie from. This option also activates the cookie engine which will make curl record incoming cookies, which may be handy if you are using this in combination with the -L, --location option or do multiple URL transfers on the same invoke. If the file name is exactly a minus ("-"), curl will instead read the contents from stdin. The file format of the file to read cookies from should be plain HTTP headers (Set-Cookie style) or the Net scape/Mozilla cookie file format. The file specified with -b, --cookie is only used as input. No cookies will be written to the file. To store cookies, use the -c, --cookie-jar option. If you use the Set-Cookie file format and do not specify a domain then the cookie is not sent since the do main will never match. To address this, set a domain in Set-Cookie line (doing that will include sub-do mains) or preferably: use the Netscape format. This option can be used multiple times. Users often want to both read cookies from a file and write updated cookies back to a file, so using both -b, --cookie and -c, --cookie-jar in the same command line is common.;NONE;2
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--create-dirs;When used in conjunction with the -o, --output option, curl will create the necessary local directory hier archy as needed. This option creates the directories mentioned with the -o, --output option, nothing else. If the --output file name uses no directory, or if the directories it mentions already exist, no directories will be created. Created dirs are made with mode 0750 on unix style file systems. To create remote directories when using FTP or SFTP, try --ftp-create-dirs.;NONE;9
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--create-file-mode <mode>;(SFTP SCP FILE) When curl is used to create files remotely using one of the supported protocols, this option allows the user to set which 'mode' to set on the file at creation time, instead of the default 0644. This option takes an octal number as argument. If this option is used several times, the last one will be used.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--crlf;(FTP SMTP) Convert LF to CRLF in upload. Useful for MVS (OS/390). (SMTP added in 7.40.0);NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--crlfile <file>;(TLS) Provide a file using PEM format with a Certificate Revocation List that may specify peer certificates that are to be considered revoked. If this option is used several times, the last one will be used.;NONE;2
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--curves <algorithm list>;(TLS) Tells curl to request specific curves to use during SSL session establishment according to RFC 8422, 5.1. Multiple algorithms can be provided by separating them with ":" (e.g. "X25519:P-521"). The parameter is available identically in the "openssl s_client/s_server" utilities. --curves allows a OpenSSL powered curl to make SSL-connections with exactly the (EC) curve requested by the client, avoiding nontransparent client/server negotiations. If this option is set, the default curves list built into openssl will be ignored.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--data-ascii <data>;(HTTP) This is just an alias for -d, --data.;NONE;5
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--data-binary <data>;(HTTP) This posts data exactly as specified with no extra processing whatsoever. If you start the data with the letter @, the rest should be a filename. Data is posted in a similar manner as -d, --data does, except that newlines and carriage returns are preserved and conversions are never done. Like -d, --data the default content-type sent to the server is application/x-www-form-urlencoded. If you want the data to be treated as arbitrary binary data by the server then set the content-type to octet- stream: -H "Content-Type: application/octet-stream". If this option is used several times, the ones following the first will append data as described in -d, --data.;NONE;5
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--data-raw <data>;(HTTP) This posts data similarly to -d, --data but without the special interpretation of the @ character.;NONE;5
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--data-urlencode <data>;(HTTP) This posts data, similar to the other -d, --data options with the exception that this performs URL- encoding. To be CGI-compliant, the <data> part should begin with a name followed by a separator and a content specifi cation. The <data> part can be passed to curl using one of the following syntaxes: content This will make curl URL-encode the content and pass that on. Just be careful so that the content does not contain any = or @ symbols, as that will then make the syntax match one of the other cases below! =content This will make curl URL-encode the content and pass that on. The preceding = symbol is not included in the data. name=content This will make curl URL-encode the content part and pass that on. Note that the name part is expected to be URL-encoded already. @filename This will make curl load data from the given file (including any newlines), URL-encode that data and pass it on in the POST. name@filename This will make curl load data from the given file (including any newlines), URL-encode that data and pass it on in the POST. The name part gets an equal sign appended, resulting in name=urlencoded-file- content. Note that the name is expected to be URL-encoded already.;NONE;5
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-d, --data <data>;(HTTP MQTT) Sends the specified data in a POST request to the HTTP server, in the same way that a browser does when a user has filled in an HTML form and presses the submit button. This will cause curl to pass the data to the server using the content-type application/x-www-form-urlencoded. Compare to -F, --form. --data-raw is almost the same but does not have a special interpretation of the @ character. To post data purely binary, you should instead use the --data-binary option. To URL-encode the value of a form field you may use --data-urlencode. If any of these options is used more than once on the same command line, the data pieces specified will be merged with a separating &-symbol. Thus, using '-d name=daniel -d skill=lousy' would generate a post chunk that looks like 'name=daniel&skill=lousy'. If you start the data with the letter @, the rest should be a file name to read the data from, or - if you want curl to read the data from stdin. Posting data from a file named 'foobar' would thus be done with -d, --data @foobar. When -d, --data is told to read from a file like that, carriage returns and newlines will be stripped out. If you do not want the @ character to have a special interpretation use --data-raw instead.;NONE;5
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-d, --data <data>;(HTTP MQTT) Sends the specified data in a POST request to the HTTP server, in the same way that a browser does when a user has filled in an HTML form and presses the submit button. This will cause curl to pass the data to the server using the content-type application/x-www-form-urlencoded. Compare to -F, --form. --data-raw is almost the same but does not have a special interpretation of the @ character. To post data purely binary, you should instead use the --data-binary option. To URL-encode the value of a form field you may use --data-urlencode. If any of these options is used more than once on the same command line, the data pieces specified will be merged with a separating &-symbol. Thus, using '-d name=daniel -d skill=lousy' would generate a post chunk that looks like 'name=daniel&skill=lousy'. If you start the data with the letter @, the rest should be a file name to read the data from, or - if you want curl to read the data from stdin. Posting data from a file named 'foobar' would thus be done with -d, --data @foobar. When -d, --data is told to read from a file like that, carriage returns and newlines will be stripped out. If you do not want the @ character to have a special interpretation use --data-raw instead.;NONE;2
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--delegation <LEVEL>;(GSS/kerberos) Set LEVEL to tell the server what it is allowed to delegate when it comes to user creden tials. none Do not allow any delegation. policy Delegates if and only if the OK-AS-DELEGATE flag is set in the Kerberos service ticket, which is a matter of realm policy. always Unconditionally allow the server to delegate. If this option is used several times, the last one will be used.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--digest;(HTTP) Enables HTTP Digest authentication. This is an authentication scheme that prevents the password from being sent over the wire in clear text. Use this in combination with the normal -u, --user option to set user name and password. If this option is used several times, only the first one is used.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--disable-eprt;(FTP) Tell curl to disable the use of the EPRT and LPRT commands when doing active FTP transfers. Curl will normally always first attempt to use EPRT, then LPRT before using PORT, but with this option, it will use PORT right away. EPRT and LPRT are extensions to the original FTP protocol, and may not work on all servers, but they enable more functionality in a better way than the traditional PORT command. --eprt can be used to explicitly enable EPRT again and --no-eprt is an alias for --disable-eprt. If the server is accessed using IPv6, this option will have no effect as EPRT is necessary then. Disabling EPRT only changes the active behavior. If you want to switch to passive mode you need to not use -P, --ftp-port or force it with --ftp-pasv.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--disable-epsv;(FTP) Tell curl to disable the use of the EPSV command when doing passive FTP transfers. Curl will normally always first attempt to use EPSV before PASV, but with this option, it will not try using EPSV. --epsv can be used to explicitly enable EPSV again and --no-epsv is an alias for --disable-epsv. If the server is an IPv6 host, this option will have no effect as EPSV is necessary then. Disabling EPSV only changes the passive behavior. If you want to switch to active mode you need to use -P, --ftp-port.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-q, --disable;If used as the first parameter on the command line, the curlrc config file will not be read and used. See the -K, --config for details on the default config file search path.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--disallow-username-in-url;(HTTP) This tells curl to exit if passed a url containing a username. This is probably most useful when the URL is being provided at run-time or similar.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--fail-early;Fail and exit on the first detected transfer error. sequent successful transfers. tected by scripts and similar. This option is global and does not need to be specified for each use of -:, --next. contained by -:, --next.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--fail-with-body;(HTTP) Return an error on server errors where the HTTP response code is 400 or greater). In normal cases when an HTTP server fails to deliver a document, it returns an HTML document stating so (which often also describes why and more). This flag will still allow curl to output and save that content but also to return error 22. This is an alternative option to -f, --fail which makes curl fail for the same circumstances but without saving the content.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-f, --fail;(HTTP) Fail silently (no output at all) on server errors. This is mostly done to enable scripts etc to better deal with failed attempts. In normal cases when an HTTP server fails to deliver a docu ment, it returns an HTML document stating so (which often also describes why and more). This flag will prevent curl from outputting that and return error 22. This method is not fail-safe and there are occasions where non-successful response codes will slip through, especially when authentication is involved (response codes 401 and 407).;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--false-start;(TLS) Tells curl to use false start during the TLS handshake. False start is a mode where a TLS client will start sending application data before verifying the server's Finished message, thus sav ing a round trip when performing a full handshake. This is currently only implemented in the NSS and Secure Transport (on iOS 7.0 or later, or OS X 10.9 or later) backends.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--form-escape;(HTTP) Tells curl to pass on names of multipart form fields and files using backslash-escaping in stead of percent-encoding.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--form-string <name=string>;(HTTP SMTP IMAP) Similar to -F, --form except that the value string for the named parameter is used literally. Leading '@' and '<' characters, and the '.type=' string in the value have no special meaning. Use this in preference to -F, --form if there's any possibility that the string value may accidentally trigger the '@' or '<' features of -F, --form.;NONE;5
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-F, --form <name=content>;(HTTP SMTP IMAP) For HTTP protocol family, this lets curl emulate a filled-in form in which a user has pressed the submit button. This causes curl to POST data using the Content-Type multipart/form- data according to RFC 2388. For SMTP and IMAP protocols, this is the means to compose a multipart mail message to transmit. This enables uploading of binary files etc. To force the 'content' part to be a file, prefix the file name with an @ sign. To just get the content part from a file, prefix the file name with the symbol <. The difference between @ and < is then that @ makes a file get attached in the post as a file upload, while the < makes a text field and just get the contents for that text field from a file. Tell curl to read content from stdin instead of a file by using - as filename. This goes for both @ and < constructs. When stdin is used, the contents is buffered in memory first by curl to determine its size and allow a possible resend. Defining a part's data from a named non-regular file (such as a named pipe or similar) is unfortunately not subject to buffering and will be effectively read at transmission time. since the full size is unknown before the transfer starts, such data is sent as chunks by HTTP and rejected by IMAP.;NONE;5
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--ftp-account <data>;(FTP) When an FTP server asks for "account data" after user name and password has been provided, this data is sent off using the ACCT command. If this option is used several times, the last one will be used.;NONE;5
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--ftp-alternative-to-user <command>;(FTP) If authenticating with the USER and PASS commands fails, send this command. When connecting to Tumbleweed's Secure Transport server over FTPS using a client certificate, using "SITE AUTH" will tell the server to retrieve the username from the certificate.;NONE;5
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--ftp-create-dirs;(FTP SFTP) When an FTP or SFTP URL/operation uses a path that does not currently exist on the server, the standard behavior of curl is to fail. Using this option, curl will instead attempt to create missing directories.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--ftp-method <method>;(FTP) Control what method curl should use to reach a file on an FTP(S) server. The method argument should be one of the following alternatives: multicwd curl does a single CWD operation for each path part in the given URL. For deep hierarchies this means many commands. This is how RFC 1738 says it should be done. This is the default but the slowest behavior. nocwd curl does no CWD at all. curl will do SIZE, RETR, STOR etc and give a full path to the server for all these commands. This is the fastest behavior. singlecwd curl does one CWD with the full target directory and then operates on the file "normally" (like in the multicwd case). This is somewhat more standards compliant than 'nocwd' but with out the full penalty of 'multicwd'.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--ftp-pasv;(FTP) Use passive mode for the data connection. Passive is the internal default behavior, but using this option can be used to override a previous -P, --ftp-port option. If this option is used several times, only the first one is used. Undoing an enforced passive really is not doable but you must then instead enforce the correct -P, --ftp-port again. Passive mode means that curl will try the EPSV command first and then PASV, unless --disable-epsv is used.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-P, --ftp-port <address>;(FTP) Reverses the default initiator/listener roles when connecting with FTP. This option makes curl use active mode. curl then tells the server to connect back to the client's specified address and port, while passive mode asks the server to setup an IP address and port for it to connect to. <ad dress> should be one of: interface e.g. "eth0" to specify which interface's IP address you want to use (Unix only) IP address e.g. "192.168.10.1" to specify the exact IP address host name e.g. "my.host.domain" to specify the machine - make curl pick the same IP address that is already used for the control connection If this option is used several times, the last one will be used. Disable the use of PORT with --ftp-pasv. Disable the attempt to use the EPRT command instead of PORT by using --disable-eprt. EPRT is really PORT++. You can also append ":[start]-[end]" to the right of the address, to tell curl what TCP port range to use. That means you specify a port range, from a lower to a higher number. A single number works as well, but do note that it increases the risk of failure since the port may not be available.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--ftp-pret;(FTP) Tell curl to send a PRET command before PASV (and EPSV). Certain FTP servers, mainly drftpd, require this non-standard command for directory listings as well as up and downloads in PASV mode.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--ftp-skip-pasv-ip;(FTP) Tell curl to not use the IP address the server suggests in its response to curl's PASV command when curl connects the data connection. Instead curl will re-use the same IP address it already uses for the control connection.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--ftp-ssl-ccc-mode <active/passive>;(FTP) Sets the CCC mode. The passive mode will not initiate the shutdown, but instead wait for the server to do it, and will not reply to the shutdown from the server. The active mode initiates the shutdown and waits for a reply from the server.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--ftp-ssl-ccc;(FTP) Use CCC (Clear Command Channel) Shuts down the SSL/TLS layer after authenticating. The rest of the control channel communication will be unencrypted. This allows NAT routers to follow the FTP transaction. The default mode is passive.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--ftp-ssl-control;(FTP) Require SSL/TLS for the FTP login, clear for transfer. Allows secure authentication, but non- encrypted data transfers for efficiency. Fails the transfer if the server does not support SSL/TLS.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-G, --get;When used, this option will make all data specified with -d, --data, --data-binary or --data-urlen code to be used in an HTTP GET request instead of the POST request that otherwise would be used. The data will be appended to the URL with a '?' separator. If used in combination with -I, --head, the POST data will instead be appended to the URL with a HEAD request. If this option is used several times, only the first one is used. This is because undoing a GET does not make sense, but you should then instead enforce the alternative method you prefer.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-g, --globoff;This option switches off the "URL globbing parser". When you set this option, you can specify URLs that contain the letters {}[] without having curl itself interpret them. Note that these letters are not normal legal URL contents but they should be encoded according to the URI standard.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--happy-eyeballs-timeout-ms <milliseconds>;Happy Eyeballs is an algorithm that attempts to connect to both IPv4 and IPv6 addresses for dual- stack hosts, giving IPv6 a head-start of the specified number of milliseconds. If the IPv6 address cannot be connected to within that time, then a connection attempt is made to the IPv4 address in parallel. The first connection to be established is the one that is used. The range of suggested useful values is limited. Happy Eyeballs RFC 6555 says "It is RECOMMENDED that connection attempts be paced 150-250 ms apart to balance human factors against network load." libcurl currently defaults to 200 ms. Firefox and Chrome currently default to 300 ms. If this option is used several times, the last one will be used.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--haproxy-protocol;(HTTP) Send a HAProxy PROXY protocol v1 header at the beginning of the connection. This is used by some load balancers and reverse proxies to indicate the client's true IP address and port. This option is primarily useful when sending test requests to a service that expects this header.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-I, --head;(HTTP FTP FILE) Fetch the headers only! HTTP-servers feature the command HEAD which this uses to get nothing but the header of a document. When used on an FTP or FILE file, curl displays the file size and last modification time only.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-H, --header <header/@file>;(HTTP) Extra header to include in the request when sending HTTP to a server. You may specify any number of extra headers. Note that if you should add a custom header that has the same name as one of the internal ones curl would use, your externally set header will be used instead of the internal one. This allows you to make even trickier stuff than curl would normally do. You should not replace internally set headers without knowing perfectly well what you are doing. Remove an internal header by giving a replacement without content on the right side of the colon, as in: -H "Host:". If you send the custom header with no-value then its header must be terminated with a semicolon, such as -H "X-Custom-Header." to send "X-Custom-Header:". curl will make sure that each header you add/replace is sent with the proper end-of-line marker, you should thus not add that as a part of the header content: do not add newlines or carriage returns, they will only mess things up for you. This option can take an argument in @filename style, which then adds a header for each line in the input file. Using @- will make curl read the header file from stdin. Added in 7.55.0. You need --proxy-header to send custom headers intended for a HTTP proxy. Added in 7.37.0. Passing on a "Transfer-Encoding: chunked" header when doing a HTTP request with a request body, will make curl send the data using chunked encoding. WARNING: headers set with this option will be set in all requests - even after redirects are fol lowed, like when told with -L, --location. This can lead to the header being sent to other hosts than the original host, so sensitive headers should be used with caution combined with following redirects. This option can be used multiple times to add/replace/remove multiple headers.;NONE;5
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-H, --header <header/@file>;(HTTP) Extra header to include in the request when sending HTTP to a server. You may specify any number of extra headers. Note that if you should add a custom header that has the same name as one of the internal ones curl would use, your externally set header will be used instead of the internal one. This allows you to make even trickier stuff than curl would normally do. You should not replace internally set headers without knowing perfectly well what you are doing. Remove an internal header by giving a replacement without content on the right side of the colon, as in: -H "Host:". If you send the custom header with no-value then its header must be terminated with a semicolon, such as -H "X-Custom-Header." to send "X-Custom-Header:". curl will make sure that each header you add/replace is sent with the proper end-of-line marker, you should thus not add that as a part of the header content: do not add newlines or carriage returns, they will only mess things up for you. This option can take an argument in @filename style, which then adds a header for each line in the input file. Using @- will make curl read the header file from stdin. Added in 7.55.0. You need --proxy-header to send custom headers intended for a HTTP proxy. Added in 7.37.0. Passing on a "Transfer-Encoding: chunked" header when doing a HTTP request with a request body, will make curl send the data using chunked encoding. WARNING: headers set with this option will be set in all requests - even after redirects are fol lowed, like when told with -L, --location. This can lead to the header being sent to other hosts than the original host, so sensitive headers should be used with caution combined with following redirects. This option can be used multiple times to add/replace/remove multiple headers.;NONE;2
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-h, --help <category>;Usage help. This lists all commands of the <category>. If no arg was provided, curl will display the most important command line arguments. If the argument "all" was provided, curl will display all options available. If the argument "category" was provided, curl will display all categories and their meanings.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--hostpubmd5 <md5>;(SFTP SCP) Pass a string containing 32 hexadecimal digits. The string should be the 128 bit MD5 checksum of the remote host's public key, curl will refuse the connection with the host unless the md5sums match.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--hostpubsha256 <sha256>;(SFTP SCP) Pass a string containing a Base64-encoded SHA256 hash of the remote host's public key. Curl will refuse the connection with the host unless the hashes match.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--hsts <file name>;(HTTPS) This option enables HSTS for the transfer. If the file name points to an existing HSTS cache file, that will be used. After a completed transfer, the cache will be saved to the file name again if it has been modified. Specify a "" file name (zero length) to avoid loading/saving and make curl just handle HSTS in mem ory. If this option is used several times, curl will load contents from all the files but the last one will be used for saving.;NONE;3
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--hsts <file name>;(HTTPS) This option enables HSTS for the transfer. If the file name points to an existing HSTS cache file, that will be used. After a completed transfer, the cache will be saved to the file name again if it has been modified. Specify a "" file name (zero length) to avoid loading/saving and make curl just handle HSTS in mem ory. If this option is used several times, curl will load contents from all the files but the last one will be used for saving.;NONE;2
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--http0.9;(HTTP) Tells curl to be fine with HTTP version 0.9 response. HTTP/0.9 is a completely headerless response and therefore you can also connect with this to non- HTTP servers and still get a response since curl will simply transparently downgrade - if allowed. Since curl 7.66.0, HTTP/0.9 is disabled by default.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-0, --http1.0;(HTTP) Tells curl to use HTTP version 1.0 instead of using its internally preferred HTTP version.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--http1.1;(HTTP) Tells curl to use HTTP version 1.1.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--http2-prior-knowledge;(HTTP) Tells curl to issue its non-TLS HTTP requests using HTTP/2 without HTTP/1.1 Upgrade. It re quires prior knowledge that the server supports HTTP/2 straight away. HTTPS requests will still do HTTP/2 the standard way with negotiated protocol version in the TLS handshake.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--http2;(HTTP) Tells curl to use HTTP version 2. See also --http1.1 and --http3. --http2 requires that the underlying libcurl was built to support HTTP/2. This option overrides --http1.1 and -0, --http1.0 and --http2-prior-knowledge. Added in 7.33.0.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--http3;(HTTP) WARNING: this option is experimental. Do not use in production. Tells curl to use HTTP version 3 directly to the host and port number used in the URL. A normal HTTP/3 transaction will be done to a host and then get redirected via Alt-SVc, but this option al lows a user to circumvent that when you know that the target speaks HTTP/3 on the given host and port. This option will make curl fail if a QUIC connection cannot be established, it cannot fall back to a lower HTTP version on its own. See also --http1.1 and --http2. --http3 requires that the underlying libcurl was built to support HTTP/3. This option overrides --http1.1 and -0, --http1.0 and --http2 and --http2-prior-knowledge. Added in 7.66.0.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--ignore-content-length;(FTP HTTP) For HTTP, Ignore the Content-Length header. This is particularly useful for servers run ning Apache 1.x, which will report incorrect Content-Length for files larger than 2 gigabytes. For FTP (since 7.46.0), skip the RETR command to figure out the size before downloading a file.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-i, --include;Include the HTTP response headers in the output. The HTTP response headers can include things like server name, cookies, date of the document, HTTP version and more... To view the request headers, consider the -v, --verbose option. See also -v, --verbose.;NONE;4
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-k, --insecure;(TLS) By default, every SSL connection curl makes is verified to be secure. This option allows curl to proceed and operate even for server connections otherwise considered insecure. The server connection is verified by making sure the server's certificate contains the right name and verifies successfully using the cert store. See this online resource for further details: https://curl.haxx.se/docs/sslcerts.html See also --proxy-insecure and --cacert.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--interface <name>;Perform an operation using a specified interface. You can enter interface name, IP address or host name. An example could look like: curl --interface eth0:1 https://www.example.com/ If this option is used several times, the last one will be used. On Linux it can be used to specify a VRF, but the binary needs to either have CAP_NET_RAW or to be run as root. More information about Linux VRF: https://www.kernel.org/doc/Documentation/network ing/vrf.txt See also --dns-interface.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-4, --ipv4;This option tells curl to resolve names to IPv4 addresses only, and not for example try IPv6. See also --http1.1 and --http2. This option overrides -6, --ipv6.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-6, --ipv6;This option tells curl to resolve names to IPv6 addresses only, and not for example try IPv4. See also --http1.1 and --http2. This option overrides -4, --ipv4.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-j, --junk-session-cookies;(HTTP) When curl is told to read cookies from a given file, this option will make it discard all "session cookies". This will basically have the same effect as if a new session is started. Typical browsers always discard session cookies when they're closed down. See also -b, --cookie and -c, --cookie-jar.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--keepalive-time <seconds>;This option sets the time a connection needs to remain idle before sending keepalive probes and the time between individual keepalive probes. It is currently effective on operating systems offering the TCP_KEEPIDLE and TCP_KEEPINTVL socket options (meaning Linux, recent AIX, HP-UX and more). This option has no effect if --no-keepalive is used. If this option is used several times, the last one will be used. If unspecified, the option defaults to 60 seconds. Added in 7.18.0.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--key-type <type>;(TLS) Private key file type. Specify which type your --key provided private key is. DER, PEM, and ENG are supported. If not specified, PEM is assumed. If this option is used several times, the last one will be used.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--key <key>;(TLS SSH) Private key file name. Allows you to provide your private key in this separate file. For SSH, if not specified, curl tries the following candidates in order: '~/.ssh/id_rsa', '~/.ssh/id_dsa', './id_rsa', './id_dsa'. If curl is built against OpenSSL library, and the engine pkcs11 is available, then a PKCS#11 URI (RFC 7512) can be used to specify a private key located in a PKCS#11 device. A string beginning with "pkcs11:" will be interpreted as a PKCS#11 URI. If a PKCS#11 URI is provided, then the --engine op tion will be set as "pkcs11" if none was provided and the --key-type option will be set as "ENG" if none was provided.;NONE;2
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--krb <level>;(FTP) Enable Kerberos authentication and use. The level must be entered and should be one of 'clear', 'safe', 'confidential', or 'private'. Should you use a level that is not one of these, 'private' will instead be used.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--libcurl <file>;Append this option to any ordinary curl command line, and you will get a libcurl-using C source code written to the file that does the equivalent of what your command-line operation does!;NONE;3
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--limit-rate <speed>;Specify the maximum transfer rate you want curl to use - for both downloads and uploads. This fea ture is useful if you have a limited pipe and you'd like your transfer not to use your entire band width. To make it slower than it otherwise would be. The given speed is measured in bytes/second, unless a suffix is appended. Appending 'k' or 'K' will count the number as kilobytes, 'm' or 'M' makes it megabytes, while 'g' or 'G' makes it gigabytes. Examples: 200K, 3m and 1G. If you also use the -Y, --speed-limit option, that option will take precedence and might cripple the rate-limiting slightly, to help keeping the speed-limit logic working.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-l, --list-only;(FTP POP3) (FTP) When listing an FTP directory, this switch forces a name-only view. This is espe cially useful if the user wants to machine-parse the contents of an FTP directory since the normal directory view doesn't use a standard look or format. When used like this, the option causes a NLST command to be sent to the server instead of LIST. Note: Some FTP servers list only files in their response to NLST. they do not include sub-directo ries and symbolic links. (POP3) When retrieving a specific email from POP3, this switch forces a LIST command to be performed instead of RETR. This is particularly useful if the user wants to see if a specific message id ex ists on the server and what size it is. Note: When combined with -X, --request, this option can be used to send an UIDL command instead, so the user may use the email's unique identifier rather than it's message id to make the request.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--local-port <num/range>;Set a preferred single number or range (FROM-TO) of local port numbers to use for the connection(s). Note that port numbers by nature are a scarce resource that will be busy at times so setting this range to something too narrow might cause unnecessary connection setup failures.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--location-trusted;(HTTP) Like -L, --location, but will allow sending the name + password to all hosts that the site may redirect to. This may or may not introduce a security breach if the site redirects you to a site to which you'll send your authentication info (which is plaintext in the case of HTTP Basic authen tication). See also -u, --user.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-L, --location;(HTTP) If the server reports that the requested page has moved to a different location (indicated with a Location: header and a 3XX response code), this option will make curl redo the request on the new place. If used together with -i, --include or -I, --head, headers from all requested pages will be shown. When authentication is used, curl only sends its credentials to the initial host. If a re direct takes curl to a different host, it won't be able to intercept the user+password. See also --location-trusted on how to change this. You can limit the amount of redirects to follow by using the --max-redirs option. When curl follows a redirect and the request is not a plain GET (for example POST or PUT), it will do the following request with a GET if the HTTP response was 301, 302, or 303. If the response code was any other 3xx code, curl will re-send the following request using the same unmodified method. You can tell curl to not change the non-GET request method to GET after a 30x response by using the dedicated options for that: --post301, --post302 and --post303.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--login-options <options>;(IMAP POP3 SMTP) Specify the login options to use during server authentication. You can use the login options to specify protocol specific options that may be used during authenti cation. At present only IMAP, POP3 and SMTP support login options. For more information about the login options please see RFC 2384, RFC 5092 and IETF draft draft-earhart-url-smtp-00.txt;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--mail-auth <address>;(SMTP) Specify a single address. This will be used to specify the authentication address (identity) of a submitted message that is being relayed to another server. See also --mail-rcpt and --mail-from.;NONE;5
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--mail-from <address>;(SMTP) Specify a single address that the given mail should get sent from. See also --mail-rcpt and --mail-auth.;NONE;5
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--mail-rcpt <address>;(SMTP) Specify a single address, user name or mailing list name. Repeat this option several times to send to multiple recipients. When performing a mail transfer, the recipient should specify a valid email address to send the mail to. When performing an address verification (VRFY command), the recipient should be specified as the user name or user name and domain (as per Section 3.5 of RFC5321). (Added in 7.34.0) When performing a mailing list expand (EXPN command), the recipient should be specified using the mailing list name, such as "Friends" or "London-Office". (Added in 7.34.0);NONE;5
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-M, --manual;Manual. Display the huge help text.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--max-filesize <bytes>;Specify the maximum size (in bytes) of a file to download. If the file requested is larger than this value, the transfer will not start and curl will return with exit code 63. A size modifier may be used. For example, Appending 'k' or 'K' will count the number as kilobytes, 'm' or 'M' makes it megabytes, while 'g' or 'G' makes it gigabytes. Examples: 200K, 3m and 1G. (Added in 7.58.0) NOTE: The file size is not always known prior to download, and for such files this option has no ef fect even if the file transfer ends up being larger than this given limit. This concerns both FTP and HTTP transfers. See also --limit-rate.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--max-redirs <num>;(HTTP) Set maximum number of redirection-followings allowed. When -L, --location is used, is used to prevent curl from following redirections too much. By default, the limit is set to 50 redirections. Set this option to -1 to make it unlimited.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-m, --max-time <seconds>;Maximum time in seconds that you allow the whole operation to take. This is useful for preventing your batch jobs from hanging for hours due to slow networks or links going down. Since 7.32.0, this option accepts decimal values, but the actual timeout will decrease in accuracy as the specified timeout increases in decimal precision.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--metalink;This option can tell curl to parse and process a given URI as Metalink file (both version 3 and 4 (RFC 5854) are supported) and make use of the mirrors listed within for failover if there are errors (such as the file or server not being available). It will also verify the hash of the file after the download completes. The Metalink file itself is downloaded and processed in memory and not stored in the local file system.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--negotiate;(HTTP) Enables Negotiate (SPNEGO) authentication. This option requires a library built with GSS-API or SSPI support. Use -V, --version to see if your curl supports GSS-API/SSPI or SPNEGO. When using this option, you must also provide a fake -u, --user option to activate the authentica tion code properly. Sending a '-u :' is enough as the user name and password from the -u, --user op tion aren't actually used.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--netrc-file <filename>;This option is similar to -n, --netrc, except that you provide the path (absolute or relative) to the netrc file that curl should use. You can only specify one netrc file per invocation.;NONE;2
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--netrc-optional;Very similar to -n, --netrc, but this option makes the .netrc usage optional and not mandatory as the -n, --netrc option does. See also --netrc-file. This option overrides -n, --netrc.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-n, --netrc;Makes curl scan the .netrc (_netrc on Windows) file in the user's home directory for login name and password. This is typically used for FTP on Unix. If used with HTTP, curl will enable user authenti cation. See netrc(5) ftp(1) for details on the file format. Curl will not complain if that file doesn't have the right permissions (it should not be either world- or group-readable). The environ ment variable "HOME" is used to find the home directory. A quick and very simple example of how to setup a .netrc to allow curl to FTP to the machine host.domain.com with user name 'myself' and password 'secret' should look similar to: machine host.domain.com login myself password secret;NONE;2
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-:, --next;Tells curl to use a separate operation for the following URL and associated options. This allows you to send several URL requests, each with their own specific options, for example, such as different user names or custom requests for each. -:, --next will reset all local options and only global ones will have their values survive over to the operation following the -:, --next instruction. Global options include -v, --verbose, --trace, --trace-ascii and --fail-early.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--no-alpn;(HTTPS) Disable the ALPN TLS extension. ALPN is enabled by default if libcurl was built with an SSL library that supports ALPN. ALPN is used by a libcurl that supports HTTP/2 to negotiate HTTP/2 sup port with the server during https sessions. See also --no-npn and --http2. --no-alpn requires that the underlying libcurl was built to support TLS. Added in 7.36.0.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-N, --no-buffer;Disables the buffering of the output stream. In normal work situations, curl will use a standard buffered output stream that will have the effect that it will output the data in chunks, not neces sarily exactly when the data arrives. Using this option will disable that buffering. Note that this is the negated option name documented. You can thus use --buffer to enforce the buffering.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--no-keepalive;Disables the use of keepalive messages on the TCP connection. curl otherwise enables them by de fault. Note that this is the negated option name documented. You can thus use --keepalive to enforce keepalive.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--no-npn;(HTTPS) Disable the NPN TLS extension. NPN is enabled by default if libcurl was built with an SSL library that supports NPN. NPN is used by a libcurl that supports HTTP/2 to negotiate HTTP/2 support with the server during https sessions. See also --no-alpn and --http2.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--no-progress-meter;Option to switch off the progress meter output without muting or otherwise affecting warning and in formational messages like -s, --silent does. Note that this is the negated option name documented. You can thus use --progress-meter to enable the progress meter again. See also -v, --verbose and -s, --silent.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--no-sessionid;(TLS) Disable curl's use of SSL session-ID caching. By default all transfers are done using the cache. Note that while nothing should ever get hurt by attempting to reuse SSL session-IDs, there seem to be broken SSL implementations in the wild that may require you to disable this in order for you to succeed. Note that this is the negated option name documented. You can thus use --sessionid to enforce ses sion-ID caching.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--noproxy <no-proxy-list>;Comma-separated list of hosts which do not use a proxy, if one is specified. The only wildcard is a single * character, which matches all hosts, and effectively disables the proxy. Each name in this list is matched as either a domain which contains the hostname, or the hostname itself. For example, local.com would match local.com, local.com:80, and www.local.com, but not www.notlocal.com.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--ntlm-wb;(HTTP) Enables NTLM much in the style --ntlm does, but hand over the authentication to the separate binary ntlmauth application that is executed when needed. See also --ntlm and --proxy-ntlm.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--ntlm;(HTTP) Enables NTLM authentication. The NTLM authentication method was designed by Microsoft and is used by IIS web servers. It is a proprietary protocol, reverse-engineered by clever people and im plemented in curl based on their efforts. This kind of behavior should not be endorsed, you should encourage everyone who uses NTLM to switch to a public and documented authentication method instead, such as Digest. If you want to enable NTLM for your proxy authentication, then use --proxy-ntlm. If this option is used several times, only the first one is used. See also --proxy-ntlm. --ntlm requires that the underlying libcurl was built to support TLS. This option overrides --basic and --negotiate and --digest and --anyauth.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--oauth2-bearer <token>;(IMAP POP3 SMTP) Specify the Bearer Token for OAUTH 2.0 server authentication. The Bearer Token is used in conjunction with the user name which can be specified as part of the --url or -u, --user op tions. The Bearer Token and user name are formatted according to RFC 6750.;NONE;5
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-o, --output <file>;Write output to <file> instead of stdout. If you are using {} or [] to fetch multiple documents, you can use '#' followed by a number in the <file> specifier. That variable will be replaced with the current string for the URL being fetched. Like in:;NONE;3
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--parallel-immediate;When doing parallel transfers, this option will instruct curl that it should rather prefer opening up more connections in parallel at once rather than waiting to see if new transfers can be added as multiplexed streams on another connection. See also -Z, --parallel and --parallel-max.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--parallel-max;When asked to do parallel transfers, using -Z, --parallel, this option controls the maximum amount of transfers to do simultaneously. The default is 50. See also -Z, --parallel.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-Z, --parallel;Makes curl perform its transfers in parallel as compared to the regular serial manner.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--pass <phrase>;(SSH TLS) Passphrase for the private key;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--path-as-is;Tell curl to not handle sequences of /../ or /./ in the given URL path. Normally curl will squash or merge them according to standards but with this option set you tell it not to do that.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--pinnedpubkey <hashes>;(TLS) Tells curl to use the specified public key file (or hashes) to verify the peer. This can be a path to a file which contains a single public key in PEM or DER format, or any number of base64 en coded sha256 hashes preceded by sha256// and separated by . When negotiating a TLS or SSL connection, the server sends a certificate indicating its identity. A public key is extracted from this certificate and if it does not exactly match the public key pro vided to this option, curl will abort the connection before sending or receiving any data.;NONE;2
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--post301;(HTTP) Tells curl to respect RFC 7231/6.4.2 and not convert POST requests into GET requests when following a 301 redirection. The non-RFC behaviour is ubiquitous in web browsers, so curl does the conversion by default to maintain consistency. However, a server may require a POST to remain a POST after such a redirection. This option is meaningful only when using -L, --location. See also --post302 and --post303 and -L, --location.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--post302;(HTTP) Tells curl to respect RFC 7231/6.4.3 and not convert POST requests into GET requests when following a 302 redirection. The non-RFC behaviour is ubiquitous in web browsers, so curl does the conversion by default to maintain consistency. However, a server may require a POST to remain a POST after such a redirection. This option is meaningful only when using -L, --location. See also --post301 and --post303 and -L, --location.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--post303;(HTTP) Tells curl to violate RFC 7231/6.4.4 and not convert POST requests into GET requests when following 303 redirections. A server may require a POST to remain a POST after a 303 redirection. This option is meaningful only when using -L, --location. See also --post302 and --post301 and -L, --location.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--preproxy [protocol://]host[:port];Use the specified SOCKS proxy before connecting to an HTTP or HTTPS -x, --proxy. In such a case curl first connects to the SOCKS proxy and then connects (through SOCKS) to the HTTP or HTTPS proxy. Hence pre proxy. The pre proxy string should be specified with a protocol:// prefix to specify alternative proxy pro tocols. Use socks4://, socks4a://, socks5:// or socks5h:// to request the specific SOCKS version to be used. No protocol specified will make curl default to SOCKS4. If the port number is not specified in the proxy string, it is assumed to be 1080. User and password that might be provided in the proxy string are URL decoded by curl. This allows you to pass in special characters such as @ by using %40 or pass in a colon with %3a.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-#, --progress-bar;Make curl display transfer progress as a simple progress bar instead of the standard, more informa tional, meter. This progress bar draws a single line of '#' characters across the screen and shows a percentage if the transfer size is known. For transfers without a known size, there will be space ship (-=o=-) that moves back and forth but only while data is being transferred, with a set of flying hash sign symbols on top.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--proto-default <protocol>;Tells curl to use protocol for any URL missing a scheme name.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--proto-redir <protocols>;Tells curl to limit what protocols it may use on redirect. Protocols denied by --proto are not over ridden by this option. See --proto for how protocols are represented.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--proto <protocols>;Tells curl to limit what protocols it may use in the transfer. Protocols are evaluated left to right, are comma separated, and are each a protocol name or 'all', optionally prefixed by zero or more modifiers. Available modifiers are: + Permit this protocol in addition to protocols already permitted (this is the default if no modi fier is used). - Deny this protocol, removing it from the list of protocols already permitted. = Permit only this protocol (ignoring the list already permitted), though subject to later modifi cation by subsequent entries in the comma separated list.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--proxy-anyauth;Tells curl to pick a suitable authentication method when communicating with the given HTTP proxy. This might cause an extra request/response round-trip. See also -x, --proxy and --proxy-basic and --proxy-digest.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--proxy-basic;Tells curl to use HTTP Basic authentication when communicating with the given proxy. Use --basic for enabling HTTP Basic with a remote host. Basic is the default authentication method curl uses with proxies. See also -x, --proxy and --proxy-anyauth and --proxy-digest.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--proxy-digest;Tells curl to use HTTP Digest authentication when communicating with the given proxy. Use --digest for enabling HTTP Digest with a remote host. See also -x, --proxy and --proxy-anyauth and --proxy-basic.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--proxy-header <header/@file>;(HTTP) Extra header to include in the request when sending HTTP to a proxy. You may specify any num ber of extra headers. This is the equivalent option to -H, --header but is for proxy communication only like in CONNECT requests when you want a separate header sent to the proxy to what is sent to the actual remote host. curl will make sure that each header you add/replace is sent with the proper end-of-line marker, you should thus not add that as a part of the header content: do not add newlines or carriage returns, they will only mess things up for you. Headers specified with this option will not be included in requests that curl knows will not be sent to a proxy. Starting in 7.55.0, this option can take an argument in @filename style, which then adds a header for each line in the input file. Using @- will make curl read the header file from stdin. This option can be used multiple times to add/replace/remove multiple headers.;NONE;5
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--proxy-header <header/@file>;(HTTP) Extra header to include in the request when sending HTTP to a proxy. You may specify any num ber of extra headers. This is the equivalent option to -H, --header but is for proxy communication only like in CONNECT requests when you want a separate header sent to the proxy to what is sent to the actual remote host. curl will make sure that each header you add/replace is sent with the proper end-of-line marker, you should thus not add that as a part of the header content: do not add newlines or carriage returns, they will only mess things up for you. Headers specified with this option will not be included in requests that curl knows will not be sent to a proxy. Starting in 7.55.0, this option can take an argument in @filename style, which then adds a header for each line in the input file. Using @- will make curl read the header file from stdin. This option can be used multiple times to add/replace/remove multiple headers.;NONE;2
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--proxy-negotiate;Tells curl to use HTTP Negotiate (SPNEGO) authentication when communicating with the given proxy. Use --negotiate for enabling HTTP Negotiate (SPNEGO) with a remote host. See also --proxy-anyauth and --proxy-basic.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--proxy-ntlm;Tells curl to use HTTP NTLM authentication when communicating with the given proxy. Use --ntlm for enabling NTLM with a remote host. See also --proxy-negotiate and --proxy-anyauth.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--proxy-pinnedpubkey <hashes>;(TLS) Tells curl to use the specified public key file (or hashes) to verify the proxy. This can be a path to a file which contains a single public key in PEM or DER format, or any number of base64 en coded sha256 hashes preceded by sha256// and separated by . When negotiating a TLS or SSL connection, the server sends a certificate indicating its identity. A public key is extracted from this certificate and if it does not exactly match the public key pro vided to this option, curl will abort the connection before sending or receiving any data. If this option is used several times, the last one will be used.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--proxy-service-name <name>;This option allows you to change the service name for proxy negotiation.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--proxy-tls13-ciphers <ciphersuite list>;(TLS) Specifies which cipher suites to use in the connection to your HTTPS proxy when it negotiates TLS 1.3. The list of ciphers suites must specify valid ciphers. Read up on TLS 1.3 cipher suite de tails on this URL: https://curl.haxx.se/docs/ssl-ciphers.html This option is currently used only when curl is built to use OpenSSL 1.1.1 or later. If you are us ing a different SSL backend you can try setting TLS 1.3 cipher suites by using the --proxy-ciphers option.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-U, --proxy-user <user:password>;Specify the user name and password to use for proxy authentication. If you use a Windows SSPI-enabled curl binary and do either Negotiate or NTLM authentication then you can tell curl to select the user name and password from your environment by specifying a single colon with this option: "-U :". On systems where it works, curl will hide the given option argument from process listings. This is not enough to protect credentials from possibly getting seen by other users on the same system as they will still be visible for a brief moment before cleared. Such sensitive data should be re trieved from a file instead or similar and never used in clear text in a command line.;NONE;5
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-x, --proxy [protocol://]host[:port];Use the specified proxy. The proxy string can be specified with a protocol:// prefix. No protocol specified or http:// will be treated as HTTP proxy. Use socks4://, socks4a://, socks5:// or socks5h:// to request a specific SOCKS version to be used. (The protocol support was added in curl 7.21.7) HTTPS proxy support via https:// protocol prefix was added in 7.52.0 for OpenSSL, GnuTLS and NSS. Unrecognized and unsupported proxy protocols cause an error since 7.52.0. Prior versions may ignore the protocol and use http:// instead. If the port number is not specified in the proxy string, it is assumed to be 1080. This option overrides existing environment variables that set the proxy to use. If there's an envi ronment variable setting a proxy, you can set proxy to "" to override it. All operations that are performed over an HTTP proxy will transparently be converted to HTTP. It means that certain protocol specific operations might not be available. This is not the case if you can tunnel through the proxy, as one with the -p, --proxytunnel option. User and password that might be provided in the proxy string are URL decoded by curl. This allows you to pass in special characters such as @ by using %40 or pass in a colon with %3a. The proxy host can be specified the exact same way as the proxy environment variables, including the protocol prefix (http://) and the embedded user + password.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--proxy1.0 <host[:port]>;Use the specified HTTP 1.0 proxy. If the port number is not specified, it is assumed at port 1080. The only difference between this and the HTTP proxy option -x, --proxy, is that attempts to use CON NECT through the proxy will specify an HTTP 1.0 protocol instead of the default HTTP 1.1.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-p, --proxytunnel;When an HTTP proxy is used -x, --proxy, this option will make curl tunnel through the proxy. The tunnel approach is made with the HTTP proxy CONNECT request and requires that the proxy allows di rect connect to the remote port number curl wants to tunnel through to. To suppress proxy CONNECT response headers when curl is set to output headers use --suppress-con nect-headers. See also -x, --proxy.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--pubkey <key>;(SFTP SCP) Public key file name. Allows you to provide your public key in this separate file. If this option is used several times, the last one will be used.;NONE;2
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--pubkey <key>;(SFTP SCP) Public key file name. Allows you to provide your public key in this separate file. If this option is used several times, the last one will be used.;NONE;5
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--random-file <file>;Specify the path name to file containing what will be considered as random data. The data may be used to seed the random engine for SSL connections. See also the --egd-file option.;NONE;2
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-r, --range <range>;(HTTP FTP SFTP FILE) Retrieve a byte range (i.e. a partial document) from an HTTP/1.1, FTP or SFTP server or a local FILE. Ranges can be specified in a number of ways.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--raw;(HTTP) When used, it disables all internal HTTP decoding of content or transfer encodings and in stead makes them passed on unaltered, raw.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-e, --referer <URL>;(HTTP) Sends the "Referrer Page" information to the HTTP server. This can also be set with the -H, --header flag of course. When used with -L, --location you can append ".auto" to the -e, --referer URL to make curl automatically set the previous URL when it follows a Location: header. The ".auto" string can be used alone, even if you don't set an initial -e, --referer.;NONE;5
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-J, --remote-header-name;(HTTP) This option tells the -O, --remote-name option to use the server-specified Content-Disposi tion filename instead of extracting a filename from the URL. If the server specifies a file name and a file with that name already exists in the current working directory it will not be overwritten and an error will occur. If the server doesn't specify a file name then this option has no effect. There's no attempt to decode %-sequences (yet) in the provided file name, so this option may provide you with rather unexpected file names. WARNING: Exercise judicious use of this option, especially on Windows. A rogue server could send you the name of a DLL or other file that could possibly be loaded automatically by Windows or some third party software.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--remote-name-all;This option changes the default action for all given URLs to be dealt with as if -O, --remote-name were used for each one. So if you want to disable that for a specific URL after --remote-name-all has been used, you must use "-o -" or --no-remote-name.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-O, --remote-name;Write output to a local file named like the remote file we get. (Only the file part of the remote file is used, the path is cut off.) The file will be saved in the current working directory. If you want the file saved in a different directory, make sure you change the current working directory before invoking curl with this option. The remote file name to use for saving is extracted from the given URL, nothing else, and if it al ready exists it will be overwritten. If you want the server to be able to choose the file name refer to -J, --remote-header-name which can be used in addition to this option. If the server chooses a file name and that name already exists it will not be overwritten. There is no URL decoding done on the file name. If it has %20 or other URL encoded parts of the name, they will end up as-is as file name. You may use this option as many times as the number of URLs you have.;NONE;3
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-R, --remote-time;When used, this will make curl attempt to figure out the timestamp of the remote file, and if that is available make the local file get that same timestamp.;NONE;9
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--request-target;(HTTP) Tells curl to use an alternative "target" (path) instead of using the path as provided in the URL. Particularly useful when wanting to issue HTTP requests without leading slash or other data that doesn't follow the regular URL pattern, like "OPTIONS *".;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-X, --request <command>;(HTTP) Specifies a custom request method to use when communicating with the HTTP server. The speci fied request method will be used instead of the method otherwise used (which defaults to GET). Read the HTTP 1.1 specification for details and explanations. Common additional HTTP requests include PUT and DELETE, but related technologies like WebDAV offers PROPFIND, COPY, MOVE and more. Normally you don't need this option. All sorts of GET, HEAD, POST and PUT requests are rather in voked by using dedicated command line options.;NONE;5
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--resolve <host:port:address[,address]...>;Provide a custom address for a specific host and port pair. Using this, you can make the curl re quests(s) use a specified address and prevent the otherwise normally resolved address to be used. Consider it a sort of /etc/hosts alternative provided on the command line. The port number should be the number used for the specific protocol the host will be used for. It means you need several en tries if you want to provide address for the same host but different ports.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--retry-connrefused;In addition to the other conditions, consider ECONNREFUSED as a transient error too for --retry. This option is used together with --retry.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--retry-delay <seconds>;Make curl sleep this amount of time before each retry when a transfer has failed with a transient error (it changes the default backoff time algorithm between retries). This option is only interest ing if --retry is also used. Setting this delay to zero will make curl use the default backoff time. If this option is used several times, the last one will be used.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--retry-max-time <seconds>;The retry timer is reset before the first transfer attempt. Retries will be done as usual (see --retry) as long as the timer hasn't reached this given limit. Notice that if the timer hasn't reached the limit, the request will be made and while performing, it may take longer than this given time period. To limit a single requests maximum time, use -m, --max-time. Set this option to zero to not timeout retries. If this option is used several times, the last one will be used.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--retry <num>;If a transient error is returned when curl tries to perform a transfer, it will retry this number of times before giving up. Setting the number to 0 makes curl do no retries (which is the default). Transient error means either: a timeout, an FTP 4xx response code or an HTTP 408 or 5xx response code. When curl is about to retry a transfer, it will first wait one second and then for all forthcoming retries it will double the waiting time until it reaches 10 minutes which then will be the delay be tween the rest of the retries. By using --retry-delay you disable this exponential backoff algo rithm. See also --retry-max-time to limit the total time allowed for retries. Since curl 7.66.0, curl will comply with the Retry-After: response header if one was present to know when to issue the next retry. If this option is used several times, the last one will be used.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--sasl-ir;Enable initial response in SASL authentication.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--service-name <name>;This option allows you to change the service name for SPNEGO.;NONE;5
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-S, --show-error;When used with -s, --silent, it makes curl show an error message if it fails.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;-s, --silent;Silent or quiet mode. Don't show progress meter or error messages. Makes Curl mute. It will still output the data you ask for, potentially even to the terminal/stdout unless you redirect it. Use -S, --show-error in addition to this option to disable progress meter but still show error mes sages. See also -v, --verbose and --stderr.;NONE;0
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--socks4 <host[:port]>;Use the specified SOCKS4 proxy. If the port number is not specified, it is assumed at port 1080. This option overrides any previous use of -x, --proxy, as they are mutually exclusive. Since 7.21.7, this option is superfluous since you can specify a socks4 proxy with -x, --proxy using a socks4:// protocol prefix. Since 7.52.0, --preproxy can be used to specify a SOCKS proxy at the same time -x, --proxy is used with an HTTP/HTTPS proxy. In such a case curl first connects to the SOCKS proxy and then connects (through SOCKS) to the HTTP or HTTPS proxy.;NONE;11
curl;curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GO PHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET or TFTP. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connec tions, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin.;--url <url>;Specify a URL to fetch. This option is mostly handy when you want to specify URL(s) in a config file. If the given URL is missing a scheme name (such as "http://" or "ftp://" etc) then curl will make a guess based on the host. If the outermost sub-domain name matches DICT, FTP, IMAP, LDAP, POP3 or SMTP then that protocol will be used, otherwise HTTP will be used. Since 7.45.0 guessing can be dis abled by setting a default protocol, see --proto-default for details. This option may be used any number of times. To control where this URL is written, use the -o, --output or the -O, --remote-name options.;NONE;5
aria2c;aria2 is a utility for downloading files. The supported protocols are HTTP(S), FTP, SFTP, BitTorrent, and Metalink. aria2 can download a file from multiple sources/protocols and tries to utilize your maximum down load bandwidth. It supports downloading a file from HTTP(S)/FTP /SFTP and BitTorrent at the same time, while the data downloaded from HTTP(S)/FTP/SFTP is uploaded to the BitTorrent swarm. Using Metalink chunk checksums, aria2 automatically validates chunks of data while downloading a file.;aria2c;aria2 is a utility for downloading files. The supported protocols are HTTP(S), FTP, SFTP, BitTorrent, and Metalink. aria2 can download a file from multiple sources/protocols and tries to utilize your maximum down load bandwidth. It supports downloading a file from HTTP(S)/FTP /SFTP and BitTorrent at the same time, while the data downloaded from HTTP(S)/FTP/SFTP is uploaded to the BitTorrent swarm. Using Metalink chunk checksums, aria2 automatically validates chunks of data while downloading a file.;NONE;5
aria2c;aria2 is a utility for downloading files. The supported protocols are HTTP(S), FTP, SFTP, BitTorrent, and Metalink. aria2 can download a file from multiple sources/protocols and tries to utilize your maximum down load bandwidth. It supports downloading a file from HTTP(S)/FTP /SFTP and BitTorrent at the same time, while the data downloaded from HTTP(S)/FTP/SFTP is uploaded to the BitTorrent swarm. Using Metalink chunk checksums, aria2 automatically validates chunks of data while downloading a file.;aria2c;aria2 is a utility for downloading files. The supported protocols are HTTP(S), FTP, SFTP, BitTorrent, and Metalink. aria2 can download a file from multiple sources/protocols and tries to utilize your maximum down load bandwidth. It supports downloading a file from HTTP(S)/FTP /SFTP and BitTorrent at the same time, while the data downloaded from HTTP(S)/FTP/SFTP is uploaded to the BitTorrent swarm. Using Metalink chunk checksums, aria2 automatically validates chunks of data while downloading a file.;NONE;3
aria2c;aria2 is a utility for downloading files. The supported protocols are HTTP(S), FTP, SFTP, BitTorrent, and Metalink. aria2 can download a file from multiple sources/protocols and tries to utilize your maximum down load bandwidth. It supports downloading a file from HTTP(S)/FTP /SFTP and BitTorrent at the same time, while the data downloaded from HTTP(S)/FTP/SFTP is uploaded to the BitTorrent swarm. Using Metalink chunk checksums, aria2 automatically validates chunks of data while downloading a file.;-d, --dir=<DIR>;The directory to store the downloaded file.;NONE;3
aria2c;aria2 is a utility for downloading files. The supported protocols are HTTP(S), FTP, SFTP, BitTorrent, and Metalink. aria2 can download a file from multiple sources/protocols and tries to utilize your maximum down load bandwidth. It supports downloading a file from HTTP(S)/FTP /SFTP and BitTorrent at the same time, while the data downloaded from HTTP(S)/FTP/SFTP is uploaded to the BitTorrent swarm. Using Metalink chunk checksums, aria2 automatically validates chunks of data while downloading a file.;-i, --input-file=<FILE>;Downloads the URIs listed in FILE. You can specify multiple sources for a single entity by putting multiple URIs on a single line separated by the TAB character. Additionally, options can be speci fied after each URI line. Option lines must start with one or more white space characters (SPACE or TAB) and must only contain one option per line. Input files can use gzip compression. When FILE is specified as -, aria2 will read the input from stdin. See the Input File subsection for details. See also the --deferred-input option. See also the --save-session option.;NONE;2
aria2c;aria2 is a utility for downloading files. The supported protocols are HTTP(S), FTP, SFTP, BitTorrent, and Metalink. aria2 can download a file from multiple sources/protocols and tries to utilize your maximum down load bandwidth. It supports downloading a file from HTTP(S)/FTP /SFTP and BitTorrent at the same time, while the data downloaded from HTTP(S)/FTP/SFTP is uploaded to the BitTorrent swarm. Using Metalink chunk checksums, aria2 automatically validates chunks of data while downloading a file.;-l, --log=<LOG>;The file name of the log file. If - is specified, log is written to stdout. If empty string("") is specified, or this option is omitted, no log is written to disk at all.;NONE;3
aria2c;aria2 is a utility for downloading files. The supported protocols are HTTP(S), FTP, SFTP, BitTorrent, and Metalink. aria2 can download a file from multiple sources/protocols and tries to utilize your maximum down load bandwidth. It supports downloading a file from HTTP(S)/FTP /SFTP and BitTorrent at the same time, while the data downloaded from HTTP(S)/FTP/SFTP is uploaded to the BitTorrent swarm. Using Metalink chunk checksums, aria2 automatically validates chunks of data while downloading a file.;-V, --check-integrity [true|false];Check file integrity by validating piece hashes or a hash of entire file. This option has effect only in BitTorrent, Metalink downloads with checksums or HTTP(S)/FTP downloads with --checksum op tion. If piece hashes are provided, this option can detect damaged portions of a file and re-down load them. If a hash of entire file is provided, hash check is only done when file has been already download. This is determined by file length. If hash check fails, file is re-downloaded from scratch. If both piece hashes and a hash of entire file are provided, only piece hashes are used. Default: false;NONE;0
aria2c;aria2 is a utility for downloading files. The supported protocols are HTTP(S), FTP, SFTP, BitTorrent, and Metalink. aria2 can download a file from multiple sources/protocols and tries to utilize your maximum down load bandwidth. It supports downloading a file from HTTP(S)/FTP /SFTP and BitTorrent at the same time, while the data downloaded from HTTP(S)/FTP/SFTP is uploaded to the BitTorrent swarm. Using Metalink chunk checksums, aria2 automatically validates chunks of data while downloading a file.;-c, --continue [true|false];Continue downloading a partially downloaded file. Use this option to resume a download started by a web browser or another program which downloads files sequentially from the beginning. Currently this option is only applicable to HTTP(S)/FTP downloads.;NONE;0
aria2c;aria2 is a utility for downloading files. The supported protocols are HTTP(S), FTP, SFTP, BitTorrent, and Metalink. aria2 can download a file from multiple sources/protocols and tries to utilize your maximum down load bandwidth. It supports downloading a file from HTTP(S)/FTP /SFTP and BitTorrent at the same time, while the data downloaded from HTTP(S)/FTP/SFTP is uploaded to the BitTorrent swarm. Using Metalink chunk checksums, aria2 automatically validates chunks of data while downloading a file.;-h, --help[=<TAG>|<KEYWORD>];The help messages are classified with tags. A tag starts with #. For example, type --help=#http to get the usage for the options tagged with #http. If non-tag word is given, print the usage for the options whose name includes that word. Available Values: #basic, #advanced, #http, #https, #ftp, #metalink, #bittorrent, #cookie, #hook, #file, #rpc, #checksum, #experimental, #deprecated, #help, #all Default: #basic;NONE;0
aria2c;aria2 is a utility for downloading files. The supported protocols are HTTP(S), FTP, SFTP, BitTorrent, and Metalink. aria2 can download a file from multiple sources/protocols and tries to utilize your maximum down load bandwidth. It supports downloading a file from HTTP(S)/FTP /SFTP and BitTorrent at the same time, while the data downloaded from HTTP(S)/FTP/SFTP is uploaded to the BitTorrent swarm. Using Metalink chunk checksums, aria2 automatically validates chunks of data while downloading a file.;--all-proxy=<PROXY>;Use a proxy server for all protocols. To override a previously defined proxy, use "". You also can override this setting and specify a proxy server for a particular protocol using --http-proxy, --https-proxy and --ftp-proxy options.;NONE;11
aria2c;aria2 is a utility for downloading files. The supported protocols are HTTP(S), FTP, SFTP, BitTorrent, and Metalink. aria2 can download a file from multiple sources/protocols and tries to utilize your maximum down load bandwidth. It supports downloading a file from HTTP(S)/FTP /SFTP and BitTorrent at the same time, while the data downloaded from HTTP(S)/FTP/SFTP is uploaded to the BitTorrent swarm. Using Metalink chunk checksums, aria2 automatically validates chunks of data while downloading a file.;--all-proxy-passwd=<PASSWD>;Set password for --all-proxy option.;NONE;5
aria2c;aria2 is a utility for downloading files. The supported protocols are HTTP(S), FTP, SFTP, BitTorrent, and Metalink. aria2 can download a file from multiple sources/protocols and tries to utilize your maximum down load bandwidth. It supports downloading a file from HTTP(S)/FTP /SFTP and BitTorrent at the same time, while the data downloaded from HTTP(S)/FTP/SFTP is uploaded to the BitTorrent swarm. Using Metalink chunk checksums, aria2 automatically validates chunks of data while downloading a file.;--all-proxy-user=<USER>;Set user for --all-proxy option.;NONE;5
aria2c;aria2 is a utility for downloading files. The supported protocols are HTTP(S), FTP, SFTP, BitTorrent, and Metalink. aria2 can download a file from multiple sources/protocols and tries to utilize your maximum down load bandwidth. It supports downloading a file from HTTP(S)/FTP /SFTP and BitTorrent at the same time, while the data downloaded from HTTP(S)/FTP/SFTP is uploaded to the BitTorrent swarm. Using Metalink chunk checksums, aria2 automatically validates chunks of data while downloading a file.;--connect-timeout=<SEC>;Set the connect timeout in seconds to establish connection to HTTP/FTP/proxy server. After the con nection is established, this option makes no effect and --timeout option is used instead. Default: 60;NONE;0
aria2c;aria2 is a utility for downloading files. The supported protocols are HTTP(S), FTP, SFTP, BitTorrent, and Metalink. aria2 can download a file from multiple sources/protocols and tries to utilize your maximum down load bandwidth. It supports downloading a file from HTTP(S)/FTP /SFTP and BitTorrent at the same time, while the data downloaded from HTTP(S)/FTP/SFTP is uploaded to the BitTorrent swarm. Using Metalink chunk checksums, aria2 automatically validates chunks of data while downloading a file.;-o, --out=<FILE>;The file name of the downloaded file. It is always relative to the directory given in --dir option. When the --force-sequential option is used, this option is ignored.;NONE;3
aria2c;aria2 is a utility for downloading files. The supported protocols are HTTP(S), FTP, SFTP, BitTorrent, and Metalink. aria2 can download a file from multiple sources/protocols and tries to utilize your maximum down load bandwidth. It supports downloading a file from HTTP(S)/FTP /SFTP and BitTorrent at the same time, while the data downloaded from HTTP(S)/FTP/SFTP is uploaded to the BitTorrent swarm. Using Metalink chunk checksums, aria2 automatically validates chunks of data while downloading a file.;-s, --split=<N>;Download a file using N connections. If more than N URIs are given, first N URIs are used and re maining URIs are used for backup. If less than N URIs are given, those URIs are used more than once so that N connections total are made simultaneously. The number of connections to the same host is restricted by the --max-connection-per-server option. See also the --min-split-size option. De fault: 5;NONE;11
aria2c;aria2 is a utility for downloading files. The supported protocols are HTTP(S), FTP, SFTP, BitTorrent, and Metalink. aria2 can download a file from multiple sources/protocols and tries to utilize your maximum down load bandwidth. It supports downloading a file from HTTP(S)/FTP /SFTP and BitTorrent at the same time, while the data downloaded from HTTP(S)/FTP/SFTP is uploaded to the BitTorrent swarm. Using Metalink chunk checksums, aria2 automatically validates chunks of data while downloading a file.;--on-bt-download-complete=<COMMAND>;For BitTorrent, a command specified in --on-download-complete is called after download completed and seeding is over. On the other hand, this option set the command to be executed after download com pleted but before seeding. See Event Hook for more details about COMMAND. Possible Values: /path/to/command;NONE;1
aria2c;aria2 is a utility for downloading files. The supported protocols are HTTP(S), FTP, SFTP, BitTorrent, and Metalink. aria2 can download a file from multiple sources/protocols and tries to utilize your maximum down load bandwidth. It supports downloading a file from HTTP(S)/FTP /SFTP and BitTorrent at the same time, while the data downloaded from HTTP(S)/FTP/SFTP is uploaded to the BitTorrent swarm. Using Metalink chunk checksums, aria2 automatically validates chunks of data while downloading a file.;--on-download-complete=<COMMAND>;Set the command to be executed after download completed. See Event Hook for more details about COM MAND. See also --on-download-stop option. Possible Values: /path/to/command;NONE;1
aria2c;aria2 is a utility for downloading files. The supported protocols are HTTP(S), FTP, SFTP, BitTorrent, and Metalink. aria2 can download a file from multiple sources/protocols and tries to utilize your maximum down load bandwidth. It supports downloading a file from HTTP(S)/FTP /SFTP and BitTorrent at the same time, while the data downloaded from HTTP(S)/FTP/SFTP is uploaded to the BitTorrent swarm. Using Metalink chunk checksums, aria2 automatically validates chunks of data while downloading a file.;--on-download-error=<COMMAND>;Set the command to be executed after download aborted due to error. See Event Hook for more details about COMMAND. See also --on-download-stop option. Possible Values: /path/to/command;NONE;1
aria2c;aria2 is a utility for downloading files. The supported protocols are HTTP(S), FTP, SFTP, BitTorrent, and Metalink. aria2 can download a file from multiple sources/protocols and tries to utilize your maximum down load bandwidth. It supports downloading a file from HTTP(S)/FTP /SFTP and BitTorrent at the same time, while the data downloaded from HTTP(S)/FTP/SFTP is uploaded to the BitTorrent swarm. Using Metalink chunk checksums, aria2 automatically validates chunks of data while downloading a file.;--on-download-pause=<COMMAND>;Set the command to be executed after download was paused. See Event Hook for more details about COMMAND. Possible Values: /path/to/command;NONE;1
aria2c;aria2 is a utility for downloading files. The supported protocols are HTTP(S), FTP, SFTP, BitTorrent, and Metalink. aria2 can download a file from multiple sources/protocols and tries to utilize your maximum down load bandwidth. It supports downloading a file from HTTP(S)/FTP /SFTP and BitTorrent at the same time, while the data downloaded from HTTP(S)/FTP/SFTP is uploaded to the BitTorrent swarm. Using Metalink chunk checksums, aria2 automatically validates chunks of data while downloading a file.;--on-download-start=<COMMAND>;Set the command to be executed after download got started. See Event Hook for more details about COMMAND. Possible Values: /path/to/command;NONE;1
aria2c;aria2 is a utility for downloading files. The supported protocols are HTTP(S), FTP, SFTP, BitTorrent, and Metalink. aria2 can download a file from multiple sources/protocols and tries to utilize your maximum down load bandwidth. It supports downloading a file from HTTP(S)/FTP /SFTP and BitTorrent at the same time, while the data downloaded from HTTP(S)/FTP/SFTP is uploaded to the BitTorrent swarm. Using Metalink chunk checksums, aria2 automatically validates chunks of data while downloading a file.;--on-download-stop=<COMMAND>;Set the command to be executed after download stopped. You can override the command to be executed for particular download result using --on-download-complete and --on-download-error. If they are specified, command specified in this option is not executed. See Event Hook for more details about COMMAND. Possible Values: /path/to/command;NONE;1
aria2c;aria2 is a utility for downloading files. The supported protocols are HTTP(S), FTP, SFTP, BitTorrent, and Metalink. aria2 can download a file from multiple sources/protocols and tries to utilize your maximum down load bandwidth. It supports downloading a file from HTTP(S)/FTP /SFTP and BitTorrent at the same time, while the data downloaded from HTTP(S)/FTP/SFTP is uploaded to the BitTorrent swarm. Using Metalink chunk checksums, aria2 automatically validates chunks of data while downloading a file.;--show-console-readout [true|false];Show console readout. Default: true;NONE;0
aria2c;aria2 is a utility for downloading files. The supported protocols are HTTP(S), FTP, SFTP, BitTorrent, and Metalink. aria2 can download a file from multiple sources/protocols and tries to utilize your maximum down load bandwidth. It supports downloading a file from HTTP(S)/FTP /SFTP and BitTorrent at the same time, while the data downloaded from HTTP(S)/FTP/SFTP is uploaded to the BitTorrent swarm. Using Metalink chunk checksums, aria2 automatically validates chunks of data while downloading a file.;--stderr [true|false];Redirect all console output that would be otherwise printed in stdout to stderr. Default: false;NONE;0
check_ssl_cert;A POSIX shell script (that can be used as a Nagios/Icinga plugin) to check an SSL/TLS connection and certificate;-f,--file file;Local file path or URI. With -f you can not only pass a x509 certificate file but also a certificate revocation list (CRL) to check the validity period or a Java KeyStore file;NONE;2
check_ssl_cert;A POSIX shell script (that can be used as a Nagios/Icinga plugin) to check an SSL/TLS connection and certificate;-H,--host host;Server;NONE;5
check_ssl_cert;A POSIX shell script (that can be used as a Nagios/Icinga plugin) to check an SSL/TLS connection and certificate;--curl-bin path ;Path of the curl binary to be used;NONE;1
check_ssl_cert;A POSIX shell script (that can be used as a Nagios/Icinga plugin) to check an SSL/TLS connection and certificate;--fingerprint SHA1;Pattern to match the SHA1-Fingerprint;NONE;0
check_ssl_cert;A POSIX shell script (that can be used as a Nagios/Icinga plugin) to check an SSL/TLS connection and certificate;--file-bin path;Path of the file binary to be used;NONE;1
crash;Crash is a tool for interactively analyzing the state of the Linux system while it is running, or after a kernel crash has occurred and a core dump has been created by the netdump, diskdump, LKCD, kdump, xendump or kvmdump facilities. It is loosely based on the SVR4 UNIX crash command, but has been significantly enhanced by completely merging it with the gdb(1) debugger. The marriage of the two effectively combines the kernel-specific nature of the traditional UNIX crash utility with the source code level debugging capabilities of gdb(1).;CRASHPAGER;If CRASHPAGER is set, its value is used as the name of the program to which command output will be sent. If not, then command output output is sent to "/usr/bin/less -E -X" by default.;NONE;1
crash;Crash is a tool for interactively analyzing the state of the Linux system while it is running, or after a kernel crash has occurred and a core dump has been created by the netdump, diskdump, LKCD, kdump, xendump or kvmdump facilities. It is loosely based on the SVR4 UNIX crash command, but has been significantly enhanced by completely merging it with the gdb(1) debugger. The marriage of the two effectively combines the kernel-specific nature of the traditional UNIX crash utility with the source code level debugging capabilities of gdb(1).;--offline [show|hide];Show or hide command output that is associated with offline cpus, overriding any settings in either ./.crashrc or $HOME/.crashrc.;NONE;0
crash;Crash is a tool for interactively analyzing the state of the Linux system while it is running, or after a kernel crash has occurred and a core dump has been created by the netdump, diskdump, LKCD, kdump, xendump or kvmdump facilities. It is loosely based on the SVR4 UNIX crash command, but has been significantly enhanced by completely merging it with the gdb(1) debugger. The marriage of the two effectively combines the kernel-specific nature of the traditional UNIX crash utility with the source code level debugging capabilities of gdb(1).;--minimal;Bring up a session that is restricted to the log, dis, rd, sym, eval, set and exit commands. This option may provide a way to extract some minimal/quick information from a corrupted or truncated dumpfile, or in situations where one of the several kernel subsystem initialization routines would abort the crash session.;NONE;0
openvpn;OpenVPN is an open source VPN daemon by James Yonan. Because OpenVPN tries to be a universal VPN tool offering a great deal of flexibility, there are a lot of options on this manual page. If you're new to OpenVPN, you might want to skip ahead to the examples section where you will see how to construct simple VPNs on the command line without even needing a configuration file.;--up cmd; Run command cmd after successful TUN/TAP device open (pre --user UID change). cmd consists of a path to script (or executable program), optionally followed by arguments. The path and arguments may be single- or double-quoted and/or escaped using a backslash, and should be sepa rated by one or more spaces.;NONE;1
openvpn;OpenVPN is an open source VPN daemon by James Yonan. Because OpenVPN tries to be a universal VPN tool offering a great deal of flexibility, there are a lot of options on this manual page. If you're new to OpenVPN, you might want to skip ahead to the examples section where you will see how to construct simple VPNs on the command line without even needing a configuration file.;--down cmd;Run command cmd after TUN/TAP device close (post --user UID change and/or --chroot ). cmd consists of a path to script (or executable program), optionally followed by arguments. The path and argu ments may be single- or double-quoted and/or escaped using a backslash, and should be separated by one or more spaces.;NONE;1
openvpn;OpenVPN is an open source VPN daemon by James Yonan. Because OpenVPN tries to be a universal VPN tool offering a great deal of flexibility, there are a lot of options on this manual page. If you're new to OpenVPN, you might want to skip ahead to the examples section where you will see how to construct simple VPNs on the command line without even needing a configuration file.;--setenv-safe name value;Set a custom environmental variable OPENVPN_name=value to pass to script.;NONE;0
openvpn;OpenVPN is an open source VPN daemon by James Yonan. Because OpenVPN tries to be a universal VPN tool offering a great deal of flexibility, there are a lot of options on this manual page. If you're new to OpenVPN, you might want to skip ahead to the examples section where you will see how to construct simple VPNs on the command line without even needing a configuration file.;--disable-occ;Don't output a warning message if option inconsistencies are detected between peers. An example of an option inconsistency would be where one peer uses --dev tun while the other peer uses --dev tap.;NONE;0
openvpn;OpenVPN is an open source VPN daemon by James Yonan. Because OpenVPN tries to be a universal VPN tool offering a great deal of flexibility, there are a lot of options on this manual page. If you're new to OpenVPN, you might want to skip ahead to the examples section where you will see how to construct simple VPNs on the command line without even needing a configuration file.;--user user;Change the user ID of the OpenVPN process to user after initialization, dropping privileges in the process. This option is useful to protect the system in the event that some hostile party was able to gain control of an OpenVPN session. Though OpenVPN's security features make this unlikely, it is provided as a second line of defense.;NONE;0
pidstat;The pidstat command is used for monitoring individual tasks currently being managed by the Linux kernel. It writes to standard output activities for every task selected with option -p or for every task managed by the Linux kernel if option -p ALL has been used. Not selecting any tasks is equivalent to specifying -p ALL but only active tasks (tasks with non-zero statistics values) will appear in the report.;pidstat;The pidstat command is used for monitoring individual tasks currently being managed by the Linux kernel. It writes to standard output activities for every task selected with option -p or for every task managed by the Linux kernel if option -p ALL has been used. Not selecting any tasks is equivalent to specifying -p ALL but only active tasks (tasks with non-zero statistics values) will appear in the report.;NONE;6
pidstat;The pidstat command is used for monitoring individual tasks currently being managed by the Linux kernel. It writes to standard output activities for every task selected with option -p or for every task managed by the Linux kernel if option -p ALL has been used. Not selecting any tasks is equivalent to specifying -p ALL but only active tasks (tasks with non-zero statistics values) will appear in the report.;--dec={ 0 | 1 | 2 };Specify the number of decimal places to use (0 to 2, default value is 2).;NONE;0
pidstat;The pidstat command is used for monitoring individual tasks currently being managed by the Linux kernel. It writes to standard output activities for every task selected with option -p or for every task managed by the Linux kernel if option -p ALL has been used. Not selecting any tasks is equivalent to specifying -p ALL but only active tasks (tasks with non-zero statistics values) will appear in the report.;-G process_name;Display only processes whose command name includes the string process_name. This string can be a regular expression. If option -t is used together with option -G then the threads belonging to that process are also displayed (even if their command name doesn't include the string process_name).;NONE;6
pidstat;The pidstat command is used for monitoring individual tasks currently being managed by the Linux kernel. It writes to standard output activities for every task selected with option -p or for every task managed by the Linux kernel if option -p ALL has been used. Not selecting any tasks is equivalent to specifying -p ALL but only active tasks (tasks with non-zero statistics values) will appear in the report.;-H;Display timestamp in seconds since the epoch.;NONE;0
pidstat;The pidstat command is used for monitoring individual tasks currently being managed by the Linux kernel. It writes to standard output activities for every task selected with option -p or for every task managed by the Linux kernel if option -p ALL has been used. Not selecting any tasks is equivalent to specifying -p ALL but only active tasks (tasks with non-zero statistics values) will appear in the report.;--human;Print sizes in human readable format (e.g. 1.0k, 1.2M, etc.) The units displayed with this option supersede any other default units (e.g. kilobytes, sectors...) associated with the metrics.;NONE;0
pidstat;The pidstat command is used for monitoring individual tasks currently being managed by the Linux kernel. It writes to standard output activities for every task selected with option -p or for every task managed by the Linux kernel if option -p ALL has been used. Not selecting any tasks is equivalent to specifying -p ALL but only active tasks (tasks with non-zero statistics values) will appear in the report.;-e program args;Execute program with given arguments args and monitor it with pidstat. pidstat stops when program terminates.;NONE;1
rsync;Rsync is a fast and extraordinarily versatile file copying tool. It can copy locally, to/from another host over any remote shell, or to/from a remote rsync daemon.;rsync;Rsync is a fast and extraordinarily versatile file copying tool. It can copy locally, to/from another host over any remote shell, or to/from a remote rsync daemon.;NONE;2
rsync;Rsync is a fast and extraordinarily versatile file copying tool. It can copy locally, to/from another host over any remote shell, or to/from a remote rsync daemon.;rsync;Rsync is a fast and extraordinarily versatile file copying tool. It can copy locally, to/from another host over any remote shell, or to/from a remote rsync daemon.;NONE;5
rsync;Rsync is a fast and extraordinarily versatile file copying tool. It can copy locally, to/from another host over any remote shell, or to/from a remote rsync daemon.;rsync;Rsync is a fast and extraordinarily versatile file copying tool. It can copy locally, to/from another host over any remote shell, or to/from a remote rsync daemon.;NONE;3
rsync;Rsync is a fast and extraordinarily versatile file copying tool. It can copy locally, to/from another host over any remote shell, or to/from a remote rsync daemon.;-e, --rsh=COMMAND;specify the remote shell to use;NONE;1
rsync;Rsync is a fast and extraordinarily versatile file copying tool. It can copy locally, to/from another host over any remote shell, or to/from a remote rsync daemon.;--specials;preserve special files;NONE;7
rsync;Rsync is a fast and extraordinarily versatile file copying tool. It can copy locally, to/from another host over any remote shell, or to/from a remote rsync daemon.;--devices;preserve device files (super-user only);NONE;7
rsync;Rsync is a fast and extraordinarily versatile file copying tool. It can copy locally, to/from another host over any remote shell, or to/from a remote rsync daemon.;--checksum-choice=STR;choose the checksum algorithms;NONE;0
rsync;Rsync is a fast and extraordinarily versatile file copying tool. It can copy locally, to/from another host over any remote shell, or to/from a remote rsync daemon.;--existing;skip creating new files on receiver;NONE;7
rsync;Rsync is a fast and extraordinarily versatile file copying tool. It can copy locally, to/from another host over any remote shell, or to/from a remote rsync daemon.;--ignore-errors;delete even if there are I/O errors;NONE;9
run-parts;run-parts runs all the executable files named within constraints described below, found in directory directory. Other files and directories are silently ignored.;--test;print the names of the scripts which would be run, but don't actually run them.;NONE;0
run-parts;run-parts runs all the executable files named within constraints described below, found in directory directory. Other files and directories are silently ignored.;--exit-on-error;exit as soon as a script returns with a non-zero exit code.;NONE;0
run-parts;run-parts runs all the executable files named within constraints described below, found in directory directory. Other files and directories are silently ignored.;-v, --verbose;print the name of each script to stderr before running.;NONE;0
run-parts;run-parts runs all the executable files named within constraints described below, found in directory directory. Other files and directories are silently ignored.;run-parts;run-parts runs all the executable files named within constraints described below, found in directory directory. Other files and directories are silently ignored.;NONE;1
scanmem;scanmem is an interactive debugging utility that can be used to isolate the address of a variable in an executing process by successively scanning the process' address space looking for matching values. By informing scanmem how the value of the variable changes over time, it can determine the actual location (or locations) of the variable by successively eliminating non-matches. scanmem determines where to look by searching for mappings with read / write permission, these are referred to as regions. Users can eliminate regions they believe are likely unrelated to the target variable (for example, located in a shared library unrelated to the variable in question), this will improve the speed of the scan, which can initially be quite slow in large programs.;scanmem;scanmem is an interactive debugging utility that can be used to isolate the address of a variable in an executing process by successively scanning the process' address space looking for matching values. By informing scanmem how the value of the variable changes over time, it can determine the actual location (or locations) of the variable by successively eliminating non-matches. scanmem determines where to look by searching for mappings with read / write permission, these are referred to as regions. Users can eliminate regions they believe are likely unrelated to the target variable (for example, located in a shared library unrelated to the variable in question), this will improve the speed of the scan, which can initially be quite slow in large programs.;NONE;6
scanmem;scanmem is an interactive debugging utility that can be used to isolate the address of a variable in an executing process by successively scanning the process' address space looking for matching values. By informing scanmem how the value of the variable changes over time, it can determine the actual location (or locations) of the variable by successively eliminating non-matches. scanmem determines where to look by searching for mappings with read / write permission, these are referred to as regions. Users can eliminate regions they believe are likely unrelated to the target variable (for example, located in a shared library unrelated to the variable in question), this will improve the speed of the scan, which can initially be quite slow in large programs.;shell shell-command;Execute shell-command using /bin/sh, then return.;NONE;1
scanmem;scanmem is an interactive debugging utility that can be used to isolate the address of a variable in an executing process by successively scanning the process' address space looking for matching values. By informing scanmem how the value of the variable changes over time, it can determine the actual location (or locations) of the variable by successively eliminating non-matches. scanmem determines where to look by searching for mappings with read / write permission, these are referred to as regions. Users can eliminate regions they believe are likely unrelated to the target variable (for example, located in a shared library unrelated to the variable in question), this will improve the speed of the scan, which can initially be quite slow in large programs.;version;Print the version of scanmem in use.;NONE;0
scanmem;scanmem is an interactive debugging utility that can be used to isolate the address of a variable in an executing process by successively scanning the process' address space looking for matching values. By informing scanmem how the value of the variable changes over time, it can determine the actual location (or locations) of the variable by successively eliminating non-matches. scanmem determines where to look by searching for mappings with read / write permission, these are referred to as regions. Users can eliminate regions they believe are likely unrelated to the target variable (for example, located in a shared library unrelated to the variable in question), this will improve the speed of the scan, which can initially be quite slow in large programs.;show info;Display information relating to info - see `help show` for details.;NONE;0
scanmem;scanmem is an interactive debugging utility that can be used to isolate the address of a variable in an executing process by successively scanning the process' address space looking for matching values. By informing scanmem how the value of the variable changes over time, it can determine the actual location (or locations) of the variable by successively eliminating non-matches. scanmem determines where to look by searching for mappings with read / write permission, these are referred to as regions. Users can eliminate regions they believe are likely unrelated to the target variable (for example, located in a shared library unrelated to the variable in question), this will improve the speed of the scan, which can initially be quite slow in large programs.;reset;Forget all known regions and matches and start again.;NONE;0
scp;scp copies files between hosts on a network. It uses ssh(1) for data transfer, and uses the same authentica tion and provides the same security as ssh(1). scp will ask for passwords or passphrases if they are needed for authentication.;scp;scp copies files between hosts on a network. It uses ssh(1) for data transfer, and uses the same authentica tion and provides the same security as ssh(1). scp will ask for passwords or passphrases if they are needed for authentication.;NONE;2
scp;scp copies files between hosts on a network. It uses ssh(1) for data transfer, and uses the same authentica tion and provides the same security as ssh(1). scp will ask for passwords or passphrases if they are needed for authentication.;scp;scp copies files between hosts on a network. It uses ssh(1) for data transfer, and uses the same authentica tion and provides the same security as ssh(1). scp will ask for passwords or passphrases if they are needed for authentication.;NONE;5
scp;scp copies files between hosts on a network. It uses ssh(1) for data transfer, and uses the same authentica tion and provides the same security as ssh(1). scp will ask for passwords or passphrases if they are needed for authentication.;scp;scp copies files between hosts on a network. It uses ssh(1) for data transfer, and uses the same authentica tion and provides the same security as ssh(1). scp will ask for passwords or passphrases if they are needed for authentication.;NONE;3
script;script makes a typescript of everything displayed on your terminal. It is useful for students who need a hardcopy record of an interactive session as proof of an assignment, as the typescript file can be printed out later with lpr(1).;-a, --append;Append the output to file or to typescript, retaining the prior contents.;NONE;3
script;script makes a typescript of everything displayed on your terminal. It is useful for students who need a hardcopy record of an interactive session as proof of an assignment, as the typescript file can be printed out later with lpr(1).;-c, --command command;Run the command rather than an interactive shell. This makes it easy for a script to capture the output of a program that behaves differently when its stdout is not a tty.;NONE;1
smbclient;smbclient is a client that can 'talk' to an SMB/CIFS server. It offers an interface similar to that of the ftp program (see ftp(1)). Operations include things like getting files from the server to the local machine, putting files from the local machine to the server, retrieving directory information from the server and so on.;smbclient;smbclient is a client that can 'talk' to an SMB/CIFS server. It offers an interface similar to that of the ftp program (see ftp(1)). Operations include things like getting files from the server to the local machine, putting files from the local machine to the server, retrieving directory information from the server and so on.;NONE;5
smbclient;smbclient is a client that can 'talk' to an SMB/CIFS server. It offers an interface similar to that of the ftp program (see ftp(1)). Operations include things like getting files from the server to the local machine, putting files from the local machine to the server, retrieving directory information from the server and so on.;! [shell command];If shell command is specified, the ! command will execute a shell locally and run the specified shell command. If no command is specified, a local shell will be run.;NONE;1
smbclient;smbclient is a client that can 'talk' to an SMB/CIFS server. It offers an interface similar to that of the ftp program (see ftp(1)). Operations include things like getting files from the server to the local machine, putting files from the local machine to the server, retrieving directory information from the server and so on.;allinfo file;The client will request that the server return all known information about a file or directory (including streams).;NONE;0
smbclient;smbclient is a client that can 'talk' to an SMB/CIFS server. It offers an interface similar to that of the ftp program (see ftp(1)). Operations include things like getting files from the server to the local machine, putting files from the local machine to the server, retrieving directory information from the server and so on.;chmod file mode in octal;This command depends on the server supporting the CIFS UNIX extensions and will fail if the server does not. The client requests that the server change the UNIX permissions to the given octal mode, in standard UNIX format.;NONE;0
smbclient;smbclient is a client that can 'talk' to an SMB/CIFS server. It offers an interface similar to that of the ftp program (see ftp(1)). Operations include things like getting files from the server to the local machine, putting files from the local machine to the server, retrieving directory information from the server and so on.;get <remote file name> [local file name];Copy the file called remote file name from the server to the machine running the client. If specified, name the local copy local file name. Note that all transfers in smbclient are binary. See also the lowercase command.;NONE;3
smbclient;smbclient is a client that can 'talk' to an SMB/CIFS server. It offers an interface similar to that of the ftp program (see ftp(1)). Operations include things like getting files from the server to the local machine, putting files from the local machine to the server, retrieving directory information from the server and so on.;listconnect;Show the current connections held for DFS purposes.;NONE;8
smbclient;smbclient is a client that can 'talk' to an SMB/CIFS server. It offers an interface similar to that of the ftp program (see ftp(1)). Operations include things like getting files from the server to the local machine, putting files from the local machine to the server, retrieving directory information from the server and so on.;more <file name>;Fetch a remote file and view it with the contents of your PAGER environment variable.;NONE;4
smbclient;smbclient is a client that can 'talk' to an SMB/CIFS server. It offers an interface similar to that of the ftp program (see ftp(1)). Operations include things like getting files from the server to the local machine, putting files from the local machine to the server, retrieving directory information from the server and so on.;more <file name>;Fetch a remote file and view it with the contents of your PAGER environment variable.;NONE;1
smbclient;smbclient is a client that can 'talk' to an SMB/CIFS server. It offers an interface similar to that of the ftp program (see ftp(1)). Operations include things like getting files from the server to the local machine, putting files from the local machine to the server, retrieving directory information from the server and so on.;put <local file name> [remote file name];Copy the file called local file name from the machine running the client to the server. If specified, name the remote copy remote file name. Note that all transfers in smbclient are binary. See also the lowercase command.;NONE;2
smbclient;smbclient is a client that can 'talk' to an SMB/CIFS server. It offers an interface similar to that of the ftp program (see ftp(1)). Operations include things like getting files from the server to the local machine, putting files from the local machine to the server, retrieving directory information from the server and so on.;queue;Displays the print queue, showing the job id, name, size and current status.;NONE;0
smbclient;smbclient is a client that can 'talk' to an SMB/CIFS server. It offers an interface similar to that of the ftp program (see ftp(1)). Operations include things like getting files from the server to the local machine, putting files from the local machine to the server, retrieving directory information from the server and so on.;quit;See the exit command.;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;NONE;5
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-help;Display this summary;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-port +int;TCP/IP port to listen on for connections (default is 4433);NONE;11
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-accept val;TCP/IP optional host and port to listen on for connections (default is *:4433);NONE;11
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-unix val;Unix domain socket to accept on;NONE;2
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-4;Use IPv4 only;NONE;11
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-6;Use IPv6 only;NONE;11
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-unlink;For -unix, unlink existing socket first;NONE;11
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-context val;Set session ID context;NONE;5
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-verify int;Turn on peer certificate verification;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-Verify int;Turn on peer certificate verification, must have a cert;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-cert infile;Certificate file to use. default is server.pem;NONE;2
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-nameopt val;Various certificate name options;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-naccept +int;Terminate after #num connections;NONE;11
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-serverinfo val;PEM serverinfo file for certificate;NONE;2
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-certform PEM|DER;Certificate format (PEM or DER) PEM default;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-key val;Private Key if not in -cert. default is server.pem;NONE;2
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-keyform format;Key format (PEM, DER or ENGINE) PEM default;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-pass val;Private key file pass phrase source;NONE;2
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-dcert infile;Second certificate file to use (usually for DSA);NONE;2
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-dhparam infile;DH parameters file to use;NONE;2
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-dcertform PEM|DER;Second certificate format (PEM or DER) PEM default;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-dkey infile;Second private key file to use (usually for DSA);NONE;2
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-dkeyform PEM|DER;Second key format (PEM, DER or ENGINE) PEM default;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-dpass val;Second private key file pass phrase source;NONE;2
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-nbio_test;Test with the non-blocking test bio;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-crlf;Convert LF from terminal into CRLF;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-debug;Print more output;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-msg;Show protocol messages;NONE;5
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-msgfile outfile;File to send output of -msg or -trace, instead of stdout;NONE;3
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-state;Print the SSL states;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-CAfile infile;PEM format file of CA's;NONE;2
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-CApath dir;PEM format directory of CA's;NONE;2
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-no-CAfile;Do not load the default certificates file;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-no-CApath;Do not load certificates from the default certificates directory;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-nocert;Don't use any certificates (Anon-DH);NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-quiet;No server output;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-no_resume_ephemeral;Disable caching and tickets if ephemeral (EC)DH is used;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-www;Respond to a 'GET /' with a status page;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-servername val;Servername for HostName TLS extension;NONE;5
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-servername_fatal;mismatch send fatal alert (default warning alert);NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-cert2 infile;Certificate file to use for servername. default isserver2.pem;NONE;2
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-key2 infile;-Private Key file to use for servername if not in -cert2;NONE;2
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-tlsextdebug;Hex dump of all TLS extensions received;NONE;4
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-id_prefix val;Generate SSL/TLS session IDs prefixed by arg;NONE;5
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-rand val;Load the file(s) into the random number generator;NONE;2
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-writerand outfile;Write random data to the specified file;NONE;3
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-keymatexport val;Export keying material using label;NONE;3
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-keymatexportlen +int;Export len bytes of keying material (default 20);NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-CRL infile;CRL file to use;NONE;2
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-crl_download;Download CRL from distribution points;NONE;5
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-cert_chain infile;certificate chain file in PEM format;NONE;2
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-dcert_chain infile;second certificate chain file in PEM format;NONE;2
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-chainCApath dir;use dir as certificate store path to build CA certificate chain;NONE;2
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-verifyCApath dir;use dir as certificate store path to verify CA certificate;NONE;2
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-no_cache;Disable session cache;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-ext_cache;Disable internal cache, setup and use external cache;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-CRLform PEM|DER;CRL format (PEM or DER) PEM is default;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-verify_return_error;Close connection on verification error;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-verify_quiet;No verify output except verify errors;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-build_chain;Build certificate chain;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-chainCAfile infile;CA file for certificate chain (PEM format);NONE;2
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-verifyCAfile infile;CA file for certificate verification (PEM format);NONE;2
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-ign_eof;ignore input eof (default when -quiet);NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-no_ign_eof;Do not ignore input eof;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-status;Request certificate status from server;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-status_verbose;Print more output in certificate status callback;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-status_timeout int;Status request responder timeout;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-status_url val;Status request fallback URL;NONE;5
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-status_file infile;File containing DER encoded OCSP Response;NONE;2
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-security_debug;Print output from SSL/TLS security framework;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-security_debug_verbose;Print more output from SSL/TLS security framework;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-brief;Restrict output to brief summary of connection parameters;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-rev;act as a simple test server which just sends back with the received text reversed;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-async;Operate in asynchronous mode;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-ssl_config val;Configure SSL_CTX using the configuration 'val';NONE;10
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-max_send_frag +int;Maximum Size of send frames;NONE;11
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-split_send_frag +int;Size used to split data for encrypt pipelines;NONE;11
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-max_pipelines +int;Maximum number of encrypt/decrypt pipelines to be used;NONE;11
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-read_buf +int;Default read buffer size to be used for connections;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-no_ssl3;Just disable SSLv3;NONE;11
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-no_tls1;Just disable TLSv1;NONE;11
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-no_tls1_1;Just disable TLSv1.1;NONE;11
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-no_tls1_2;Just disable TLSv1.2;NONE;11
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-no_tls1_3;Just disable TLSv1.3;NONE;11
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-bugs;Turn on SSL bug compatibility;NONE;11
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-no_comp;Disable SSL/TLS compression (default);NONE;11
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-comp;Use SSL/TLS-level compression;NONE;11
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-no_ticket;Disable use of TLS session tickets;NONE;11
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-serverpref;Use server's cipher preferences;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-legacy_renegotiation;Enable use of legacy renegotiation (dangerous);NONE;11
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-no_renegotiation;Disable all renegotiation.;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-legacy_server_connect;Allow initial connection to servers that don't support RI;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-no_resumption_on_reneg;Disallow session resumption on renegotiation;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-no_legacy_server_connect;Disallow initial connection to servers that don't support RI;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-allow_no_dhe_kex;In TLSv1.3 allow non-(ec)dhe based key exchange on resumption;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-prioritize_chacha;Prioritize ChaCha ciphers when preferred by clients;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-strict;Enforce strict certificate checks as per TLS standard;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-sigalgs val;Signature algorithms to support (colon-separated list);NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-client_sigalgs val;Signature algorithms to support for client certificate authentication (colon-separated list);NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-groups val;Groups to advertise (colon-separated list);NONE;11
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-curves val;Groups to advertise (colon-separated list);NONE;11
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-named_curve val;Elliptic curve used for ECDHE (server-side only);NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-cipher val;Specify TLSv1.2 and below cipher list to be used;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-ciphersuites val;Specify TLSv1.3 ciphersuites to be used;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-min_protocol val;Specify the minimum protocol version to be used;NONE;11
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-max_protocol val;Specify the maximum protocol version to be used;NONE;11
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-record_padding val;Block size to pad TLS 1.3 records to.;NONE;11
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-debug_broken_protocol;Perform all sorts of protocol violations for testing purposes;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-no_middlebox;Disable TLSv1.3 middlebox compat mode;NONE;11
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-policy val;adds policy to the acceptable policy set;NONE;2
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-purpose val;certificate chain purpose;NONE;11
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-verify_name val;verification policy name;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-verify_depth int;chain depth limit;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-auth_level int;chain authentication security level;NONE;11
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-attime intmax;verification epoch time;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-verify_hostname val;expected peer hostname;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-verify_email val;expected peer email;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-verify_ip val;expected peer IP address;NONE;11
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-ignore_critical;permit unhandled critical extensions;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-issuer_checks;(deprecated);NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-crl_check;check leaf certificate revocation;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-crl_check_all;check full chain revocation;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-policy_check;perform rfc5280 policy checks;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-explicit_policy;set policy variable require-explicit-policy;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-inhibit_any;set policy variable inhibit-any-policy;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-inhibit_map;set policy variable inhibit-policy-mapping;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-x509_strict;disable certificate compatibility work-arounds;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-extended_crl;enable extended CRL features;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-use_deltas;use delta CRLs;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-policy_print;print policy processing diagnostics;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-check_ss_sig;check root CA self-signatures;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-trusted_first;search trust store first (default);NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-suiteB_128_only;Suite B 128-bit-only mode;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-suiteB_128;Suite B 128-bit mode allowing 192-bit algorithms;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-suiteB_192;Suite B 192-bit-only mode;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-partial_chain;accept chains anchored by intermediate trust-store CAs;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-no_alt_chains;(deprecated);NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-no_check_time;ignore certificate validity time;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-allow_proxy_certs;allow the use of proxy certificates;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-xkey infile;key for Extended certificates;NONE;2
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-xcert infile;cert for Extended certificates;NONE;2
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-xchain infile;chain for Extended certificates;NONE;2
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-xchain_build;build certificate chain for the extended certificates;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-xcertform PEM|DER;format of Extended certificate (PEM or DER) PEM default;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-xkeyform PEM|DER;format of Extended certificate's key (PEM or DER) PEM default;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-nbio;Use non-blocking IO;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-psk_identity val;PSK identity to expect;NONE;5
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-psk_hint val;PSK identity hint to use;NONE;5
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-psk val;PSK in hex (without 0x);NONE;5
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-psk_session infile;File to read PSK SSL session from;NONE;2
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-srpvfile infile;The verifier file for SRP;NONE;2
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-srpuserseed val;A seed string for a default user salt;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-tls1;Just talk TLSv1;NONE;11
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-tls1_1;Just talk TLSv1.1;NONE;11
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-tls1_2;just talk TLSv1.2;NONE;11
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-tls1_3;just talk TLSv1.3;NONE;11
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-dtls;Use any DTLS version;NONE;11
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-timeout;Enable timeouts;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-mtu +int;Set link layer MTU;NONE;11
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-listen;Listen for a DTLS ClientHello with a cookie and then connect;NONE;5
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-stateless;Require TLSv1.3 cookies;NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-dtls1;Just talk DTLSv1;NONE;11
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-dtls1_2;Just talk DTLSv1.2;NONE;11
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-no_dhe;Disable ephemeral DH;NONE;11
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-nextprotoneg val;Set the advertised protocols for the NPN extension (comma-separated list);NONE;5
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-use_srtp val;Offer SRTP key management with a colon-separated profile list;NONE;11
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-keylogfile outfile;Write TLS secrets to file;NONE;3
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-max_early_data int;The maximum number of bytes of early data as advertised in tickets;NONE;11
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-recv_max_early_data int;The maximum number of bytes of early data (hard limit);NONE;11
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-early_data;Attempt to read early data;NONE;4
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-num_tickets int;The number of TLSv1.3 session tickets that a server will automatically issue;NONE;5
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-anti_replay;Switch on anti-replay protection (default);NONE;0
s_server;This implements a generic SSL/TLS server which accepts connections from remote clients speaking SSL/TLS. It's intended for testing purposes only and provides only rudimentary interface functionality but internally uses mostly all functionality of the OpenSSL ssl library. It provides both an own command line oriented protocol for testing SSL functions and a simple HTTP response facility to emulate an SSL/TLS-aware webserver.;-no_anti_replay;Switch off anti-replay protection;NONE;11
sftp;sftp is an interactive file transfer program, similar to ftp(1), which performs all operations over an encrypted ssh(1) transport. It may also use many features of ssh, such as public key authentication and compression. sftp connects and logs into the specified host, then enters an interactive command mode.;sftp;sftp is an interactive file transfer program, similar to ftp(1), which performs all operations over an encrypted ssh(1) transport. It may also use many features of ssh, such as public key authentication and compression. sftp connects and logs into the specified host, then enters an interactive command mode.;NONE;5
sftp;sftp is an interactive file transfer program, similar to ftp(1), which performs all operations over an encrypted ssh(1) transport. It may also use many features of ssh, such as public key authentication and compression. sftp connects and logs into the specified host, then enters an interactive command mode.;sftp;sftp is an interactive file transfer program, similar to ftp(1), which performs all operations over an encrypted ssh(1) transport. It may also use many features of ssh, such as public key authentication and compression. sftp connects and logs into the specified host, then enters an interactive command mode.;NONE;2
sftp;sftp is an interactive file transfer program, similar to ftp(1), which performs all operations over an encrypted ssh(1) transport. It may also use many features of ssh, such as public key authentication and compression. sftp connects and logs into the specified host, then enters an interactive command mode.;sftp;sftp is an interactive file transfer program, similar to ftp(1), which performs all operations over an encrypted ssh(1) transport. It may also use many features of ssh, such as public key authentication and compression. sftp connects and logs into the specified host, then enters an interactive command mode.;NONE;3
sftp;sftp is an interactive file transfer program, similar to ftp(1), which performs all operations over an encrypted ssh(1) transport. It may also use many features of ssh, such as public key authentication and compression. sftp connects and logs into the specified host, then enters an interactive command mode.;sftp;sftp is an interactive file transfer program, similar to ftp(1), which performs all operations over an encrypted ssh(1) transport. It may also use many features of ssh, such as public key authentication and compression. sftp connects and logs into the specified host, then enters an interactive command mode.;NONE;7
sftp;sftp is an interactive file transfer program, similar to ftp(1), which performs all operations over an encrypted ssh(1) transport. It may also use many features of ssh, such as public key authentication and compression. sftp connects and logs into the specified host, then enters an interactive command mode.;sftp;sftp is an interactive file transfer program, similar to ftp(1), which performs all operations over an encrypted ssh(1) transport. It may also use many features of ssh, such as public key authentication and compression. sftp connects and logs into the specified host, then enters an interactive command mode.;NONE;1
sftp;sftp is an interactive file transfer program, similar to ftp(1), which performs all operations over an encrypted ssh(1) transport. It may also use many features of ssh, such as public key authentication and compression. sftp connects and logs into the specified host, then enters an interactive command mode.;-B buffer_size;Specify the size of the buffer that sftp uses when transferring files. Larger buffers require fewer round trips at the cost of higher memory consumption. The default is 32768 bytes.;NONE;11
sftp;sftp is an interactive file transfer program, similar to ftp(1), which performs all operations over an encrypted ssh(1) transport. It may also use many features of ssh, such as public key authentication and compression. sftp connects and logs into the specified host, then enters an interactive command mode.;-b batchfile;Batch mode reads a series of commands from an input batchfile instead of stdin. Since it lacks user interaction it should be used in conjunction with non-interactive authentication. A batchfile of '-' may be used to indicate standard input. sftp will abort if any of the following commands fail: get, put, rename, ln, rm, mkdir, chdir, ls, lchdir, chmod, chown, chgrp, lpwd, df, and lmkdir. Termination on error can be suppressed on a command by command basis by prefixing the command with a '-' character (for example, -rm /tmp/blah*).;NONE;10
sftp;sftp is an interactive file transfer program, similar to ftp(1), which performs all operations over an encrypted ssh(1) transport. It may also use many features of ssh, such as public key authentication and compression. sftp connects and logs into the specified host, then enters an interactive command mode.;-F ssh_config;Specifies an alternative per-user configuration file for ssh(1). This option is directly passed to ssh(1).;NONE;2
sftp;sftp is an interactive file transfer program, similar to ftp(1), which performs all operations over an encrypted ssh(1) transport. It may also use many features of ssh, such as public key authentication and compression. sftp connects and logs into the specified host, then enters an interactive command mode.;-S program;Name of the program to use for the encrypted connection. The program must understand ssh(1) options. ;NONE;1
sftp;sftp is an interactive file transfer program, similar to ftp(1), which performs all operations over an encrypted ssh(1) transport. It may also use many features of ssh, such as public key authentication and compression. sftp connects and logs into the specified host, then enters an interactive command mode.;-s subsystem | sftp_server;Specifies the SSH2 subsystem or the path for an sftp server on the remote host. A path is useful for using sftp over protocol version 1, or when the remote sshd(8) does not have an sftp subsystem configured.;NONE;5
sftp;sftp is an interactive file transfer program, similar to ftp(1), which performs all operations over an encrypted ssh(1) transport. It may also use many features of ssh, such as public key authentication and compression. sftp connects and logs into the specified host, then enters an interactive command mode.;-p;Preserves modification times, access times, and modes from the original files transferred.;NONE;7
sftp;sftp is an interactive file transfer program, similar to ftp(1), which performs all operations over an encrypted ssh(1) transport. It may also use many features of ssh, such as public key authentication and compression. sftp connects and logs into the specified host, then enters an interactive command mode.;-p;Preserves modification times, access times, and modes from the original files transferred.;NONE;9
sftp;sftp is an interactive file transfer program, similar to ftp(1), which performs all operations over an encrypted ssh(1) transport. It may also use many features of ssh, such as public key authentication and compression. sftp connects and logs into the specified host, then enters an interactive command mode.;-P port;Specifies the port to connect to on the remote host.;NONE;11
sftp;sftp is an interactive file transfer program, similar to ftp(1), which performs all operations over an encrypted ssh(1) transport. It may also use many features of ssh, such as public key authentication and compression. sftp connects and logs into the specified host, then enters an interactive command mode.;-r;Recursively copy entire directories when uploading and downloading. Note that sftp does not follow symbolic links encountered in the tree traversal.;NONE;7
sftp;sftp is an interactive file transfer program, similar to ftp(1), which performs all operations over an encrypted ssh(1) transport. It may also use many features of ssh, such as public key authentication and compression. sftp connects and logs into the specified host, then enters an interactive command mode.;-a;Attempt to continue interrupted transfers rather than overwriting existing partial or complete copies of files.  If the partial contents differ from those being transferred, then the resultant file is likely to be corrupt.;NONE;2
sftp;sftp is an interactive file transfer program, similar to ftp(1), which performs all operations over an encrypted ssh(1) transport. It may also use many features of ssh, such as public key authentication and compression. sftp connects and logs into the specified host, then enters an interactive command mode.;-4;Forces sftp to use IPv4 addresses only.;NONE;11
sftp;sftp is an interactive file transfer program, similar to ftp(1), which performs all operations over an encrypted ssh(1) transport. It may also use many features of ssh, such as public key authentication and compression. sftp connects and logs into the specified host, then enters an interactive command mode.;-6;Forces sftp to use IPv6 addresses only.;NONE;11
sftp;sftp is an interactive file transfer program, similar to ftp(1), which performs all operations over an encrypted ssh(1) transport. It may also use many features of ssh, such as public key authentication and compression. sftp connects and logs into the specified host, then enters an interactive command mode.;-C;Enables compression (via ssh's -C flag).;NONE;11
sftp;sftp is an interactive file transfer program, similar to ftp(1), which performs all operations over an encrypted ssh(1) transport. It may also use many features of ssh, such as public key authentication and compression. sftp connects and logs into the specified host, then enters an interactive command mode.;-c cipher;Selects the cipher to use for encrypting the data transfers. This option is directly passed to ssh(1).;NONE;11
sftp;sftp is an interactive file transfer program, similar to ftp(1), which performs all operations over an encrypted ssh(1) transport. It may also use many features of ssh, such as public key authentication and compression. sftp connects and logs into the specified host, then enters an interactive command mode.;-i identity_file;Selects the file from which the identity (private key) for public key authentication is read. This option is directly passed to ssh(1).;NONE;2
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;-A, --catenate, --concatenate;Append archive to the end of another archive. The arguments are treated as the names of archives to append. All archives must be of the same format as the archive they are appended to, otherwise the resulting archive might be unusable with non-GNU implementations of tar. Notice also that when more than one archive is given, the members from archives other than the first one will be accessible in the resulting archive only if using the -i (--ignore-zeros) option. Compressed archives cannot be concatenated.;NONE;2
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;-A, --catenate, --concatenate;Append archive to the end of another archive. The arguments are treated as the names of archives to append. All archives must be of the same format as the archive they are appended to, otherwise the resulting archive might be unusable with non-GNU implementations of tar. Notice also that when more than one archive is given, the members from archives other than the first one will be accessible in the resulting archive only if using the -i (--ignore-zeros) option. Compressed archives cannot be concatenated.;NONE;3
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;-c, --create;Create a new archive. Arguments supply the names of the files to be archived. Directories are archived recursively, unless the --no-recursion option is given.;NONE;2
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;-c, --create;Create a new archive. Arguments supply the names of the files to be archived. Directories are archived recursively, unless the --no-recursion option is given.;NONE;3
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;-d, --diff, --compare;Find differences between archive and file system. The arguments are optional and specify archive members to compare. If not given, the current working directory is assumed.;NONE;7
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;-d, --diff, --compare;Find differences between archive and file system. The arguments are optional and specify archive members to compare. If not given, the current working directory is assumed.;NONE;2
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;--delete;Delete from the archive. The arguments supply names of the archive members to be removed. At least one argument must be given. This option does not operate on compressed archives. There is no short option equivalent.;NONE;3
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;-r, --append;Append files to the end of an archive. Arguments have the same meaning as for -c (--create).;NONE;2
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;-r, --append;Append files to the end of an archive. Arguments have the same meaning as for -c (--create).;NONE;3
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;-t, --list;List the contents of an archive. Arguments are optional. When given, they specify the names of the members to list.;NONE;4
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;--test-label;Test the archive volume label and exit. When used without arguments, it prints the volume label (if any) and exits with status 0. When one or more command line arguments are given. tar compares the volume label with each argument. It exits with code 0 if a match is found, and with code 1 other wise. No output is displayed, unless used together with the -v (--verbose) option.;NONE;4
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;-u, --update;Append files which are newer than the corresponding copy in the archive. Arguments have the same meaning as with -c and -r options. Notice, that newer files don't replace their old archive copies, but instead are appended to the end of archive. The resulting archive can thus contain several mem bers of the same name, corresponding to various versions of the same file.;NONE;2
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;-u, --update;Append files which are newer than the corresponding copy in the archive. Arguments have the same meaning as with -c and -r options. Notice, that newer files don't replace their old archive copies, but instead are appended to the end of archive. The resulting archive can thus contain several mem bers of the same name, corresponding to various versions of the same file.;NONE;3
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;-x, --extract, --get;Extract files from an archive. Arguments are optional. When given, they specify names of the ar chive members to be extracted.;NONE;2
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;-x, --extract, --get;Extract files from an archive. Arguments are optional. When given, they specify names of the ar chive members to be extracted.;NONE;3
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;--show-defaults;Show built-in defaults for various tar options and exit. No arguments are allowed.;NONE;0
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;-?, --help;Display a short option summary and exit.  No arguments allowed.;NONE;0
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;--usage;Display a list of available options and exit. No arguments allowed.;NONE;0
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;--version;Print program version and copyright information and exit.;NONE;0
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;--check-device;Check device numbers when creating incremental archives (default).;NONE;0
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;-g, --listed-incremental=FILE;Handle new GNU-format incremental backups. FILE is the name of a snapshot file, where tar stores additional information which is used to decide which files changed since the previous incremental dump and, consequently, must be dumped again. If FILE does not exist when creating an archive, it will be created and all files will be added to the resulting archive (the level 0 dump). To create incremental archives of non-zero level N, create a copy of the snapshot file created during the level N-1, and use it as FILE. When listing or extracting, the actual contents of FILE is not inspected, it is needed only due to syntactical requirements. It is therefore common practice to use /dev/null in its place.;NONE;2
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;-g, --listed-incremental=FILE;Handle new GNU-format incremental backups. FILE is the name of a snapshot file, where tar stores additional information which is used to decide which files changed since the previous incremental dump and, consequently, must be dumped again. If FILE does not exist when creating an archive, it will be created and all files will be added to the resulting archive (the level 0 dump). To create incremental archives of non-zero level N, create a copy of the snapshot file created during the level N-1, and use it as FILE. When listing or extracting, the actual contents of FILE is not inspected, it is needed only due to syntactical requirements. It is therefore common practice to use /dev/null in its place.;NONE;3
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;--hole-detection=METHOD;Use METHOD to detect holes in sparse files. This option implies --sparse. Valid values for METHOD are seek and raw. Default is seek with fallback to raw when not applicable.;NONE;0
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;-G, --incremental;Handle old GNU-format incremental backups.;NONE;0
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;--ignore-failed-read;Do not exit with nonzero on unreadable files.;NONE;0
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;-n, --seek;Assume the archive is seekable. Normally tar determines automatically whether the archive can be seeked or not. This option is intended for use in cases when such recognition fails. It takes ef fect only if the archive is open for reading (e.g. with --list or --extract options).;NONE;0
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;--no-check-device;Do not check device numbers when creating incremental archives.;NONE;0
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;--no-seek;Assume the archive is not seekable.;NONE;0
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;--occurrence[=N];Process only the Nth occurrence of each file in the archive. This option is valid only when used with one of the following subcommands: --delete, --diff, --extract or --list and when a list of files is given either on the command line or via the -T option. The default N is 1.;NONE;0
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;--restrict;Disable the use of some potentially harmful options.;NONE;0
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;--sparse-version=MAJOR[.MINOR];Set version of the sparse format to use (implies --sparse). This option implies --sparse. Valid argument values are 0.0, 0.1, and 1.0. For a detailed discussion of sparse formats, refer to the GNU Tar Manual, appendix D, "Sparse Formats". Using info reader, it can be accessed running the following command: info tar 'Sparse Formats'.;NONE;0
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;-S, --sparse;Handle sparse files efficiently. Some files in the file system may have segments which were actu ally never written (quite often these are database files created by such systems as DBM). When given this option, tar attempts to determine if the file is sparse prior to archiving it, and if so, to reduce the resulting archive size by not dumping empty parts of the file.;NONE;0
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;-k, --keep-old-files;Don't replace existing files when extracting.;NONE;7
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;--keep-newer-files;Don't replace existing files that are newer than their archive copies.;NONE;7
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;--keep-directory-symlink;Don't replace existing symlinks to directories when extracting.;NONE;7
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;--no-overwrite-dir;Preserve metadata of existing directories.;NONE;0
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;--one-top-level[=DIR];Extract all files into DIR, or, if used without argument, into a subdirectory named by the base name of the archive (minus standard compression suffixes recognizable by --auto-compress).;NONE;7
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;--one-top-level[=DIR];Extract all files into DIR, or, if used without argument, into a subdirectory named by the base name of the archive (minus standard compression suffixes recognizable by --auto-compress).;NONE;3
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;--overwrite;Overwrite existing files when extracting.;NONE;3
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;--overwrite-dir;Overwrite metadata of existing directories when extracting (default).;NONE;9
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;--recursive-unlink;Recursively remove all files in the directory prior to extracting it.;NONE;7
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;--recursive-unlink;Recursively remove all files in the directory prior to extracting it.;NONE;9
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;--remove-files;Remove files from disk after adding them to the archive.;NONE;9
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;--skip-old-files;Don't replace existing files when extracting, silently skip over them.;NONE;7
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;-U, --unlink-first;Remove each file prior to extracting over it.;NONE;9
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;-W, --verify;Verify the archive after writing it.;NONE;2
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;--ignore-command-error;Ignore subprocess exit codes.;NONE;0
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;--no-ignore-command-error;Treat non-zero exit codes of children as error (default).;NONE;0
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;-O, --to-stdout;Extract files to standard output.;NONE;4
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;--to-command=COMMAND;Pipe extracted files to COMMAND. The argument is the pathname of an external program, optionally with command line arguments. The program will be invoked and the contents of the file being ex tracted supplied to it on its standard output. Additional data will be supplied via the following environment variables:;NONE;1
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;-F, --info-script=COMMAND, --new-volume-script=COMMAND;Run COMMAND at the end of each tape (implies -M). The command can include arguments.;NONE;1
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;--rmt-command=COMMAND;Use COMMAND instead of rmt when accessing remote archives. See the description of the -f option, above.;NONE;1
tar;GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine.;--rsh-command=COMMAND;Use COMMAND instead of rsh when accessing remote archives. See the description of the -f option, above.;NONE;1
uname;print system information;-s, --kernel-name;print the kernel name;NONE;6
uname;print system information;uname;print system information;NONE;4
uname;print system information;-n, --nodename;print the network node hostname;NONE;8
uname;print system information;-n, --nodename;print the network node hostname;NONE;6
uname;print system information;-r, --kernel-release;print the kernel release;NONE;6
uname;print system information;-v, --kernel-version;print the kernel version;NONE;6
uname;print system information;-m, --machine;print the machine hardware name;NONE;6
uname;print system information;-p, --processor;print the processor type or "unknown";NONE;6
uname;print system information;-i, --hardware-platform;print the hardware platform or "unknown";NONE;6
uname;print system information;-o, --operating-system;print the operating system;NONE;6
uname;print system information;--help display;this help and exit;NONE;0
uname;print system information;--version;output version information and exit;NONE;0
uname;print system information;-a, --all;print all information, in the following order, except omit -p and -i if unknown;NONE;6
uname;print system information;-a, --all;print all information, in the following order, except omit -p and -i if unknown;NONE;8
wget;The non-interactive network downloader.;-h, --help;Print a help message describing all of Wget's command-line options.;NONE;0
wget;The non-interactive network downloader.;-b, --background;Go to background immediately after startup. If no output file is specified via the -o, output is redirected to wget-log.;NONE;0
wget;The non-interactive network downloader.;wget;The non-interactive network downloader.;NONE;5
wget;The non-interactive network downloader.;wget;The non-interactive network downloader.;NONE;3
wget;The non-interactive network downloader.;-o logfile;, --output-file=logfile Log all messages to logfile. The messages are normally reported to standard error.;NONE;3
wget;The non-interactive network downloader.;-a logfile;, --append-output=logfile Append to logfile. This is the same as -o, only it appends to logfile instead of overwriting the old log file. If logfile does not exist, a new file is created.;NONE;3
wget;The non-interactive network downloader.;-a logfile, --append-output=logfile;Append to logfile. This is the same as -o, only it appends to logfile instead of overwriting the old log file. If logfile does not exist, a new file is created.;NONE;7
wget;The non-interactive network downloader.;-a logfile, --append-output=logfile;Append to logfile. This is the same as -o, only it appends to logfile instead of overwriting the old log file. If logfile does not exist, a new file is created.;NONE;9
wget;The non-interactive network downloader.;-d, --debug;Turn on debug output, meaning various information important to the developers of Wget if it does not work properly. Your system administrator may have chosen to compile Wget without debug support, in which case -d will not work. Please note that compiling with debug support is always safe---Wget compiled with the debug support will not print any debug info unless requested with -d.;NONE;4
wget;The non-interactive network downloader.;-q, --quiet;Turn off Wget's output.;NONE;0
wget;The non-interactive network downloader.;-v, --verbose;Turn on verbose output, with all the available data. The default output is verbose.;NONE;0
wget;The non-interactive network downloader.;-nv, --no-verbose;Turn off verbose without being completely quiet (use -q for that), which means that error messages and basic information still get printed.;NONE;0
wget;The non-interactive network downloader.;--report-speed=type;Output bandwidth as type. The only accepted value is bits.;NONE;0
wget;The non-interactive network downloader.;-i file, --input-file=file;Read URLs from a local or external file. If - is specified as file, URLs are read from the standard input. (Use ./- to read from a file literally named -.);NONE;2
wget;The non-interactive network downloader.;-F, --force-html;When input is read from a file, force it to be treated as an HTML file. This enables you to retrieve relative links from existing HTML files on your local disk, by adding "<base href="url">" to HTML, or using the --base command-line option.;NONE;0
wget;The non-interactive network downloader.;-B URL, --base=URL;Resolves relative links using URL as the point of reference, when reading links from an HTML file specified via the -i/--input-file option (together with --force-html, or when the input file was fetched remotely from a server describing it as HTML). This is equivalent to the presence of a "BASE" tag in the HTML input file, with URL as the value for the "href" attribute.;NONE;0
wget;The non-interactive network downloader.;--config=FILE;Specify the location of a startup file you wish to use.;NONE;2
wget;The non-interactive network downloader.;--bind-address=ADDRESS;When making client TCP/IP connections, bind to ADDRESS on the local machine. ADDRESS may be specified as a hostname or IP address. This option can be useful if your machine is bound to multiple IPs.;NONE;11
wget;The non-interactive network downloader.;-t number;, --tries=number Set number of retries to number. Specify 0 or inf for infinite retrying. The default is to retry 20 times, with the exception of fatal errors like "connection refused" or "not found" (404), which are not retried.;NONE;11
wget;The non-interactive network downloader.;-O file;, --output-document=file The documents will not be written to the appropriate files, but all will be concatenated together and written to file. If - is used as file, documents will be printed to standard output, disabling link conversion. (Use ./- to print to a file literally named -.);NONE;3
wget;The non-interactive network downloader.;-nc, --no-clobber;If a file is downloaded more than once in the same directory, Wget's behavior depends on a few options, including -nc. In certain cases, the local file will be clobbered, or overwritten, upon repeated download. In other cases it will be preserved.;NONE;0
wget;The non-interactive network downloader.;--backups=backups;Before (over)writing a file, back up an existing file by adding a .1 suffix (_1 on VMS) to the file name. Such backup files are rotated to .2, .3, and so on, up to backups (and lost beyond that).;NONE;7
wget;The non-interactive network downloader.;--backups=backups;Before (over)writing a file, back up an existing file by adding a .1 suffix (_1 on VMS) to the file name. Such backup files are rotated to .2, .3, and so on, up to backups (and lost beyond that).;NONE;3
wget;The non-interactive network downloader.;-c, --continue;Continue getting a partially-downloaded file. This is useful when you want to finish up a download started by a previous instance of Wget, or by another program.;NONE;7
wget;The non-interactive network downloader.;--progress=type;Select the type of the progress indicator you wish to use. Legal indicators are "dot" and "bar".;NONE;0
wget;The non-interactive network downloader.;-N, --timestamping;Turn on time-stamping.;NONE;9
wget;The non-interactive network downloader.;--no-use-server-timestamps;Don't set the local file's timestamp by the one on the server. By default, when a file is downloaded, it's timestamps are set to match those from the remote file. This allows the use of --timestamping on subsequent invocations of wget. However, it is sometimes useful to base the local file's timestamp on when it was actually downloaded. for that purpose, the --no-use-server-timestamps option has been provided.;NONE;9
wget;The non-interactive network downloader.;-S, server-response;Print the headers sent by HTTP servers and responses sent by FTP servers.;NONE;4
wget;The non-interactive network downloader.;--spider;When invoked with this option, Wget will behave as a Web spider, which means that it will not download the pages, just check that they are there.;NONE;0
wget;The non-interactive network downloader.;-T seconds;, --timeout=seconds Set the network timeout to seconds seconds. This is equivalent to specifying --dns-timeout, --connect-timeout, and --read-timeout, all at the same time.;NONE;11
wget;The non-interactive network downloader.;--dns-timeout=seconds;Set the DNS lookup timeout to seconds seconds. DNS lookups that don't complete within the specified time will fail. By default, there is no timeout on DNS lookups, other than that implemented by system libraries.;NONE;11
wget;The non-interactive network downloader.;--connect-timeout=seconds;Set the connect timeout to seconds seconds. TCP connections that take longer to establish will be aborted. By default, there is no connect timeout, other than that implemented by system libraries.;NONE;11
wget;The non-interactive network downloader.;--read-timeout=seconds;Set the read (and write) timeout to seconds seconds. The "time" of this timeout refers to idle time: if, at any point in the download, no data is received for more than the specified number of seconds, reading fails and the download is restarted. This option does not directly affect the duration of the entire download.;NONE;11
wget;The non-interactive network downloader.;--limit-rate=amount;Limit the download speed to amount bytes per second. Amount may be expressed in bytes, kilobytes with the k suffix, or megabytes with the m suffix. For example, --limit-rate=20k will limit the retrieval rate to 20KB/s. This is useful when, for whatever reason, you don't want Wget to consume the entire available bandwidth.;NONE;11
wget;The non-interactive network downloader.;-w seconds;, --wait=seconds Wait the specified number of seconds between the retrievals. Use of this option is recommended, as it lightens the server load by making the requests less frequent. Instead of in seconds, the time can be specified in minutes using the "m" suffix, in hours using "h" suffix, or in days using "d" suffix.;NONE;11
wget;The non-interactive network downloader.;--waitretry=seconds;If you don't want Wget to wait between every retrieval, but only between retries of failed downloads, you can use this option. Wget will use linear backoff, waiting 1 second after the first failure on a given file, then waiting 2 seconds after the second failure on that file, up to the maximum number of seconds you specify.;NONE;11
wget;The non-interactive network downloader.;--random-wait;Some web sites may perform log analysis to identify retrieval programs such as Wget by looking for statistically significant similarities in the time between requests. This option causes the time between requests to vary between 0.5 and 1.5 * wait seconds, where wait was specified using the --wait option, in order to mask Wget's presence from such analysis.;NONE;11
wget;The non-interactive network downloader.;--no-proxy;Don't use proxies, even if the appropriate *_proxy environment variable is defined.;NONE;0
wget;The non-interactive network downloader.;-Q quota;, --quota=quota Specify download quota for automatic retrievals. The value can be specified in bytes (default), kilobytes (with k suffix), or megabytes (with m suffix).;NONE;0
wget;The non-interactive network downloader.;--no-dns-cache;Turn off caching of DNS lookups. Normally, Wget remembers the IP addresses it looked up from DNS so it doesn't have to repeatedly contact the DNS server for the same (typically small) set of hosts it retrieves from. This cache exists in memory only. a new Wget run will contact DNS again.;NONE;11
wget;The non-interactive network downloader.;--restrict-file-names=modes;Change which characters found in remote URLs must be escaped during generation of local filenames. Characters that are restricted by this option are escaped, i.e. replaced with %HH, where HH is the hexadecimal number that corresponds to the restricted character. This option may also be used to force all alphabetical cases to be either lower- or uppercase.;NONE;0
wget;The non-interactive network downloader.;-4, --inet4-only;Force connecting to IPv4 or IPv6 addresses. With --inet4-only or -4, Wget will only connect to IPv4 hosts, ignoring AAAA records in DNS, and refusing to connect to IPv6 addresses specified in URLs. Conversely, with --inet6-only or -6, Wget will only connect to IPv6 hosts and ignore A records and IPv4 addresses.;NONE;11
wget;The non-interactive network downloader.;--prefer-family=NONE/IPv4/IPv6; When given a choice of several addresses, connect to the addresses with specified address family first. The address order returned by DNS is used without change by default. This avoids spurious errors and connect attempts when accessing hosts that resolve to both IPv6 and IPv4 addresses from IPv4 networks. For example, www.kame.net resolves to 2001:200:0:8002:203:47ff:fea5:3085 and to 203.178.141.194. When the preferred family is "IPv4", the IPv4 address is used first. when the preferred family is "IPv6", the IPv6 address is used first. if the specified value is "none", the address order returned by DNS is used without change. Unlike -4 and -6, this option doesn't inhibit access to any address family, it only changes the order in which the addresses are accessed. Also note that the reordering performed by this option is stable---it doesn't affect order of addresses of the same family. That is, the relative order of all IPv4 addresses and of all IPv6 addresses remains intact in all cases.;NONE;11
wget;The non-interactive network downloader.;--retry-connrefused;Consider "connection refused" a transient error and try again. Normally Wget gives up on a URL when it is unable to connect to the site because failure to connect is taken as a sign that the server is not running at all and that retries would not help. This option is for mirroring unreliable sites whose servers tend to disappear for short periods of time.;NONE;11
wget;The non-interactive network downloader.;--user=user;, --password=password Specify the username user and password password for both FTP and HTTP file retrieval. These parameters can be overridden using the --ftp-user and --ftp-password options for FTP connections and the --http-user and --http-password options for HTTP connections.;NONE;5
wget;The non-interactive network downloader.;--ask-password;Prompt for a password for each connection established. Cannot be specified when --password is being used, because they are mutually exclusive.;NONE;0
wget;The non-interactive network downloader.;--no-iri;Turn off internationalized URI (IRI) support. Use --iri to turn it on. IRI support is activated by default.;NONE;0
wget;The non-interactive network downloader.;--local-encoding=encoding;Force Wget to use encoding as the default system encoding. That affects how Wget converts URLs specified as arguments from locale to UTF-8 for IRI support.;NONE;0
wget;The non-interactive network downloader.;--remote-encoding=encoding;Force Wget to use encoding as the default remote server encoding. That affects how Wget converts URIs found in files from remote encoding to UTF-8 during a recursive fetch. This options is only useful for IRI support, for the interpretation of non-ASCII characters.;NONE;0
wget;The non-interactive network downloader.;--unlink;Force Wget to unlink file instead of clobbering existing file. This option is useful for downloading to the directory with hardlinks.;NONE;9
wget;The non-interactive network downloader.;-nd, --no-directories;Do not create a hierarchy of directories when retrieving recursively. With this option turned on, all files will get saved to the current directory, without clobbering (if a name shows up more than once, the filenames will get extensions .n).;NONE;0
wget;The non-interactive network downloader.;-x, --force-directories;The opposite of -nd---create a hierarchy of directories, even if one would not have been created otherwise. E.g. wget -x http://fly.srk.fer.hr/robots.txt will save the downloaded file to fly.srk.fer.hr/robots.txt.;NONE;3
wget;The non-interactive network downloader.;-nH, --no-host-directories;Disable generation of host-prefixed directories. By default, invoking Wget with -r http://fly.srk.fer.hr/ will create a structure of directories beginning with fly.srk.fer.hr/. This option disables such behavior.;NONE;0
wget;The non-interactive network downloader.;--protocol-directories;Use the protocol name as a directory component of local file names. For example, with this option, wget -r http://host will save to http/host/... rather than just to host/....;NONE;0
wget;The non-interactive network downloader.;--cut-dirs=number;Ignore number directory components. This is useful for getting a fine-grained control over the directory where recursive retrieval will be saved.;NONE;0
wget;The non-interactive network downloader.;-P prefix;, --directory-prefix=prefix Set directory prefix to prefix. The directory prefix is the directory where all other files and subdirectories will be saved to, i.e. the top of the retrieval tree. The default is . (the current directory).;NONE;0
wget;The non-interactive network downloader.;--default-page=name;Use name as the default file name when it isn't known (i.e., for URLs that end in a slash), instead of index.html.;NONE;0
wget;The non-interactive network downloader.;-E, --adjust-extension;If a file of type application/xhtml+xml or text/html is downloaded and the URL does not end with the regexp \.[Hh][Tt][Mm][Ll]?, this option will cause the suffix .html to be appended to the local filename. This is useful, for instance, when you're mirroring a remote site that uses .asp pages, but you want the mirrored pages to be viewable on your stock Apache server. Another good use for this is when you're downloading CGI-generated materials. A URL like http://site.com/article.cgi?25 will be saved as article.cgi?25.html.;NONE;0
wget;The non-interactive network downloader.;--http-user=user, --http-password=password;Specify the username user and password password on an HTTP server. According to the type of the challenge, Wget will encode them using either the "basic" (insecure), the "digest", or the Windows "NTLM" authentication scheme.;NONE;5
wget;The non-interactive network downloader.;--no-http-keep-alive;Turn off the "keep-alive" feature for HTTP downloads. Normally, Wget asks the server to keep the connection open so that, when you download more than one document from the same server, they get transferred over the same TCP connection. This saves time and at the same time reduces the load on the server.;NONE;11
wget;The non-interactive network downloader.;--no-cache;Disable server-side cache. In this case, Wget will send the remote server an appropriate directive (Pragma: no-cache) to get the file from the remote service, rather than returning the cached version. This is especially useful for retrieving and flushing out-of-date documents on proxy servers.;NONE;11
wget;The non-interactive network downloader.;--no-cookies;Disable the use of cookies. Cookies are a mechanism for maintaining server-side state. The server sends the client a cookie using the "Set-Cookie" header, and the client responds with the same cookie upon further requests. Since cookies allow the server owners to keep track of visitors and for sites to exchange this information, some consider them a breach of privacy. The default is to use cookies. however, storing cookies is not on by default.;NONE;11
wget;The non-interactive network downloader.;--load-cookies file;Load cookies from file before the first HTTP retrieval. file is a textual file in the format originally used by Netscape's cookies.txt file.;NONE;2
wget;The non-interactive network downloader.;--save-cookies file;Save cookies to file before exiting. This will not save cookies that have expired or that have no expiry time (so-called "session cookies"), but also see --keep-session-cookies.;NONE;3
wget;The non-interactive network downloader.;--keep-session-cookies;When specified, causes --save-cookies to also save session cookies. Session cookies are normally not saved because they are meant to be kept in memory and forgotten when you exit the browser. Saving them is useful on sites that require you to log in or to visit the home page before you can access some pages. With this option, multiple Wget runs are considered a single browser session as far as the site is concerned.;NONE;3
wget;The non-interactive network downloader.;--ignore-length;Unfortunately, some HTTP servers (CGI programs, to be more precise) send out bogus "Content-Length" headers, which makes Wget go wild, as it thinks not all the document was retrieved. You can spot this syndrome if Wget retries getting the same document again and again, each time claiming that the (otherwise normal) connection has closed on the very same byte. With this option, Wget will ignore the "Content-Length" header---as if it never existed.;NONE;0
wget;The non-interactive network downloader.;--header=header-line;Send header-line along with the rest of the headers in each HTTP request. The supplied header is sent as-is, which means it must contain name and value separated by colon, and must not contain newlines.;NONE;5
wget;The non-interactive network downloader.;--max-redirect=number;Specifies the maximum number of redirections to follow for a resource. The default is 20, which is usually far more than necessary. However, on those occasions where you want to allow more (or fewer), this is the option to use.;NONE;11
wget;The non-interactive network downloader.;--proxy-user=user, --proxy-password=password;Specify the username user and password password for authentication on a proxy server. Wget will encode them using the "basic" authentication scheme.;NONE;5
wget;The non-interactive network downloader.;--referer=url;Include `Referer: url' header in HTTP request. Useful for retrieving documents with server-side processing that assume they are always being retrieved by interactive web browsers and only come out properly when Referer is set to one of the pages that point to them.;NONE;5
wget;The non-interactive network downloader.;--save-headers;Save the headers sent by the HTTP server to the file, preceding the actual contents, with an empty line as the separator.;NONE;3
wget;The non-interactive network downloader.;-U agent-string;, --user-agent=agent-string Identify as agent-string to the HTTP server.;NONE;5
wget;The non-interactive network downloader.;--post-data=string;Use POST as the method for all HTTP requests and send the specified data in the request body. --post-data sends string as data, whereas --post-file sends the contents of file. Expects its content as a command-line parameter.;NONE;5
wget;The non-interactive network downloader.;--post-file=file;Use POST as the method for all HTTP requests and send sends the contents of file in the request body. Expects content of the form "key1=value1&key2=value2". with percent-encoding for special characters. In particular, --post-file is not for transmitting files as form attachments: those must appear as "key=value" data (with appropriate percent-coding) just like everything else. Wget does not currently support "multipart/form-data" for transmitting POST data. only "application/x-www-form-urlencoded". Only one of --post-data and --post-file should be specified.;NONE;2
wget;The non-interactive network downloader.;--post-file=file;Use POST as the method for all HTTP requests and send sends the contents of file in the request body. Expects content of the form "key1=value1&key2=value2". with percent-encoding for special characters. In particular, --post-file is not for transmitting files as form attachments: those must appear as "key=value" data (with appropriate percent-coding) just like everything else. Wget does not currently support "multipart/form-data" for transmitting POST data. only "application/x-www-form-urlencoded". Only one of --post-data and --post-file should be specified.;NONE;5
